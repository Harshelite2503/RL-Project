{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple StockÂ Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a âˆˆ A includes three actions: a âˆˆ {âˆ’1, 0, 1}, where âˆ’1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {âˆ’k, ..., âˆ’1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or âˆ’10, respectively\n",
        "\n",
        "* Reward function: r(s, a, sâ€²) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, sâ€²) = vâ€² âˆ’ v, where vâ€² and v represent the portfolio\n",
        "values at state sâ€² and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mPT0ipYE28wL",
        "outputId": "457e63fa-1d7c-447c-fe7f-61928d7c99c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wrds in /usr/local/lib/python3.9/site-packages (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/site-packages (from wrds) (1.24.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/site-packages (from wrds) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/site-packages (from wrds) (1.10.1)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.9/site-packages (from wrds) (2.9.6)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.9/site-packages (from wrds) (1.4.47)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas->wrds) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting swig\n",
            "  Using cached swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "Installing collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mâœ¨ðŸ°âœ¨ Everything looks OK!\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-o0j3qxwz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-o0j3qxwz\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 8a75a4bbb28f86f88ee2d4bd9a8c19cce444badb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-ft4kotam/elegantrl_d0e13019f20f43b584c97d2af9b342e0\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-ft4kotam/elegantrl_d0e13019f20f43b584c97d2af9b342e0\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit bf5ecff658f46c9c8c3e09a02e72be7383bd201a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-ft4kotam/pyfolio_9829ca83fa314ad995eced7c2c68bb00\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/quantopian/pyfolio.git /tmp/pip-install-ft4kotam/pyfolio_9829ca83fa314ad995eced7c2c68bb00\n",
            "  Resolved https://github.com/quantopian/pyfolio.git to commit 4b901f6d73aa02ceb6d04b7d83502e5c6f2e81aa\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.24.2)\n",
            "Requirement already satisfied: stable-baselines3<2.0.0,>=1.6.2 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.8.0)\n",
            "Requirement already satisfied: exchange_calendars==3.6.3 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.6.3)\n",
            "Requirement already satisfied: lz4 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (4.3.2)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.5.3)\n",
            "Requirement already satisfied: scikit-learn>=0.21.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.7.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.6)\n",
            "Requirement already satisfied: alpaca_trade_api>=2.1.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: ray[default,tune]>=2.0.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (2.3.1)\n",
            "Requirement already satisfied: wrds>=3.1.6 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.1.6)\n",
            "Requirement already satisfied: importlib-metadata==4.13.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (4.13.0)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.4.0)\n",
            "Requirement already satisfied: gym>=0.17 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.21.0)\n",
            "Requirement already satisfied: jqdatasdk in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (1.8.11)\n",
            "Requirement already satisfied: ccxt>=1.66.32 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (3.0.66)\n",
            "Requirement already satisfied: stockstats>=0.4.0 in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.5.2)\n",
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.9/site-packages (from finrl==0.3.5) (0.2.17)\n",
            "Requirement already satisfied: pyluach in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.2.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.12.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2023.3)\n",
            "Requirement already satisfied: korean-lunar-calendar in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.3.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (2.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/site-packages (from importlib-metadata==4.13.0->finrl==0.3.5) (3.15.0)\n",
            "Requirement already satisfied: deprecation==2.1.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.0)\n",
            "Requirement already satisfied: websocket-client<2,>=0.56.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.5.1)\n",
            "Requirement already satisfied: msgpack==1.0.3 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.0.3)\n",
            "Requirement already satisfied: requests<3,>2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.28.2)\n",
            "Requirement already satisfied: aiohttp==3.8.1 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.8.1)\n",
            "Requirement already satisfied: websockets<11,>=9.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (10.4)\n",
            "Requirement already satisfied: PyYAML==6.0 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.26.15)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (22.2.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.3.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.9/site-packages (from deprecation==2.1.0->alpaca_trade_api>=2.1.0->finrl==0.3.5) (23.1)\n",
            "Requirement already satisfied: aiodns>=1.1.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (3.0.0)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (39.0.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (65.6.3)\n",
            "Requirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (2022.12.7)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (3.11.0)\n",
            "Requirement already satisfied: grpcio>=1.32.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.53.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (3.20.3)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (8.1.3)\n",
            "Requirement already satisfied: virtualenv>=20.0.24 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (20.21.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (4.17.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.10.7)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.14)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (6.3.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.5.5)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.11.2)\n",
            "Requirement already satisfied: gpustat>=1.0.0 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (1.1)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.16.0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/site-packages (from ray[default,tune]>=2.0.0->finrl==0.3.5) (0.9.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.10.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (3.1.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.21.0->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: torch>=1.11 in /usr/local/lib/python3.9/site-packages (from stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: sqlalchemy<2 in /usr/local/lib/python3.9/site-packages (from wrds>=3.1.6->finrl==0.3.5) (1.4.47)\n",
            "Requirement already satisfied: psycopg2-binary in /usr/local/lib/python3.9/site-packages (from wrds>=3.1.6->finrl==0.3.5) (2.9.6)\n",
            "Requirement already satisfied: pymysql>=0.7.6 in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (1.0.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (1.16.0)\n",
            "Requirement already satisfied: thriftpy2>=0.3.9 in /usr/local/lib/python3.9/site-packages (from jqdatasdk->finrl==0.3.5) (0.4.16)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (9.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (5.12.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (3.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (4.39.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/site-packages (from matplotlib->finrl==0.3.5) (1.0.7)\n",
            "Requirement already satisfied: ipython>=3.2.3 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (8.12.0)\n",
            "Requirement already satisfied: seaborn>=0.7.1 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.12.2)\n",
            "Requirement already satisfied: empyrical>=0.5.0 in /usr/local/lib/python3.9/site-packages (from pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.5.5)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (4.9.2)\n",
            "Requirement already satisfied: appdirs>=1.4.4 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (1.4.4)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (0.0.11)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (1.1)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (4.12.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.9/site-packages (from yfinance->finrl==0.3.5) (2.3.7)\n",
            "Requirement already satisfied: pycares>=4.0.0 in /usr/local/lib/python3.9/site-packages (from aiodns>=1.1.1->ccxt>=1.66.32->finrl==0.3.5) (4.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4>=4.11.1->yfinance->finrl==0.3.5) (2.4)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/site-packages (from cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (1.15.1)\n",
            "Requirement already satisfied: pandas-datareader>=0.2 in /usr/local/lib/python3.9/site-packages (from empyrical>=0.5.0->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.10.0)\n",
            "Requirement already satisfied: psutil>=5.6.0 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (5.9.4)\n",
            "Requirement already satisfied: nvidia-ml-py>=11.450.129 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (11.525.112)\n",
            "Requirement already satisfied: blessed>=1.17.1 in /usr/local/lib/python3.9/site-packages (from gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (1.20.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/site-packages (from html5lib>=1.1->yfinance->finrl==0.3.5) (0.5.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.1.6)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.5)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.8.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (4.5.0)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.18.2)\n",
            "Requirement already satisfied: pygments>=2.4.0 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.15.0)\n",
            "Requirement already satisfied: traitlets>=5 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.9.0)\n",
            "Requirement already satisfied: stack-data in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.6.2)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (3.0.38)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (5.1.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/site-packages (from ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/site-packages (from sqlalchemy<2->wrds>=3.1.6->finrl==0.3.5) (2.0.2)\n",
            "Requirement already satisfied: ply<4.0,>=3.4 in /usr/local/lib/python3.9/site-packages (from thriftpy2>=0.3.9->jqdatasdk->finrl==0.3.5) (3.11)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.1.2)\n",
            "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (10.9.0.58)\n",
            "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.4.0.1)\n",
            "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.91)\n",
            "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.14.3)\n",
            "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (10.2.10.91)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (1.11.1)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.99)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.0.0)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.101)\n",
            "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.4.91)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (11.7.99)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.1)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.9/site-packages (from torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (8.5.0.96)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (0.38.4)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (3.26.3)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/site-packages (from triton==2.0.0->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (16.0.1)\n",
            "Requirement already satisfied: platformdirs<4,>=2.4 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[default,tune]>=2.0.0->finrl==0.3.5) (3.2.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.6 in /usr/local/lib/python3.9/site-packages (from virtualenv>=20.0.24->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.3.6)\n",
            "Requirement already satisfied: pyglet>=1.4.0 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.0.5)\n",
            "Requirement already satisfied: box2d-py==2.3.5 in /usr/local/lib/python3.9/site-packages (from gym>=0.17->finrl==0.3.5) (2.3.5)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/site-packages (from jsonschema->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.19.3)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.9/site-packages (from opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.9/site-packages (from opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (2.11.0)\n",
            "Requirement already satisfied: wcwidth>=0.1.4 in /usr/local/lib/python3.9/site-packages (from blessed>=1.17.1->gpustat>=1.0.0->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.2.6)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (2.21)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=2.14.1 in /usr/local/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (2.17.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.56.2 in /usr/local/lib/python3.9/site-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (1.59.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/site-packages (from jedi>=0.16->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/site-packages (from pexpect>4.3->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.7.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (2.1.2)\n",
            "Requirement already satisfied: asttokens>=2.1.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (2.2.1)\n",
            "Requirement already satisfied: executing>=1.2.0 in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (1.2.0)\n",
            "Requirement already satisfied: pure-eval in /usr/local/lib/python3.9/site-packages (from stack-data->ipython>=3.2.3->pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2->finrl==0.3.5) (0.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/site-packages (from sympy->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/site-packages (from google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (4.9)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]>=2.0.0->finrl==0.3.5) (0.4.8)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "# ## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them. \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4p9cubCEtdO",
        "outputId": "ca78c2a3-bb06-4106-8a8a-9b84e2a5499b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.9/site-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (1.24.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pandas==1.5.3"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "print(pd.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fAw6Vfvwxx7",
        "outputId": "d6f28b30-2bfb-4559-a9f0-a1533452b57b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.5.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "EeMK7Uentj1V"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "AqC6WLsGmcP0"
      },
      "outputs": [],
      "source": [
        "# !pip install pandas==1.5.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "226AbR6_E0Sp"
      },
      "outputs": [],
      "source": [
        "tickers = ['BAJAJ-AUTO.NS',\t\n",
        "'TITAN.NS',\t\n",
        "'TATASTEEL.NS',\t\n",
        "'NESTLEIND.NS',\t\n",
        "'BRITANNIA.NS',\t\n",
        "'TATACONSUM.NS',\n",
        "'CIPLA.NS',\t\n",
        "'ULTRACEMCO.NS',\t\n",
        "'RELIANCE.NS',\t\n",
        "'ITC.NS',\t\n",
        "'BHARTIARTL.NS',\t\n",
        "'MARUTI.NS',\t\n",
        "'ONGC.NS',\t\n",
        "'BAJFINANCE.NS',\t\n",
        "'COALINDIA.NS',\t\n",
        "'ICICIBANK.NS',\t\n",
        "'WIPRO.NS',\t\n",
        "'HINDALCO.NS',\t\n",
        "'HEROMOTOCO.NS',\t\n",
        "'ADANIENT.NS',\t\n",
        "'LT.NS',\t\n",
        "'KOTAKBANK.NS',\t\n",
        "'BAJAJFINSV.NS',\t\n",
        "'NTPC.NS',\t \n",
        "'TCS.NS',\t\n",
        "'APOLLOHOSP.NS',\t\n",
        "'HDFCLIFE.NS',\t\n",
        "'INDUSINDBK.NS',\t\n",
        "'DRREDDY.NS',\t\t\t\t\t\n",
        "'TECHM.NS']\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "w9A8CN5R5PuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "690ae092-0c9c-4876-f878-01e065ccdf90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['BAJAJ-AUTO.NS', 'TITAN.NS', 'TATASTEEL.NS', 'NESTLEIND.NS', 'BRITANNIA.NS', 'TATACONSUM.NS', 'CIPLA.NS', 'ULTRACEMCO.NS', 'RELIANCE.NS', 'ITC.NS', 'BHARTIARTL.NS', 'MARUTI.NS', 'ONGC.NS', 'BAJFINANCE.NS', 'COALINDIA.NS', 'ICICIBANK.NS', 'WIPRO.NS', 'HINDALCO.NS', 'HEROMOTOCO.NS', 'ADANIENT.NS', 'LT.NS', 'KOTAKBANK.NS', 'BAJAJFINSV.NS', 'NTPC.NS', 'TCS.NS', 'APOLLOHOSP.NS', 'HDFCLIFE.NS', 'INDUSINDBK.NS', 'DRREDDY.NS', 'TECHM.NS']\n"
          ]
        }
      ],
      "source": [
        "print(tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "b76ff11b-c58e-43f2-98ae-7615a922d8ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (130112, 8)\n"
          ]
        }
      ],
      "source": [
        "# TRAIN_START_DATE = '2009-04-01'\n",
        "# TRAIN_END_DATE = '2021-01-01'\n",
        "# TEST_START_DATE = '2021-01-01'\n",
        "# TEST_END_DATE = '2022-06-01'\n",
        "\n",
        "TRAIN_START_DATE = '2005-01-01'\n",
        "TRAIN_END_DATE = '2021-10-01'\n",
        "TEST_START_DATE = '2021-10-01'\n",
        "TEST_END_DATE = '2023-04-01'\n",
        "\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TEST_END_DATE,\n",
        "                     ticker_list = tickers).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GiRuFOTOtj1Y",
        "outputId": "e05e3321-0f63-4330-ab8c-ff25b8a2c272"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date         open         high          low        close   volume  \\\n",
              "0  2005-01-03     5.962399     6.054364     5.901089     4.469341  6912918   \n",
              "1  2005-01-03   126.000000   131.000000   126.000000   115.371010   164838   \n",
              "2  2005-01-03   287.250000   289.950012   281.299988   190.725143   778286   \n",
              "3  2005-01-03  1149.000000  1159.800049  1125.199951  1121.040161   389100   \n",
              "4  2005-01-03    11.490891    11.703667    11.322807     9.849682   179573   \n",
              "\n",
              "             tic  day  \n",
              "0    ADANIENT.NS    0  \n",
              "1  APOLLOHOSP.NS    0  \n",
              "2  BAJAJ-AUTO.NS    0  \n",
              "3  BAJAJFINSV.NS    0  \n",
              "4  BAJFINANCE.NS    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d6130ad-43cb-451e-99c7-88a88f56a09a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>5.962399</td>\n",
              "      <td>6.054364</td>\n",
              "      <td>5.901089</td>\n",
              "      <td>4.469341</td>\n",
              "      <td>6912918</td>\n",
              "      <td>ADANIENT.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>115.371010</td>\n",
              "      <td>164838</td>\n",
              "      <td>APOLLOHOSP.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>287.250000</td>\n",
              "      <td>289.950012</td>\n",
              "      <td>281.299988</td>\n",
              "      <td>190.725143</td>\n",
              "      <td>778286</td>\n",
              "      <td>BAJAJ-AUTO.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>1149.000000</td>\n",
              "      <td>1159.800049</td>\n",
              "      <td>1125.199951</td>\n",
              "      <td>1121.040161</td>\n",
              "      <td>389100</td>\n",
              "      <td>BAJAJFINSV.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>11.490891</td>\n",
              "      <td>11.703667</td>\n",
              "      <td>11.322807</td>\n",
              "      <td>9.849682</td>\n",
              "      <td>179573</td>\n",
              "      <td>BAJFINANCE.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d6130ad-43cb-451e-99c7-88a88f56a09a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d6130ad-43cb-451e-99c7-88a88f56a09a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d6130ad-43cb-451e-99c7-88a88f56a09a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSw4ZEzVtj1Z",
        "outputId": "ba175061-9122-421f-ade7-55b52dfb404d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              date         open         high          low        close  \\\n",
              "130107  2023-03-31  3189.949951  3213.000000  3152.000000  3205.899902   \n",
              "130108  2023-03-31  1095.000000  1106.000000  1091.449951  1101.849976   \n",
              "130109  2023-03-31  2526.949951  2536.750000  2500.000000  2514.899902   \n",
              "130110  2023-03-31  7575.100098  7644.299805  7547.049805  7622.149902   \n",
              "130111  2023-03-31   363.350006   365.750000   361.299988   365.250000   \n",
              "\n",
              "         volume            tic  day  \n",
              "130107  2382581         TCS.NS    4  \n",
              "130108  2281085       TECHM.NS    4  \n",
              "130109   848456       TITAN.NS    4  \n",
              "130110   378456  ULTRACEMCO.NS    4  \n",
              "130111  3957106       WIPRO.NS    4  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-771cf7c0-a920-4f03-ae8f-2444c6146f64\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130107</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>3189.949951</td>\n",
              "      <td>3213.000000</td>\n",
              "      <td>3152.000000</td>\n",
              "      <td>3205.899902</td>\n",
              "      <td>2382581</td>\n",
              "      <td>TCS.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130108</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>1095.000000</td>\n",
              "      <td>1106.000000</td>\n",
              "      <td>1091.449951</td>\n",
              "      <td>1101.849976</td>\n",
              "      <td>2281085</td>\n",
              "      <td>TECHM.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130109</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>2526.949951</td>\n",
              "      <td>2536.750000</td>\n",
              "      <td>2500.000000</td>\n",
              "      <td>2514.899902</td>\n",
              "      <td>848456</td>\n",
              "      <td>TITAN.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130110</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>7575.100098</td>\n",
              "      <td>7644.299805</td>\n",
              "      <td>7547.049805</td>\n",
              "      <td>7622.149902</td>\n",
              "      <td>378456</td>\n",
              "      <td>ULTRACEMCO.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130111</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>363.350006</td>\n",
              "      <td>365.750000</td>\n",
              "      <td>361.299988</td>\n",
              "      <td>365.250000</td>\n",
              "      <td>3957106</td>\n",
              "      <td>WIPRO.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-771cf7c0-a920-4f03-ae8f-2444c6146f64')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-771cf7c0-a920-4f03-ae8f-2444c6146f64 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-771cf7c0-a920-4f03-ae8f-2444c6146f64');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "d4ca4e19-7ebe-484a-e5ec-b5ab9158e8a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(130112, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "bba34196-27c0-49f6-d585-854a1d483a81"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         date         open         high          low        close   volume  \\\n",
              "0  2005-01-03     5.962399     6.054364     5.901089     4.469341  6912918   \n",
              "1  2005-01-03   126.000000   131.000000   126.000000   115.371010   164838   \n",
              "2  2005-01-03   287.250000   289.950012   281.299988   190.725143   778286   \n",
              "3  2005-01-03  1149.000000  1159.800049  1125.199951  1121.040161   389100   \n",
              "4  2005-01-03    11.490891    11.703667    11.322807     9.849682   179573   \n",
              "\n",
              "             tic  day  \n",
              "0    ADANIENT.NS    0  \n",
              "1  APOLLOHOSP.NS    0  \n",
              "2  BAJAJ-AUTO.NS    0  \n",
              "3  BAJAJFINSV.NS    0  \n",
              "4  BAJFINANCE.NS    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d7d20492-9bac-4b90-9915-a946dd0f8e71\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>5.962399</td>\n",
              "      <td>6.054364</td>\n",
              "      <td>5.901089</td>\n",
              "      <td>4.469341</td>\n",
              "      <td>6912918</td>\n",
              "      <td>ADANIENT.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>115.371010</td>\n",
              "      <td>164838</td>\n",
              "      <td>APOLLOHOSP.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>287.250000</td>\n",
              "      <td>289.950012</td>\n",
              "      <td>281.299988</td>\n",
              "      <td>190.725143</td>\n",
              "      <td>778286</td>\n",
              "      <td>BAJAJ-AUTO.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>1149.000000</td>\n",
              "      <td>1159.800049</td>\n",
              "      <td>1125.199951</td>\n",
              "      <td>1121.040161</td>\n",
              "      <td>389100</td>\n",
              "      <td>BAJAJFINSV.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>11.490891</td>\n",
              "      <td>11.703667</td>\n",
              "      <td>11.322807</td>\n",
              "      <td>9.849682</td>\n",
              "      <td>179573</td>\n",
              "      <td>BAJFINANCE.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d7d20492-9bac-4b90-9915-a946dd0f8e71')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d7d20492-9bac-4b90-9915-a946dd0f8e71 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d7d20492-9bac-4b90-9915-a946dd0f8e71');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "df.sort_values(['date','tic']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vryMsdNL9H",
        "outputId": "25c217a6-c263-4e6c-fbd9-2426beb3a78d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "len(df.tic.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcNyXa7RNPrF",
        "outputId": "b01c0c84-f0fe-4cf5-d26b-1a8c09c4d08b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ADANIENT.NS      4505\n",
              "APOLLOHOSP.NS    4505\n",
              "WIPRO.NS         4505\n",
              "ULTRACEMCO.NS    4505\n",
              "TITAN.NS         4505\n",
              "TCS.NS           4505\n",
              "TATASTEEL.NS     4505\n",
              "TATACONSUM.NS    4505\n",
              "RELIANCE.NS      4505\n",
              "ONGC.NS          4505\n",
              "NTPC.NS          4505\n",
              "NESTLEIND.NS     4505\n",
              "MARUTI.NS        4505\n",
              "LT.NS            4505\n",
              "ICICIBANK.NS     4505\n",
              "HINDALCO.NS      4505\n",
              "HEROMOTOCO.NS    4505\n",
              "DRREDDY.NS       4505\n",
              "CIPLA.NS         4505\n",
              "BRITANNIA.NS     4505\n",
              "BHARTIARTL.NS    4505\n",
              "BAJFINANCE.NS    4505\n",
              "BAJAJ-AUTO.NS    4505\n",
              "KOTAKBANK.NS     4504\n",
              "ITC.NS           4504\n",
              "BAJAJFINSV.NS    4504\n",
              "INDUSINDBK.NS    4503\n",
              "TECHM.NS         4094\n",
              "COALINDIA.NS     3060\n",
              "HDFCLIFE.NS      1328\n",
              "Name: tic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "df.tic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007â€“2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "kM5bH9uroCeg"
      },
      "outputs": [],
      "source": [
        "#  INDICATORS = ['macd',\n",
        "#                'rsi_30',\n",
        "#                'cci_30',\n",
        "#                'dx_30']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXfBcjxtj1a",
        "outputId": "0885b18a-70bd-4b52-a202-21573463f55e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "grvhGJJII3Xn",
        "outputId": "0506c9b2-e2a0-4fc2-99aa-c02ab817010b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              date         open         high          low        close  \\\n",
              "27844   2009-11-26   176.833328   180.083328   174.166672   104.839539   \n",
              "21028   2008-09-05   234.100006   235.399994   232.350006   217.322632   \n",
              "29156   2010-02-22   185.000000   186.666672   183.641663   104.208061   \n",
              "13814   2007-06-05   133.833328   133.958328   132.083328    76.140846   \n",
              "101113  2022-10-25  3804.000000  3804.899902  3690.000000  3650.509521   \n",
              "\n",
              "         volume           tic  day      macd      boll_ub      boll_lb  \\\n",
              "27844   7724702       NTPC.NS    3  0.306767   108.667997   102.990075   \n",
              "21028   1065986      CIPLA.NS    4  3.673377   227.114174   210.928551   \n",
              "29156   3981498       ONGC.NS    0 -1.467419   106.720582   101.548351   \n",
              "13814    770402       NTPC.NS    1  0.596431    78.397252    72.259999   \n",
              "101113   228569  BRITANNIA.NS    1  8.100393  3800.798649  3651.983235   \n",
              "\n",
              "           rsi_30     cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
              "27844   49.354134 -50.780905  10.050324    106.256649    105.060071   \n",
              "21028   55.148253  29.120936  10.306480    214.605094    206.165520   \n",
              "29156   45.746557 -45.091681  22.432515    106.967526    108.811394   \n",
              "13814   55.349890  43.374586   2.003210     75.336975     73.378592   \n",
              "101113  49.878574 -54.592213   2.965445   3706.129191   3659.357365   \n",
              "\n",
              "        turbulence  \n",
              "27844     9.099641  \n",
              "21028    17.461752  \n",
              "29156     5.144043  \n",
              "13814     9.245995  \n",
              "101113   23.160994  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-621f765f-4f06-4bfa-87d6-20299abda7f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27844</th>\n",
              "      <td>2009-11-26</td>\n",
              "      <td>176.833328</td>\n",
              "      <td>180.083328</td>\n",
              "      <td>174.166672</td>\n",
              "      <td>104.839539</td>\n",
              "      <td>7724702</td>\n",
              "      <td>NTPC.NS</td>\n",
              "      <td>3</td>\n",
              "      <td>0.306767</td>\n",
              "      <td>108.667997</td>\n",
              "      <td>102.990075</td>\n",
              "      <td>49.354134</td>\n",
              "      <td>-50.780905</td>\n",
              "      <td>10.050324</td>\n",
              "      <td>106.256649</td>\n",
              "      <td>105.060071</td>\n",
              "      <td>9.099641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21028</th>\n",
              "      <td>2008-09-05</td>\n",
              "      <td>234.100006</td>\n",
              "      <td>235.399994</td>\n",
              "      <td>232.350006</td>\n",
              "      <td>217.322632</td>\n",
              "      <td>1065986</td>\n",
              "      <td>CIPLA.NS</td>\n",
              "      <td>4</td>\n",
              "      <td>3.673377</td>\n",
              "      <td>227.114174</td>\n",
              "      <td>210.928551</td>\n",
              "      <td>55.148253</td>\n",
              "      <td>29.120936</td>\n",
              "      <td>10.306480</td>\n",
              "      <td>214.605094</td>\n",
              "      <td>206.165520</td>\n",
              "      <td>17.461752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29156</th>\n",
              "      <td>2010-02-22</td>\n",
              "      <td>185.000000</td>\n",
              "      <td>186.666672</td>\n",
              "      <td>183.641663</td>\n",
              "      <td>104.208061</td>\n",
              "      <td>3981498</td>\n",
              "      <td>ONGC.NS</td>\n",
              "      <td>0</td>\n",
              "      <td>-1.467419</td>\n",
              "      <td>106.720582</td>\n",
              "      <td>101.548351</td>\n",
              "      <td>45.746557</td>\n",
              "      <td>-45.091681</td>\n",
              "      <td>22.432515</td>\n",
              "      <td>106.967526</td>\n",
              "      <td>108.811394</td>\n",
              "      <td>5.144043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13814</th>\n",
              "      <td>2007-06-05</td>\n",
              "      <td>133.833328</td>\n",
              "      <td>133.958328</td>\n",
              "      <td>132.083328</td>\n",
              "      <td>76.140846</td>\n",
              "      <td>770402</td>\n",
              "      <td>NTPC.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>0.596431</td>\n",
              "      <td>78.397252</td>\n",
              "      <td>72.259999</td>\n",
              "      <td>55.349890</td>\n",
              "      <td>43.374586</td>\n",
              "      <td>2.003210</td>\n",
              "      <td>75.336975</td>\n",
              "      <td>73.378592</td>\n",
              "      <td>9.245995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101113</th>\n",
              "      <td>2022-10-25</td>\n",
              "      <td>3804.000000</td>\n",
              "      <td>3804.899902</td>\n",
              "      <td>3690.000000</td>\n",
              "      <td>3650.509521</td>\n",
              "      <td>228569</td>\n",
              "      <td>BRITANNIA.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>8.100393</td>\n",
              "      <td>3800.798649</td>\n",
              "      <td>3651.983235</td>\n",
              "      <td>49.878574</td>\n",
              "      <td>-54.592213</td>\n",
              "      <td>2.965445</td>\n",
              "      <td>3706.129191</td>\n",
              "      <td>3659.357365</td>\n",
              "      <td>23.160994</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-621f765f-4f06-4bfa-87d6-20299abda7f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-621f765f-4f06-4bfa-87d6-20299abda7f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-621f765f-4f06-4bfa-87d6-20299abda7f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "processed.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,â€¦,-1, 0, 1,Â â€¦, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "f5fae7b1-ecc0-4e3f-b7e0-165bbb46c566"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stock Dimension: 23, State Space: 231\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 1000000, \n",
        "    \"buy_cost_pct\": 0.001, \n",
        "    \"sell_cost_pct\": 0.001, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "v-gthCxMtj1d"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window, \n",
        "                 validation_window=validation_window, \n",
        "                 **env_kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KsfEHa_Etj1d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007,\n",
        "                    'use_rms_prop': False, #using Adam\n",
        "                    'gae_lambda': 0.5,\n",
        "                    \"gamma\": 0.2 \n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128,\n",
        "                    'gae_lambda': 0.5,\n",
        "                    \"gamma\": 0.2   \n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 10_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64,\n",
        "                      \"gamma\": 0.2   \n",
        "                    }\n",
        "\n",
        "timesteps_dict = {'a2c' : 30_000, \n",
        "                 'ppo' : 30_000, \n",
        "                 'ddpg' : 30_000\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1lyCECstj1e",
        "outputId": "c7da2818-0aaf-44f2-a5b5-a6272b2da0b4",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 125          |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -0.204       |\n",
            "|    reward             | -0.100516796 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.0499       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 133         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -1.77       |\n",
            "|    reward             | -0.13978107 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0432      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 2100       |\n",
            "|    time_elapsed       | 140        |\n",
            "|    total_timesteps    | 10500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2099       |\n",
            "|    policy_loss        | -3.6       |\n",
            "|    reward             | -0.0215843 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.0293     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 145         |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 8.42        |\n",
            "|    reward             | -0.67315817 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.468       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 152       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | -7.19     |\n",
            "|    reward             | 1.6706648 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.05      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 160         |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.3       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | 16.2        |\n",
            "|    reward             | -0.45372024 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 2.19        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 165         |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.3       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | 2.98        |\n",
            "|    reward             | -0.18203014 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0123      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 171         |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | 18.1        |\n",
            "|    reward             | -0.26333037 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.584       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 179       |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.4     |\n",
            "|    explained_variance | -0.00915  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | 4.32      |\n",
            "|    reward             | 1.6598191 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 1.34      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 2800       |\n",
            "|    time_elapsed       | 186        |\n",
            "|    total_timesteps    | 14000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2799       |\n",
            "|    policy_loss        | 4.85       |\n",
            "|    reward             | 0.23064949 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.193      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 191         |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | -10         |\n",
            "|    reward             | -0.82135475 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.321       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 199         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 12          |\n",
            "|    reward             | 0.026174234 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.54        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 206        |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | 10.7       |\n",
            "|    reward             | -0.7764801 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.255      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 211        |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | 4.53       |\n",
            "|    reward             | 0.96866107 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 4.11       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 218        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | -44.1      |\n",
            "|    reward             | -0.3829237 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.07       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 226         |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | -2.22       |\n",
            "|    reward             | -0.10957737 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.00961     |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 3500      |\n",
            "|    time_elapsed       | 232       |\n",
            "|    total_timesteps    | 17500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.7     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3499      |\n",
            "|    policy_loss        | -5.22     |\n",
            "|    reward             | 0.0       |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.0356    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 237        |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | -3.21      |\n",
            "|    reward             | -0.5294824 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.196      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 245        |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3699       |\n",
            "|    policy_loss        | 3.66       |\n",
            "|    reward             | -0.4855914 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.0449     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 3800         |\n",
            "|    time_elapsed       | 252          |\n",
            "|    total_timesteps    | 19000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3799         |\n",
            "|    policy_loss        | 0.712        |\n",
            "|    reward             | -0.045459095 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.0805       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 257         |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | 8.73        |\n",
            "|    reward             | -0.15676919 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.296       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 264        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | 1.42       |\n",
            "|    reward             | 0.53361696 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.495      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 272       |\n",
            "|    total_timesteps    | 20500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.9     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | 47.9      |\n",
            "|    reward             | 6.9983134 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 19.4      |\n",
            "-------------------------------------\n",
            "day: 4132, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 3999615.27\n",
            "total_reward: 2999615.27\n",
            "total_cost: 2176.39\n",
            "total_trades: 43892\n",
            "Sharpe: 0.673\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 277         |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | 0.131       |\n",
            "|    reward             | -0.09635388 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.00561     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 284         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | 1.74        |\n",
            "|    reward             | -0.07791044 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.0803      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 292        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | 0.655      |\n",
            "|    reward             | 0.33625445 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.204      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 4500         |\n",
            "|    time_elapsed       | 298          |\n",
            "|    total_timesteps    | 22500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.2        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4499         |\n",
            "|    policy_loss        | 10.8         |\n",
            "|    reward             | -0.011093812 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.152        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 303        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | 18.1       |\n",
            "|    reward             | 0.02865946 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.479      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 311       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 2.39      |\n",
            "|    reward             | 2.1182435 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 0.129     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 318       |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.3     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | -50.3     |\n",
            "|    reward             | 2.2441263 |\n",
            "|    std                | 1.08      |\n",
            "|    value_loss         | 12        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4900       |\n",
            "|    time_elapsed       | 323        |\n",
            "|    total_timesteps    | 24500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4899       |\n",
            "|    policy_loss        | -11        |\n",
            "|    reward             | -2.0758054 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 6.81       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5000        |\n",
            "|    time_elapsed       | 331         |\n",
            "|    total_timesteps    | 25000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4999        |\n",
            "|    policy_loss        | -2.82       |\n",
            "|    reward             | 0.050358616 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0124      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 339        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | -3.88      |\n",
            "|    reward             | 0.07396062 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.0261     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5200       |\n",
            "|    time_elapsed       | 344        |\n",
            "|    total_timesteps    | 26000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5199       |\n",
            "|    policy_loss        | 1.2        |\n",
            "|    reward             | 0.25631994 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.00721    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 351         |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.7       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | -3.39       |\n",
            "|    reward             | -0.24930036 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.0489      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 359        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -9.43      |\n",
            "|    reward             | -0.1694943 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.252      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 365        |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | -13        |\n",
            "|    reward             | 0.23154108 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.246      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 371       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | -2.81     |\n",
            "|    reward             | 0.5351194 |\n",
            "|    std                | 1.1       |\n",
            "|    value_loss         | 0.114     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 379        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | -12.1      |\n",
            "|    reward             | 0.34957176 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.275      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5800        |\n",
            "|    time_elapsed       | 385         |\n",
            "|    total_timesteps    | 29000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.9       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5799        |\n",
            "|    policy_loss        | 1.11        |\n",
            "|    reward             | 0.025204455 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.0311      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 391         |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | 1.94        |\n",
            "|    reward             | -0.32805324 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.0285      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 398         |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35.1       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | -3.9        |\n",
            "|    reward             | 0.022656728 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.0228      |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2021-10-04 to  2022-01-04\n",
            "A2C Sharpe Ratio:  -0.02491633302472802\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'gae_lambda': 0.5, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_126_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    fps             | 78       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 26       |\n",
            "|    total_timesteps | 2048     |\n",
            "| train/             |          |\n",
            "|    reward          | 8.154867 |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013101538 |\n",
            "|    clip_fraction        | 0.175       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.0367     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.71        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0228     |\n",
            "|    reward               | -8.168363   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 10.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01648186  |\n",
            "|    clip_fraction        | 0.18        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.0001     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 32.1        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0116     |\n",
            "|    reward               | -0.03745833 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 87          |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 102         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01842643  |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.8       |\n",
            "|    explained_variance   | -0.00935    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.333      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0216     |\n",
            "|    reward               | -0.50812477 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.75        |\n",
            "-----------------------------------------\n",
            "day: 4132, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 136411.98\n",
            "total_reward: -863588.02\n",
            "total_cost: 250671.62\n",
            "total_trades: 59480\n",
            "Sharpe: 0.179\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 128         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018942812 |\n",
            "|    clip_fraction        | 0.244       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.9       |\n",
            "|    explained_variance   | -8.73       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.324      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.013      |\n",
            "|    reward               | 0.009284378 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.0699      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 79           |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 155          |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.020701567  |\n",
            "|    clip_fraction        | 0.246        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.9        |\n",
            "|    explained_variance   | -0.00795     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.356       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.0193      |\n",
            "|    reward               | 0.0026228668 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 4.69         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 182         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01743339  |\n",
            "|    clip_fraction        | 0.212       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | -13.7       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.33       |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0166     |\n",
            "|    reward               | 0.055277936 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.00239     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 78           |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 208          |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0154483775 |\n",
            "|    clip_fraction        | 0.203        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33          |\n",
            "|    explained_variance   | 0.0302       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.326       |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.0152      |\n",
            "|    reward               | 0.024001846  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 4.12         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 233         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017756326 |\n",
            "|    clip_fraction        | 0.217       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.1       |\n",
            "|    explained_variance   | -0.167      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.338      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.01       |\n",
            "|    reward               | 0.03188828  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.0117      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 258         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01711688  |\n",
            "|    clip_fraction        | 0.219       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.1       |\n",
            "|    explained_variance   | 0.061       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.356      |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0144     |\n",
            "|    reward               | 0.025296437 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.17        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 284         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021614444 |\n",
            "|    clip_fraction        | 0.244       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | -1.28       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.333      |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00973    |\n",
            "|    reward               | 0.09796656  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.0012      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 311         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.02012723  |\n",
            "|    clip_fraction        | 0.222       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.3       |\n",
            "|    explained_variance   | 0.0725      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.333      |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0174     |\n",
            "|    reward               | -0.11002167 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.09        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 337         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022805607 |\n",
            "|    clip_fraction        | 0.255       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | -0.177      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.306      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00991    |\n",
            "|    reward               | 0.077530056 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.096       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 363         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018291485 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | 0.0654      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.319      |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0157     |\n",
            "|    reward               | -0.10324069 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 4.15        |\n",
            "-----------------------------------------\n",
            "day: 4132, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 204049.39\n",
            "total_reward: -795950.61\n",
            "total_cost: 294552.39\n",
            "total_trades: 59935\n",
            "Sharpe: 0.206\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 389         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014614755 |\n",
            "|    clip_fraction        | 0.202       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.5       |\n",
            "|    explained_variance   | -0.061      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.332      |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00539    |\n",
            "|    reward               | -0.06673583 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.0289      |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2021-10-04 to  2022-01-04\n",
            "PPO Sharpe Ratio:  -0.3637201521444795\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_126_1\n",
            "day: 4132, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1887248.09\n",
            "total_reward: 887248.09\n",
            "total_cost: 1072.51\n",
            "total_trades: 45454\n",
            "Sharpe: 0.520\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 60         |\n",
            "|    time_elapsed    | 274        |\n",
            "|    total_timesteps | 16532      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -0.0829    |\n",
            "|    critic_loss     | 52.3       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 12399      |\n",
            "|    reward          | -2.5437124 |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 8          |\n",
            "|    fps             | 57         |\n",
            "|    time_elapsed    | 578        |\n",
            "|    total_timesteps | 33064      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -0.0486    |\n",
            "|    critic_loss     | 2.49       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 28931      |\n",
            "|    reward          | -2.5437124 |\n",
            "-----------------------------------\n",
            "======DDPG Validation from:  2021-10-04 to  2022-01-04\n",
            "======Best Model Retraining from:  2005-01-01 to  2022-01-04\n",
            "======Trading from:  2022-01-04 to  2022-04-06\n",
            "============================================\n",
            "turbulence_threshold:  120.32525595826708\n",
            "======Model training from:  2005-01-01 to  2022-01-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'use_rms_prop': False, 'gae_lambda': 0.5, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_189_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 59          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 8           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.6       |\n",
            "|    explained_variance | 0.0649      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | 17.9        |\n",
            "|    reward             | -0.25341693 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.905       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 67        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 14        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.6     |\n",
            "|    explained_variance | 0.0497    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | 54        |\n",
            "|    reward             | 1.3423641 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 11        |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 20         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | -71.5      |\n",
            "|    reward             | -1.0642452 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 11.5       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 70         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 28         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.6      |\n",
            "|    explained_variance | -0.0319    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -37.3      |\n",
            "|    reward             | -2.3369462 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 4.91       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 70        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 35        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -39.3     |\n",
            "|    reward             | 3.6232505 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 13.2      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 40         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 12.7       |\n",
            "|    reward             | -3.8022969 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 6.11       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 48       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | -22.7    |\n",
            "|    reward             | 3.64851  |\n",
            "|    std                | 0.998    |\n",
            "|    value_loss         | 73.5     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 71       |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 56       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.5    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -185     |\n",
            "|    reward             | 7.271604 |\n",
            "|    std                | 0.996    |\n",
            "|    value_loss         | 201      |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 900          |\n",
            "|    time_elapsed       | 61           |\n",
            "|    total_timesteps    | 4500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -32.6        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 899          |\n",
            "|    policy_loss        | -3.01        |\n",
            "|    reward             | -0.028943421 |\n",
            "|    std                | 0.998        |\n",
            "|    value_loss         | 0.0161       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 67          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.6       |\n",
            "|    explained_variance | 0.0493      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -6.27       |\n",
            "|    reward             | 0.027673155 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.142       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 76          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.7       |\n",
            "|    explained_variance | 0.0118      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -4.8        |\n",
            "|    reward             | -0.20771118 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.0255      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 82          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -1.91       |\n",
            "|    reward             | -0.25524557 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.0453      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 87          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 7.45        |\n",
            "|    reward             | -0.23333667 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.104       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 96         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.8      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 3.3        |\n",
            "|    reward             | 0.06549592 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.0279     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 103       |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | 7.8       |\n",
            "|    reward             | 0.0983422 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.0738    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 108        |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.9      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 13.1       |\n",
            "|    reward             | -0.5967774 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.596      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 116         |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | 3.05        |\n",
            "|    reward             | 0.013311936 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.012       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 123        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -3.4       |\n",
            "|    reward             | 0.07445844 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0157     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 129          |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | -7.57        |\n",
            "|    reward             | -0.031388517 |\n",
            "|    std                | 1.03         |\n",
            "|    value_loss         | 0.0586       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 136         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.3       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -0.626      |\n",
            "|    reward             | -0.20544322 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0497      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 2100        |\n",
            "|    time_elapsed       | 144         |\n",
            "|    total_timesteps    | 10500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2099        |\n",
            "|    policy_loss        | -0.279      |\n",
            "|    reward             | -0.45334944 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.085       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 150         |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 2.74        |\n",
            "|    reward             | 0.123380765 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.146       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2300        |\n",
            "|    time_elapsed       | 156         |\n",
            "|    total_timesteps    | 11500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.5       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2299        |\n",
            "|    policy_loss        | 16          |\n",
            "|    reward             | -0.71457535 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.356       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 164        |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.5      |\n",
            "|    explained_variance | -3.58e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | 11.4       |\n",
            "|    reward             | 0.10760832 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 2.45       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 170       |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -29.3     |\n",
            "|    reward             | 1.7373002 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 1.88      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 2600      |\n",
            "|    time_elapsed       | 176       |\n",
            "|    total_timesteps    | 13000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2599      |\n",
            "|    policy_loss        | 1.49      |\n",
            "|    reward             | 0.2063686 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.014     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 184       |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | -9.24     |\n",
            "|    reward             | 0.5425867 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.239     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 191         |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.7       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | 21.5        |\n",
            "|    reward             | -0.03154554 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.16        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 197         |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.7       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | 13.4        |\n",
            "|    reward             | -0.19267298 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.349       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3000       |\n",
            "|    time_elapsed       | 204        |\n",
            "|    total_timesteps    | 15000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2999       |\n",
            "|    policy_loss        | -14.7      |\n",
            "|    reward             | 0.71789604 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.352      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 212        |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.7      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | -7.49      |\n",
            "|    reward             | -0.2979797 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.275      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 217         |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | 2.51        |\n",
            "|    reward             | -0.29364222 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.798       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 224       |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 66.8      |\n",
            "|    reward             | 0.7933405 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 6.04      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 72           |\n",
            "|    iterations         | 3400         |\n",
            "|    time_elapsed       | 233          |\n",
            "|    total_timesteps    | 17000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.7        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3399         |\n",
            "|    policy_loss        | 2.27         |\n",
            "|    reward             | -0.056315884 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.0685       |\n",
            "----------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 3500     |\n",
            "|    time_elapsed       | 238      |\n",
            "|    total_timesteps    | 17500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -33.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3499     |\n",
            "|    policy_loss        | -11.1    |\n",
            "|    reward             | 0.673989 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.231    |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 244        |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | -1.6       |\n",
            "|    reward             | -0.4239493 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.196      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3700       |\n",
            "|    time_elapsed       | 253        |\n",
            "|    total_timesteps    | 18500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3699       |\n",
            "|    policy_loss        | 6.55       |\n",
            "|    reward             | -0.2294519 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.721      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 259        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | -15.2      |\n",
            "|    reward             | 0.55426496 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.885      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3900       |\n",
            "|    time_elapsed       | 264        |\n",
            "|    total_timesteps    | 19500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3899       |\n",
            "|    policy_loss        | -0.926     |\n",
            "|    reward             | -1.6434005 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.247      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 273       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 11.9      |\n",
            "|    reward             | 1.1855661 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 3.53      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 4100      |\n",
            "|    time_elapsed       | 280       |\n",
            "|    total_timesteps    | 20500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4099      |\n",
            "|    policy_loss        | -1.55     |\n",
            "|    reward             | 1.0622708 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 7.25      |\n",
            "-------------------------------------\n",
            "day: 4195, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 8647075.81\n",
            "total_reward: 7647075.81\n",
            "total_cost: 1972.11\n",
            "total_trades: 54151\n",
            "Sharpe: 0.737\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 285         |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -29.1       |\n",
            "|    reward             | 0.001268674 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.834       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 293        |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | -0.418     |\n",
            "|    reward             | 0.13708454 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.00771    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4400        |\n",
            "|    time_elapsed       | 300         |\n",
            "|    total_timesteps    | 22000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4399        |\n",
            "|    policy_loss        | 1.55        |\n",
            "|    reward             | -0.14804763 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.0101      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 306         |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 13.8        |\n",
            "|    reward             | -0.44971266 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.219       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 312       |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | -8.11     |\n",
            "|    reward             | 0.3573134 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.0806    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 321         |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | -19.8       |\n",
            "|    reward             | -0.43568486 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.704       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 4800      |\n",
            "|    time_elapsed       | 327       |\n",
            "|    total_timesteps    | 24000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4799      |\n",
            "|    policy_loss        | -4.65     |\n",
            "|    reward             | 0.5514634 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.126     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4900       |\n",
            "|    time_elapsed       | 332        |\n",
            "|    total_timesteps    | 24500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4899       |\n",
            "|    policy_loss        | 35         |\n",
            "|    reward             | -0.8604306 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 3.66       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 5000     |\n",
            "|    time_elapsed       | 341      |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -34.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4999     |\n",
            "|    policy_loss        | -226     |\n",
            "|    reward             | 3.449718 |\n",
            "|    std                | 1.07     |\n",
            "|    value_loss         | 247      |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 5100        |\n",
            "|    time_elapsed       | 347         |\n",
            "|    total_timesteps    | 25500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.3       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5099        |\n",
            "|    policy_loss        | -0.206      |\n",
            "|    reward             | -0.22838955 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0291      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 353         |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | 9.95        |\n",
            "|    reward             | 0.097644605 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.097       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 361        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | -0.217     |\n",
            "|    reward             | 0.11521581 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.0553     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 368        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -8.08      |\n",
            "|    reward             | 0.29053706 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.072      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 374        |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | 2.7        |\n",
            "|    reward             | 0.54061383 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.224      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 381        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | -0.0105    |\n",
            "|    reward             | 0.61929905 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.053      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 389        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | 16.3       |\n",
            "|    reward             | -0.8712787 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.305      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 5800        |\n",
            "|    time_elapsed       | 395         |\n",
            "|    total_timesteps    | 29000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5799        |\n",
            "|    policy_loss        | 2.1         |\n",
            "|    reward             | -0.24067852 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.362       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 5900         |\n",
            "|    time_elapsed       | 401          |\n",
            "|    total_timesteps    | 29500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5899         |\n",
            "|    policy_loss        | 2.36         |\n",
            "|    reward             | -0.005183777 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.00493      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 410         |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | 0.313       |\n",
            "|    reward             | 0.013942411 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.000296    |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2022-01-04 to  2022-04-06\n",
            "A2C Sharpe Ratio:  -0.08288141978059434\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'gae_lambda': 0.5, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_189_1\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 80        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 25        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 7.7266393 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 80          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014109278 |\n",
            "|    clip_fraction        | 0.219       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.0144     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.91        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0224     |\n",
            "|    reward               | -5.021268   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 12.6        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 80          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 76          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01501884  |\n",
            "|    clip_fraction        | 0.186       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.8       |\n",
            "|    explained_variance   | -0.00228    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 20.1        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0139     |\n",
            "|    reward               | 0.004787103 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 33.9        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 79           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 102          |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.017925914  |\n",
            "|    clip_fraction        | 0.221        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.9        |\n",
            "|    explained_variance   | -0.00986     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.241        |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0167      |\n",
            "|    reward               | -0.007097373 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 8.49         |\n",
            "------------------------------------------\n",
            "day: 4195, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 22498.79\n",
            "total_reward: -977501.21\n",
            "total_cost: 76710.78\n",
            "total_trades: 56886\n",
            "Sharpe: -0.034\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 129         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016120918 |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | -9.83       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.344      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00926    |\n",
            "|    reward               | 0.04231898  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.00325     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 156         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017813183 |\n",
            "|    clip_fraction        | 0.209       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | -0.0372     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.336      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0197     |\n",
            "|    reward               | 0.01823132  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.82        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 181         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018428799 |\n",
            "|    clip_fraction        | 0.227       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | -0.626      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.343      |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    reward               | 0.27560323  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.00465     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 206         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019737577 |\n",
            "|    clip_fraction        | 0.245       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | 0.0044      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.348      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0169     |\n",
            "|    reward               | 0.17848718  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.43        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 231         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016963324 |\n",
            "|    clip_fraction        | 0.228       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.1       |\n",
            "|    explained_variance   | -0.124      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.322      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0127     |\n",
            "|    reward               | 0.08942795  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.0287      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 79           |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 258          |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.018886426  |\n",
            "|    clip_fraction        | 0.23         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.1        |\n",
            "|    explained_variance   | 0.0362       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.353       |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.0193      |\n",
            "|    reward               | 0.0063826847 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 4.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 79           |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 284          |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.017547965  |\n",
            "|    clip_fraction        | 0.206        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.2        |\n",
            "|    explained_variance   | -0.155       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.33        |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.0045      |\n",
            "|    reward               | -0.060593665 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.00504      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 311         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.02118311  |\n",
            "|    clip_fraction        | 0.225       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | 0.052       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.324      |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    reward               | 0.030360557 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.03        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 78           |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 337          |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.018830068  |\n",
            "|    clip_fraction        | 0.217        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.3        |\n",
            "|    explained_variance   | -0.0908      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.32        |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.00756     |\n",
            "|    reward               | -0.045281373 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0402       |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 79           |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 362          |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.017872859  |\n",
            "|    clip_fraction        | 0.214        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.3        |\n",
            "|    explained_variance   | 0.0581       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.333       |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.0158      |\n",
            "|    reward               | -0.002169372 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 4.29         |\n",
            "------------------------------------------\n",
            "day: 4195, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 21839.14\n",
            "total_reward: -978160.86\n",
            "total_cost: 79246.34\n",
            "total_trades: 57188\n",
            "Sharpe: -0.070\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 387         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014727926 |\n",
            "|    clip_fraction        | 0.192       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | -0.785      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.331      |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00849    |\n",
            "|    reward               | 0.08693178  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.002       |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-01-04 to  2022-04-06\n",
            "PPO Sharpe Ratio:  -0.093006545397313\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_189_1\n",
            "day: 4195, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 291426.71\n",
            "total_reward: -708573.29\n",
            "total_cost: 1000.95\n",
            "total_trades: 46148\n",
            "Sharpe: 0.327\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 59         |\n",
            "|    time_elapsed    | 279        |\n",
            "|    total_timesteps | 16784      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -0.056     |\n",
            "|    critic_loss     | 32.3       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 12588      |\n",
            "|    reward          | 0.28934327 |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 8          |\n",
            "|    fps             | 57         |\n",
            "|    time_elapsed    | 584        |\n",
            "|    total_timesteps | 33568      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | -0.000168  |\n",
            "|    critic_loss     | 1.45       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 29372      |\n",
            "|    reward          | 0.28934327 |\n",
            "-----------------------------------\n",
            "======DDPG Validation from:  2022-01-04 to  2022-04-06\n",
            "======Best Model Retraining from:  2005-01-01 to  2022-04-06\n",
            "======Trading from:  2022-04-06 to  2022-07-07\n",
            "============================================\n",
            "turbulence_threshold:  120.32525595826708\n",
            "======Model training from:  2005-01-01 to  2022-04-06\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'use_rms_prop': False, 'gae_lambda': 0.5, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_252_1\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 91          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 5           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.6       |\n",
            "|    explained_variance | -0.0472     |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | 24.9        |\n",
            "|    reward             | -0.65211123 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 1.92        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | -0.0129   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -11.9     |\n",
            "|    reward             | 1.3002951 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.39      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 30.8      |\n",
            "|    reward             | -1.421139 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 14.3      |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 26       |\n",
            "|    total_timesteps    | 2000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.7    |\n",
            "|    explained_variance | -0.00842 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | -10.1    |\n",
            "|    reward             | 0.451967 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 4.82     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 500        |\n",
            "|    time_elapsed       | 32         |\n",
            "|    total_timesteps    | 2500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 499        |\n",
            "|    policy_loss        | 20.1       |\n",
            "|    reward             | -3.1646876 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 8.35       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 40        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -25.2     |\n",
            "|    reward             | -4.952772 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 17.3      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 700        |\n",
            "|    time_elapsed       | 46         |\n",
            "|    total_timesteps    | 3500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | -0.00203   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 699        |\n",
            "|    policy_loss        | 61.6       |\n",
            "|    reward             | -0.5638201 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 11         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -43.5     |\n",
            "|    reward             | 16.063559 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 18.6      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 900        |\n",
            "|    time_elapsed       | 60         |\n",
            "|    total_timesteps    | 4500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 899        |\n",
            "|    policy_loss        | 1.95       |\n",
            "|    reward             | 0.21239579 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 0.00515    |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 67         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -6.82      |\n",
            "|    reward             | 0.12937956 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.194      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 72          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | -2.1        |\n",
            "|    reward             | -0.05072769 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0241      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 3.18       |\n",
            "|    reward             | 0.30300444 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0159     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 87          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 1.71        |\n",
            "|    reward             | -0.32394984 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0238      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 93         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 28         |\n",
            "|    reward             | -1.7627957 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 1.37       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 99          |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 24          |\n",
            "|    reward             | 0.020155558 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 2.58        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 107       |\n",
            "|    total_timesteps    | 8000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.2     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | -14.6     |\n",
            "|    reward             | 2.6165125 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.42      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 113       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -38.8     |\n",
            "|    reward             | 4.2440567 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 2.45      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 119         |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 0.712       |\n",
            "|    reward             | 0.047790986 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.00102     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 127         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | 4.7         |\n",
            "|    reward             | 0.022277445 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.114       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 134         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 0.331       |\n",
            "|    reward             | 0.010748734 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.00294     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 2100        |\n",
            "|    time_elapsed       | 139         |\n",
            "|    total_timesteps    | 10500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.8       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2099        |\n",
            "|    policy_loss        | 1.76        |\n",
            "|    reward             | -0.03986921 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0141      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 2200         |\n",
            "|    time_elapsed       | 147          |\n",
            "|    total_timesteps    | 11000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2199         |\n",
            "|    policy_loss        | 2.78         |\n",
            "|    reward             | -0.030005917 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.0332       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2300        |\n",
            "|    time_elapsed       | 154         |\n",
            "|    total_timesteps    | 11500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2299        |\n",
            "|    policy_loss        | -0.165      |\n",
            "|    reward             | 0.022787718 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.0246      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 160         |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | 2.72        |\n",
            "|    reward             | -0.12889056 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.0269      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 166        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | -1.33      |\n",
            "|    reward             | -0.5022585 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.0119     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 174         |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.3       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | -0.684      |\n",
            "|    reward             | 0.055884894 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0107      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 180         |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | -6.66       |\n",
            "|    reward             | -0.07096293 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0575      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 2800         |\n",
            "|    time_elapsed       | 186          |\n",
            "|    total_timesteps    | 14000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2799         |\n",
            "|    policy_loss        | 0.113        |\n",
            "|    reward             | -0.038486794 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.018        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 194        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | -2.8       |\n",
            "|    reward             | -0.3587465 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.0709     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 201         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.8       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 7.58        |\n",
            "|    reward             | 0.011045508 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.177       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 206         |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | -18.7       |\n",
            "|    reward             | -0.17118266 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.493       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 214        |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | 0.953      |\n",
            "|    reward             | 0.09630355 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 1.07       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 221        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | -16.5      |\n",
            "|    reward             | 0.82027936 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.598      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 227        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | 7.28       |\n",
            "|    reward             | -1.9809712 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.928      |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 3500         |\n",
            "|    time_elapsed       | 234          |\n",
            "|    total_timesteps    | 17500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.9        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3499         |\n",
            "|    policy_loss        | -2.66        |\n",
            "|    reward             | -0.065432206 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 0.0175       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 3600         |\n",
            "|    time_elapsed       | 242          |\n",
            "|    total_timesteps    | 18000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3599         |\n",
            "|    policy_loss        | -4.21        |\n",
            "|    reward             | -0.043512423 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 0.0177       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 247          |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | -5.73        |\n",
            "|    reward             | -0.106439635 |\n",
            "|    std                | 1.12         |\n",
            "|    value_loss         | 0.0652       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 253        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | 1.99       |\n",
            "|    reward             | 0.07755106 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.0665     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 261       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -35.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | -5.56     |\n",
            "|    reward             | 0.2120704 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 0.175     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 268        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | 6.4        |\n",
            "|    reward             | 0.01219198 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.064      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 273        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 1.19       |\n",
            "|    reward             | 0.29207182 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.0958     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 281         |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -37.4       |\n",
            "|    reward             | -0.17916931 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 1.62        |\n",
            "---------------------------------------\n",
            "day: 4258, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 932660.53\n",
            "total_reward: -67339.47\n",
            "total_cost: 15374.42\n",
            "total_trades: 43140\n",
            "Sharpe: 0.451\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 288         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | -3.68       |\n",
            "|    reward             | 0.017215347 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 0.013       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 4400         |\n",
            "|    time_elapsed       | 294          |\n",
            "|    total_timesteps    | 22000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4399         |\n",
            "|    policy_loss        | -1.89        |\n",
            "|    reward             | -0.094700344 |\n",
            "|    std                | 1.14         |\n",
            "|    value_loss         | 0.0164       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 301         |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35.8       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 7.03        |\n",
            "|    reward             | -0.20956019 |\n",
            "|    std                | 1.15        |\n",
            "|    value_loss         | 0.0599      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 4600         |\n",
            "|    time_elapsed       | 309          |\n",
            "|    total_timesteps    | 23000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35.8        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4599         |\n",
            "|    policy_loss        | -3.4         |\n",
            "|    reward             | -0.088202186 |\n",
            "|    std                | 1.15         |\n",
            "|    value_loss         | 0.0178       |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 314       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -35.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | 0.396     |\n",
            "|    reward             | 0.1102719 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.03      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 320        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4799       |\n",
            "|    policy_loss        | -1.42      |\n",
            "|    reward             | 0.07285194 |\n",
            "|    std                | 1.15       |\n",
            "|    value_loss         | 0.0473     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 328         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35.9       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 11.3        |\n",
            "|    reward             | 0.124419615 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.298       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 335       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | 0.4       |\n",
            "|    reward             | 2.0223644 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.276     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 340       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 22.6      |\n",
            "|    reward             | 1.0379288 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.535     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 348         |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36.1       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | -2.82       |\n",
            "|    reward             | -0.09358188 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.0138      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 355         |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | 5.49        |\n",
            "|    reward             | -0.47385758 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.245       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 360        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -36.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -1.43      |\n",
            "|    reward             | 0.39769867 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.0718     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 5500        |\n",
            "|    time_elapsed       | 368         |\n",
            "|    total_timesteps    | 27500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5499        |\n",
            "|    policy_loss        | 35.9        |\n",
            "|    reward             | -0.66922283 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 2.05        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 376       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | 9.99      |\n",
            "|    reward             | 1.3643748 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 3.88      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 381         |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | 12.8        |\n",
            "|    reward             | 0.013865435 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.297       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 387       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 7.8       |\n",
            "|    reward             | 1.0790455 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 1.22      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 5900      |\n",
            "|    time_elapsed       | 396       |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5899      |\n",
            "|    policy_loss        | 13        |\n",
            "|    reward             | 0.7003695 |\n",
            "|    std                | 1.18      |\n",
            "|    value_loss         | 3.82      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 402         |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | 1.66        |\n",
            "|    reward             | -0.08673756 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 0.306       |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2022-04-06 to  2022-07-07\n",
            "A2C Sharpe Ratio:  -0.08357490447798964\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'gae_lambda': 0.5, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_252_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    fps             | 81       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 25       |\n",
            "|    total_timesteps | 2048     |\n",
            "| train/             |          |\n",
            "|    reward          | 6.789974 |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 52          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013982379 |\n",
            "|    clip_fraction        | 0.157       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.6       |\n",
            "|    explained_variance   | -0.0283     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 2.91        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0238     |\n",
            "|    reward               | -5.59304    |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 8.28        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 80          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017780054 |\n",
            "|    clip_fraction        | 0.177       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.000853   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 27.5        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0122     |\n",
            "|    reward               | 0.1309272   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 60.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 106         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014986847 |\n",
            "|    clip_fraction        | 0.179       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.00909    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 16.1        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0146     |\n",
            "|    reward               | 0.005610075 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 20.7        |\n",
            "-----------------------------------------\n",
            "day: 4258, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 242968.35\n",
            "total_reward: -757031.65\n",
            "total_cost: 614826.04\n",
            "total_trades: 65063\n",
            "Sharpe: 0.257\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 132         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021399263 |\n",
            "|    clip_fraction        | 0.248       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.8       |\n",
            "|    explained_variance   | -0.283      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.269      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0116     |\n",
            "|    reward               | 0.06111563  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.184       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 159         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015789943 |\n",
            "|    clip_fraction        | 0.239       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.8       |\n",
            "|    explained_variance   | 0.00891     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.324      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    reward               | 0.026080215 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 4.43        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 187         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021004513 |\n",
            "|    clip_fraction        | 0.216       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.9       |\n",
            "|    explained_variance   | -4.2        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.334      |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00935    |\n",
            "|    reward               | -0.23518856 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.00994     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 75          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 216         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022169748 |\n",
            "|    clip_fraction        | 0.238       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.9       |\n",
            "|    explained_variance   | -0.0451     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.234      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0149     |\n",
            "|    reward               | -1.1126422  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 3.28        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 75          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 243         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019018799 |\n",
            "|    clip_fraction        | 0.207       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | -0.0719     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.185      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.008      |\n",
            "|    reward               | 0.105546534 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.395       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 269         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019706931 |\n",
            "|    clip_fraction        | 0.241       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | 0.00728     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.0843     |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0137     |\n",
            "|    reward               | 0.017597537 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.72        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 75          |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 296         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020587523 |\n",
            "|    clip_fraction        | 0.221       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | -0.323      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.298      |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00448    |\n",
            "|    reward               | 0.008051389 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.064       |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 75           |\n",
            "|    iterations           | 12           |\n",
            "|    time_elapsed         | 326          |\n",
            "|    total_timesteps      | 24576        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.01939699   |\n",
            "|    clip_fraction        | 0.233        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.3        |\n",
            "|    explained_variance   | 0.0278       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.316       |\n",
            "|    n_updates            | 110          |\n",
            "|    policy_gradient_loss | -0.0131      |\n",
            "|    reward               | -0.015373765 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 4.23         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 75          |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 352         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017865112 |\n",
            "|    clip_fraction        | 0.212       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | -0.127      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.282      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.00922    |\n",
            "|    reward               | 0.40113336  |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.135       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 75          |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 379         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017806701 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | 0.0365      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.287      |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0117     |\n",
            "|    reward               | -0.09404322 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.06        |\n",
            "-----------------------------------------\n",
            "day: 4258, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 634060.41\n",
            "total_reward: -365939.59\n",
            "total_cost: 855583.19\n",
            "total_trades: 67302\n",
            "Sharpe: 0.307\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 75           |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 405          |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.017100126  |\n",
            "|    clip_fraction        | 0.209        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.4        |\n",
            "|    explained_variance   | -0.106       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.291       |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.00907     |\n",
            "|    reward               | -0.011206085 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.166        |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2022-04-06 to  2022-07-07\n",
            "PPO Sharpe Ratio:  -0.061758462064130215\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_252_1\n",
            "day: 4258, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1005404.55\n",
            "total_reward: 5404.55\n",
            "total_cost: 999.00\n",
            "total_trades: 63869\n",
            "Sharpe: 0.372\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 58        |\n",
            "|    time_elapsed    | 289       |\n",
            "|    total_timesteps | 17036     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -0.0912   |\n",
            "|    critic_loss     | 114       |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 12777     |\n",
            "|    reward          | 1.0456908 |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 56        |\n",
            "|    time_elapsed    | 603       |\n",
            "|    total_timesteps | 34072     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -0.00994  |\n",
            "|    critic_loss     | 2.27      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 29813     |\n",
            "|    reward          | 1.0456908 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2022-04-06 to  2022-07-07\n",
            "======Best Model Retraining from:  2005-01-01 to  2022-07-07\n",
            "======Trading from:  2022-07-07 to  2022-10-10\n",
            "============================================\n",
            "turbulence_threshold:  120.32525595826708\n",
            "======Model training from:  2005-01-01 to  2022-07-07\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007, 'use_rms_prop': False, 'gae_lambda': 0.5, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_315_1\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 88        |\n",
            "|    iterations         | 100       |\n",
            "|    time_elapsed       | 5         |\n",
            "|    total_timesteps    | 500       |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 99        |\n",
            "|    policy_loss        | 7.18      |\n",
            "|    reward             | -1.231488 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 0.349     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.6     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -15.7     |\n",
            "|    reward             | 3.2253816 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 21.7      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 71         |\n",
            "|    iterations         | 300        |\n",
            "|    time_elapsed       | 21         |\n",
            "|    total_timesteps    | 1500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 299        |\n",
            "|    policy_loss        | 3.75       |\n",
            "|    reward             | -10.515456 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 12.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 26         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -54.7      |\n",
            "|    reward             | -3.3833406 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 5.27       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | -0.000985 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -117      |\n",
            "|    reward             | 4.7888327 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 205       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 41         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.8      |\n",
            "|    explained_variance | 0.00492    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 162        |\n",
            "|    reward             | -14.756081 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 192        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 191       |\n",
            "|    reward             | 50.653732 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 269       |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 53       |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.8    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | -642     |\n",
            "|    reward             | 16.3528  |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 1.92e+03 |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 62        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.8     |\n",
            "|    explained_variance | -0.192    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | 3.86      |\n",
            "|    reward             | 0.1037293 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.0245    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 68         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.9      |\n",
            "|    explained_variance | -11.1      |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | -22.6      |\n",
            "|    reward             | 0.18140455 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.61       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 1100         |\n",
            "|    time_elapsed       | 74           |\n",
            "|    total_timesteps    | 5500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -32.9        |\n",
            "|    explained_variance | -0.0113      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1099         |\n",
            "|    policy_loss        | 4.45         |\n",
            "|    reward             | -0.011081489 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.0997       |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 82        |\n",
            "|    total_timesteps    | 6000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.9     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | -37.4     |\n",
            "|    reward             | 0.388587  |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 1.79      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 89          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.9       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 6.26        |\n",
            "|    reward             | -0.46084607 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.315       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 94        |\n",
            "|    total_timesteps    | 7000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -19.7     |\n",
            "|    reward             | -0.588928 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.769     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 1500       |\n",
            "|    time_elapsed       | 102        |\n",
            "|    total_timesteps    | 7500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1499       |\n",
            "|    policy_loss        | 9.44       |\n",
            "|    reward             | 0.38555962 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 1.72       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 110        |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.9      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | -6.2       |\n",
            "|    reward             | 0.90049076 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.589      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 115       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.9     |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -20.4     |\n",
            "|    reward             | 2.009121  |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 6.14      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 122       |\n",
            "|    total_timesteps    | 9000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.9     |\n",
            "|    explained_variance | -0.00279  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | -44.3     |\n",
            "|    reward             | 3.9201784 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 7.42      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 131       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -109      |\n",
            "|    reward             | 0.2641978 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 11.9      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 136       |\n",
            "|    total_timesteps    | 10000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -8.38     |\n",
            "|    reward             | -2.368903 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 10.5      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 142       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.9     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 5.46      |\n",
            "|    reward             | 1.1744264 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 0.117     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 72       |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 151      |\n",
            "|    total_timesteps    | 11000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.9    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | -62.3    |\n",
            "|    reward             | 3.637089 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 17.9     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 157       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | -48.7     |\n",
            "|    reward             | 4.3846836 |\n",
            "|    std                | 1.01      |\n",
            "|    value_loss         | 11.7      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 163         |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | 5.39        |\n",
            "|    reward             | -0.96557266 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 23.5        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 171        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | 116        |\n",
            "|    reward             | -2.4912071 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 58.6       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 178         |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.8       |\n",
            "|    explained_variance | -0.163      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | -7.93       |\n",
            "|    reward             | 0.058275618 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0573      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 183         |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | -0.44       |\n",
            "|    reward             | -0.21671686 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0215      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2800       |\n",
            "|    time_elapsed       | 191        |\n",
            "|    total_timesteps    | 14000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2799       |\n",
            "|    policy_loss        | -1.27      |\n",
            "|    reward             | -0.0438954 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0037     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 199        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 7.64       |\n",
            "|    reward             | 0.46106675 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.148      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 204       |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | -18.7     |\n",
            "|    reward             | 0.1163171 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.18      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3100      |\n",
            "|    time_elapsed       | 211       |\n",
            "|    total_timesteps    | 15500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3099      |\n",
            "|    policy_loss        | 11        |\n",
            "|    reward             | 1.3819245 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.434     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 220        |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33        |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | -5.33      |\n",
            "|    reward             | 0.72514653 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.122      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 225       |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33       |\n",
            "|    explained_variance | -2.38e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 13.6      |\n",
            "|    reward             | -6.222612 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 1.11      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 231         |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.1       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | -64.1       |\n",
            "|    reward             | -0.16523503 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 9.82        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 3500       |\n",
            "|    time_elapsed       | 240        |\n",
            "|    total_timesteps    | 17500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3499       |\n",
            "|    policy_loss        | -3.7       |\n",
            "|    reward             | 0.25578055 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.0188     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 246         |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.3       |\n",
            "|    explained_variance | -2.38e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | -2.77       |\n",
            "|    reward             | -0.13779865 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.00981     |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 3700     |\n",
            "|    time_elapsed       | 252      |\n",
            "|    total_timesteps    | 18500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -33.3    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3699     |\n",
            "|    policy_loss        | -1.18    |\n",
            "|    reward             | 0.054382 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 0.00487  |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 260        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | 1.72       |\n",
            "|    reward             | 0.47049376 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.0736     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 267         |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | 4.03        |\n",
            "|    reward             | 0.091931306 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.0501      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4000       |\n",
            "|    time_elapsed       | 272        |\n",
            "|    total_timesteps    | 20000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3999       |\n",
            "|    policy_loss        | -0.299     |\n",
            "|    reward             | 0.18576829 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.137      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 280         |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | 0.772       |\n",
            "|    reward             | 0.038358845 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.123       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 288         |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -0.898      |\n",
            "|    reward             | 0.075719155 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.0366      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4300        |\n",
            "|    time_elapsed       | 293         |\n",
            "|    total_timesteps    | 21500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4299        |\n",
            "|    policy_loss        | -28.4       |\n",
            "|    reward             | -0.79768175 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 2.1         |\n",
            "---------------------------------------\n",
            "day: 4321, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 631892.21\n",
            "total_reward: -368107.79\n",
            "total_cost: 1391.17\n",
            "total_trades: 59673\n",
            "Sharpe: 0.352\n",
            "=================================\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 73       |\n",
            "|    iterations         | 4400     |\n",
            "|    time_elapsed       | 301      |\n",
            "|    total_timesteps    | 22000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -33.7    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 4399     |\n",
            "|    policy_loss        | -3.25    |\n",
            "|    reward             | 0.222429 |\n",
            "|    std                | 1.05     |\n",
            "|    value_loss         | 0.0539   |\n",
            "------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 72           |\n",
            "|    iterations         | 4500         |\n",
            "|    time_elapsed       | 309          |\n",
            "|    total_timesteps    | 22500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.8        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4499         |\n",
            "|    policy_loss        | 3.57         |\n",
            "|    reward             | -0.034812633 |\n",
            "|    std                | 1.05         |\n",
            "|    value_loss         | 0.0286       |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 314       |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | -5.31     |\n",
            "|    reward             | 0.2217052 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.064     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 321        |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | 2.9        |\n",
            "|    reward             | 0.25574848 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.0234     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 72           |\n",
            "|    iterations         | 4800         |\n",
            "|    time_elapsed       | 329          |\n",
            "|    total_timesteps    | 24000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34          |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4799         |\n",
            "|    policy_loss        | -0.274       |\n",
            "|    reward             | -0.010247554 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.022        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 4900       |\n",
            "|    time_elapsed       | 335        |\n",
            "|    total_timesteps    | 24500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4899       |\n",
            "|    policy_loss        | -2.94      |\n",
            "|    reward             | 0.14675692 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.0206     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 341        |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | 4.66       |\n",
            "|    reward             | 0.05664527 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 0.0766     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 350       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | 17        |\n",
            "|    reward             | 0.3443851 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.683     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 356       |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.1     |\n",
            "|    explained_variance | 0.00765   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5199      |\n",
            "|    policy_loss        | 2.19      |\n",
            "|    reward             | 0.1990793 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.221     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 362         |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | 9.32        |\n",
            "|    reward             | -0.09453133 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.781       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 370        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.1      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | 8.3        |\n",
            "|    reward             | 0.77290493 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 4.38       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 5500      |\n",
            "|    time_elapsed       | 377       |\n",
            "|    total_timesteps    | 27500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5499      |\n",
            "|    policy_loss        | -29.7     |\n",
            "|    reward             | 1.2763234 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 2.24      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 383        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | 22.9       |\n",
            "|    reward             | 0.14722355 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 2.21       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 5700      |\n",
            "|    time_elapsed       | 391       |\n",
            "|    total_timesteps    | 28500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.2     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5699      |\n",
            "|    policy_loss        | -10.6     |\n",
            "|    reward             | -3.983309 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 0.879     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 72         |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 398        |\n",
            "|    total_timesteps    | 29000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.1      |\n",
            "|    explained_variance | 1.79e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | 40.1       |\n",
            "|    reward             | -6.0689344 |\n",
            "|    std                | 1.07       |\n",
            "|    value_loss         | 11         |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 72        |\n",
            "|    iterations         | 5900      |\n",
            "|    time_elapsed       | 404       |\n",
            "|    total_timesteps    | 29500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5899      |\n",
            "|    policy_loss        | -137      |\n",
            "|    reward             | 2.1072922 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 29.3      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 72           |\n",
            "|    iterations         | 6000         |\n",
            "|    time_elapsed       | 411          |\n",
            "|    total_timesteps    | 30000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.2        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5999         |\n",
            "|    policy_loss        | 86.4         |\n",
            "|    reward             | -0.064872764 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 61.1         |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2022-07-07 to  2022-10-10\n",
            "A2C Sharpe Ratio:  0.06909620221761968\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128, 'gae_lambda': 0.5, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_315_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    fps             | 75       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 27       |\n",
            "|    total_timesteps | 2048     |\n",
            "| train/             |          |\n",
            "|    reward          | 3.147825 |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 75          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 54          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013984504 |\n",
            "|    clip_fraction        | 0.194       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.6       |\n",
            "|    explained_variance   | -0.0575     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.208       |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0269     |\n",
            "|    reward               | -0.79927975 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 3.47        |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 76            |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 80            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.0183972     |\n",
            "|    clip_fraction        | 0.22          |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -32.7         |\n",
            "|    explained_variance   | -0.0051       |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | 2.02          |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -0.021        |\n",
            "|    reward               | -0.0061787143 |\n",
            "|    std                  | 1             |\n",
            "|    value_loss           | 5.04          |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 105         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014222236 |\n",
            "|    clip_fraction        | 0.185       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.00871    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.032      |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0115     |\n",
            "|    reward               | 0.010158665 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 5.41        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 76           |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 133          |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.014956067  |\n",
            "|    clip_fraction        | 0.196        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.7        |\n",
            "|    explained_variance   | -0.803       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.349       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.019       |\n",
            "|    reward               | -0.108517334 |\n",
            "|    std                  | 0.999        |\n",
            "|    value_loss           | 0.017        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 161         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017913897 |\n",
            "|    clip_fraction        | 0.227       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | 0.0254      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.272      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0171     |\n",
            "|    reward               | 0.032159142 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 4.09        |\n",
            "-----------------------------------------\n",
            "day: 4321, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 86680.91\n",
            "total_reward: -913319.09\n",
            "total_cost: 242059.49\n",
            "total_trades: 63180\n",
            "Sharpe: 0.002\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 188         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017327927 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.8       |\n",
            "|    explained_variance   | -0.358      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.314      |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.0151     |\n",
            "|    reward               | 0.004908325 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.0112      |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 76           |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 214          |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.02196481   |\n",
            "|    clip_fraction        | 0.229        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.9        |\n",
            "|    explained_variance   | 0.0505       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.335       |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.0198      |\n",
            "|    reward               | 0.0039847367 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 4.32         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 240         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016395664 |\n",
            "|    clip_fraction        | 0.205       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | -0.724      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.379      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0124     |\n",
            "|    reward               | 0.006560592 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.00264     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 268         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020969622 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.1       |\n",
            "|    explained_variance   | 0.0794      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.348      |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0187     |\n",
            "|    reward               | 0.064646296 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 3.98        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 295         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022909489 |\n",
            "|    clip_fraction        | 0.236       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.1       |\n",
            "|    explained_variance   | -0.144      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.351      |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.0143     |\n",
            "|    reward               | -0.72296494 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.0203      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 322         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023263574 |\n",
            "|    clip_fraction        | 0.26        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.1       |\n",
            "|    explained_variance   | -0.184      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 23.1        |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0102     |\n",
            "|    reward               | 0.750509    |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 3.24        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 76         |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 348        |\n",
            "|    total_timesteps      | 26624      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01866424 |\n",
            "|    clip_fraction        | 0.224      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -33.2      |\n",
            "|    explained_variance   | -0.0462    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.154     |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.0129    |\n",
            "|    reward               | 0.06043465 |\n",
            "|    std                  | 1.03       |\n",
            "|    value_loss           | 0.429      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 76           |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 374          |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.02017009   |\n",
            "|    clip_fraction        | 0.241        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.3        |\n",
            "|    explained_variance   | 2.04e-05     |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0906      |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.0112      |\n",
            "|    reward               | -0.033823185 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 5.44         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 76            |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 402           |\n",
            "|    total_timesteps      | 30720         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.01791894    |\n",
            "|    clip_fraction        | 0.213         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -33.4         |\n",
            "|    explained_variance   | -1.91         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.361        |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -0.0109       |\n",
            "|    reward               | -0.0025188408 |\n",
            "|    std                  | 1.04          |\n",
            "|    value_loss           | 0.0035        |\n",
            "-------------------------------------------\n",
            "======PPO Validation from:  2022-07-07 to  2022-10-10\n",
            "PPO Sharpe Ratio:  0.04090524165695635\n",
            "======DDPG Training========\n",
            "{'buffer_size': 10000, 'learning_rate': 0.0005, 'batch_size': 64, 'gamma': 0.2}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_315_1\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    episodes        | 4        |\n",
            "|    fps             | 58       |\n",
            "|    time_elapsed    | 294      |\n",
            "|    total_timesteps | 17288    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -0.0689  |\n",
            "|    critic_loss     | 60.3     |\n",
            "|    learning_rate   | 0.0005   |\n",
            "|    n_updates       | 12966    |\n",
            "|    reward          | 2.168459 |\n",
            "---------------------------------\n",
            "day: 4321, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1009788.58\n",
            "total_reward: 9788.58\n",
            "total_cost: 999.00\n",
            "total_trades: 51853\n",
            "Sharpe: 0.367\n",
            "=================================\n",
            "======DDPG Validation from:  2022-07-07 to  2022-10-10\n",
            "======Best Model Retraining from:  2005-01-01 to  2022-10-10\n",
            "======Trading from:  2022-10-10 to  2023-01-09\n",
            "Ensemble Strategy took:  93.97543507814407  minutes\n"
          ]
        }
      ],
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                 PPO_model_kwargs,\n",
        "                                                 DDPG_model_kwargs,\n",
        "                                                 timesteps_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "-0qd8acMtj1f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "23a7d4bd-0a42-452b-8bb1-9685972008ee"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
              "0  126  2021-10-04  2022-01-04        A2C  -0.024916   -0.36372   -0.066869\n",
              "1  189  2022-01-04  2022-04-06       DDPG  -0.082881  -0.093007   -0.057806\n",
              "2  252  2022-04-06  2022-07-07       DDPG  -0.083575  -0.061758    0.038288\n",
              "3  315  2022-07-07  2022-10-10       DDPG   0.069096   0.040905    0.182442"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f423f5f0-36ef-4700-a013-f4be8e275aa7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.024916</td>\n",
              "      <td>-0.36372</td>\n",
              "      <td>-0.066869</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>2022-04-06</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.082881</td>\n",
              "      <td>-0.093007</td>\n",
              "      <td>-0.057806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2022-04-06</td>\n",
              "      <td>2022-07-07</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>-0.083575</td>\n",
              "      <td>-0.061758</td>\n",
              "      <td>0.038288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>315</td>\n",
              "      <td>2022-07-07</td>\n",
              "      <td>2022-10-10</td>\n",
              "      <td>DDPG</td>\n",
              "      <td>0.069096</td>\n",
              "      <td>0.040905</td>\n",
              "      <td>0.182442</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f423f5f0-36ef-4700-a013-f4be8e275aa7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f423f5f0-36ef-4700-a013-f4be8e275aa7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f423f5f0-36ef-4700-a013-f4be8e275aa7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest OurÂ Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "X4JKB--8tj1g"
      },
      "outputs": [],
      "source": [
        "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "q9mKF7GGtj1g",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "148e0589-d765-4772-e3d0-504fcdda3f25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharpe Ratio:  0.7923189994711206\n"
          ]
        }
      ],
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "df_account_value=pd.DataFrame()\n",
        "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
        "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "print('Sharpe Ratio: ',sharpe)\n",
        "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "oyosyW7_tj1g",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "36b6b359-00b3-44e8-f783-504be981d0d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   account_value        date  daily_return    datadate\n",
              "0   1.000000e+06  2022-01-04           NaN  2022-01-04\n",
              "1   1.035652e+06  2022-01-05      0.035652  2022-01-05\n",
              "2   1.048480e+06  2022-01-06      0.012386  2022-01-06\n",
              "3   1.038534e+06  2022-01-07     -0.009486  2022-01-07\n",
              "4   1.049344e+06  2022-01-10      0.010409  2022-01-10"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4488dff3-f19a-4df5-83e8-9fdd8b299513\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-01-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.035652e+06</td>\n",
              "      <td>2022-01-05</td>\n",
              "      <td>0.035652</td>\n",
              "      <td>2022-01-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.048480e+06</td>\n",
              "      <td>2022-01-06</td>\n",
              "      <td>0.012386</td>\n",
              "      <td>2022-01-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.038534e+06</td>\n",
              "      <td>2022-01-07</td>\n",
              "      <td>-0.009486</td>\n",
              "      <td>2022-01-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.049344e+06</td>\n",
              "      <td>2022-01-10</td>\n",
              "      <td>0.010409</td>\n",
              "      <td>2022-01-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4488dff3-f19a-4df5-83e8-9fdd8b299513')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4488dff3-f19a-4df5-83e8-9fdd8b299513 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4488dff3-f19a-4df5-83e8-9fdd8b299513');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "df_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "wLsRdw2Ctj1h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "80b8a35a-7edd-4cb1-a7a8-a33e7e315c4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "metadata": {},
          "execution_count": 52
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Nzkr9yv-AdV_",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "95b975fd-5e94-475f-dc93-497567756e92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return          0.160068\n",
            "Cumulative returns     0.160068\n",
            "Annual volatility      0.218142\n",
            "Sharpe ratio           0.792319\n",
            "Calmar ratio           1.183781\n",
            "Stability              0.683461\n",
            "Max drawdown          -0.135217\n",
            "Omega ratio            1.146418\n",
            "Sortino ratio          1.158101\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.173585\n",
            "Daily value at risk   -0.026797\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "DiHhM1YkoCel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48a3e3d5-e039-4a69-e657-f100c3e788c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==============Get Baseline Stats===========\n",
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (251, 8)\n",
            "Annual return          0.008342\n",
            "Cumulative returns     0.008309\n",
            "Annual volatility      0.173584\n",
            "Sharpe ratio           0.134686\n",
            "Calmar ratio           0.051410\n",
            "Stability              0.185640\n",
            "Max drawdown          -0.162268\n",
            "Omega ratio            1.022609\n",
            "Sortino ratio          0.187640\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.052711\n",
            "Daily value at risk   -0.021777\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "df_dji_ = get_baseline(\n",
        "        ticker=\"^BSESN\", \n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(df_dji_, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "RhJ9whD75WTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55738099-05e4-4688-848a-00594b8f11f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_dji:             date           dji\n",
            "0    2022-01-04  1.000000e+06\n",
            "1    2022-01-05  1.006135e+06\n",
            "2    2022-01-06  9.957550e+05\n",
            "3    2022-01-07  9.981408e+05\n",
            "4    2022-01-10  1.009017e+06\n",
            "..          ...           ...\n",
            "247  2023-01-02  1.021917e+06\n",
            "248  2023-01-03  1.024029e+06\n",
            "249  2023-01-04  1.013391e+06\n",
            "250  2023-01-05  1.008309e+06\n",
            "251  2023-01-06           NaN\n",
            "\n",
            "[252 rows x 2 columns]\n",
            "df_dji:                       dji\n",
            "date                    \n",
            "2022-01-04  1.000000e+06\n",
            "2022-01-05  1.006135e+06\n",
            "2022-01-06  9.957550e+05\n",
            "2022-01-07  9.981408e+05\n",
            "2022-01-10  1.009017e+06\n",
            "...                  ...\n",
            "2023-01-02  1.021917e+06\n",
            "2023-01-03  1.024029e+06\n",
            "2023-01-04  1.013391e+06\n",
            "2023-01-05  1.008309e+06\n",
            "2023-01-06           NaN\n",
            "\n",
            "[252 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "df_dji = pd.DataFrame()\n",
        "df_dji['date'] = df_account_value['date']\n",
        "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji.csv\")\n",
        "df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji+.csv\")\n",
        "\n",
        "df_account_value.to_csv('df_account_value.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "HggausPRoCem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f91d733d-4f3e-4977-d8ee-c19af69f9275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df_result_ensemble.columns:  Index(['ensemble'], dtype='object')\n",
            "df_trade_date:         datadate\n",
            "0    2021-10-04\n",
            "1    2021-10-05\n",
            "2    2021-10-06\n",
            "3    2021-10-07\n",
            "4    2021-10-08\n",
            "..          ...\n",
            "367  2023-03-24\n",
            "368  2023-03-27\n",
            "369  2023-03-28\n",
            "370  2023-03-29\n",
            "371  2023-03-31\n",
            "\n",
            "[372 rows x 1 columns]\n",
            "df_result_ensemble:                  ensemble\n",
            "date                    \n",
            "2022-01-04  1.000000e+06\n",
            "2022-01-05  1.035652e+06\n",
            "2022-01-06  1.048480e+06\n",
            "2022-01-07  1.038534e+06\n",
            "2022-01-10  1.049344e+06\n",
            "...                  ...\n",
            "2023-01-02  1.150693e+06\n",
            "2023-01-03  1.160601e+06\n",
            "2023-01-04  1.147002e+06\n",
            "2023-01-05  1.157772e+06\n",
            "2023-01-06  1.160068e+06\n",
            "\n",
            "[252 rows x 1 columns]\n",
            "==============Compare to BSE===========\n",
            "result:                  ensemble           dji\n",
            "date                                  \n",
            "2022-01-04  1.000000e+06  1.000000e+06\n",
            "2022-01-05  1.035652e+06  1.006135e+06\n",
            "2022-01-06  1.048480e+06  9.957550e+05\n",
            "2022-01-07  1.038534e+06  9.981408e+05\n",
            "2022-01-10  1.049344e+06  1.009017e+06\n",
            "...                  ...           ...\n",
            "2023-01-02  1.150693e+06  1.021917e+06\n",
            "2023-01-03  1.160601e+06  1.024029e+06\n",
            "2023-01-04  1.147002e+06  1.013391e+06\n",
            "2023-01-05  1.157772e+06  1.008309e+06\n",
            "2023-01-06  1.160068e+06           NaN\n",
            "\n",
            "[252 rows x 2 columns]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "\n",
        "\n",
        "# print(\"==============Compare to DJIA===========\")\n",
        "# %matplotlib inline\n",
        "# # S&P 500: ^GSPC\n",
        "# # Dow Jones Index: ^DJI\n",
        "# # NASDAQ 100: ^NDX\n",
        "# backtest_plot(df_account_value, \n",
        "#               baseline_ticker = '^DJI', \n",
        "#               baseline_start = df_account_value.loc[0,'date'],\n",
        "#               baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "df.to_csv(\"df.csv\")\n",
        "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\n",
        "df_result_ensemble = df_result_ensemble.set_index('date')\n",
        "\n",
        "print(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n",
        "\n",
        "# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\n",
        "print(\"df_trade_date: \", df_trade_date)\n",
        "# df_result_ensemble['date'] = df_trade_date['datadate']\n",
        "# df_result_ensemble['account_value'] = df_account_value['account_value']\n",
        "df_result_ensemble.to_csv(\"df_result_ensemble.csv\")\n",
        "print(\"df_result_ensemble: \", df_result_ensemble)\n",
        "print(\"==============Compare to BSE===========\")\n",
        "result = pd.DataFrame()\n",
        "# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n",
        "# result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
        "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\n",
        "print(\"result: \", result)\n",
        "result.to_csv(\"result.csv\")\n",
        "result.columns = ['ensemble', 'BSE']\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "plt.figure();\n",
        "result.plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "96anaYsiO9zP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "1cdd001a-83c0-4c2f-e77e-73f325c4f829"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "MessageError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m   )\n\u001b[0;32m--> 177\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    102\u001b[0m     ):\n\u001b[1;32m    103\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hz-je2g_PF_N"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/\" \"/content/drive/MyDrive/RL_India\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bavcsby7SRFI"
      },
      "outputs": [],
      "source": [
        "!du -h /content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBQx4bVQFi-a"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
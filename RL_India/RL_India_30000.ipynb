{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lb9q2_QZgdNk"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AI4Finance-Foundation/FinRL-Tutorials/blob/master/2-Advance/FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gXaoZs2lh1hi"
      },
      "source": [
        "# Deep Reinforcement Learning for Stock Trading from Scratch: Multiple Stock Trading Using Ensemble Strategy\n",
        "\n",
        "Tutorials to use OpenAI DRL to trade multiple stocks using ensemble strategy in one Jupyter Notebook | Presented at ICAIF 2020\n",
        "\n",
        "* This notebook is the reimplementation of our paper: Deep Reinforcement Learning for Automated Stock Trading: An Ensemble Strategy, using FinRL.\n",
        "* Check out medium blog for detailed explanations: https://medium.com/@ai4finance/deep-reinforcement-learning-for-automated-stock-trading-f1dad0126a02\n",
        "* Please report any issues to our Github: https://github.com/AI4Finance-LLC/FinRL-Library/issues\n",
        "* **Pytorch Version** \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGunVt8oLCVS"
      },
      "source": [
        "# Content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOzAKQ-SLGX6"
      },
      "source": [
        "* [1. Problem Definition](#0)\n",
        "* [2. Getting Started - Load Python packages](#1)\n",
        "    * [2.1. Install Packages](#1.1)    \n",
        "    * [2.2. Check Additional Packages](#1.2)\n",
        "    * [2.3. Import Packages](#1.3)\n",
        "    * [2.4. Create Folders](#1.4)\n",
        "* [3. Download Data](#2)\n",
        "* [4. Preprocess Data](#3)        \n",
        "    * [4.1. Technical Indicators](#3.1)\n",
        "    * [4.2. Perform Feature Engineering](#3.2)\n",
        "* [5.Build Environment](#4)  \n",
        "    * [5.1. Training & Trade Data Split](#4.1)\n",
        "    * [5.2. User-defined Environment](#4.2)   \n",
        "    * [5.3. Initialize Environment](#4.3)    \n",
        "* [6.Implement DRL Algorithms](#5)  \n",
        "* [7.Backtesting Performance](#6)  \n",
        "    * [7.1. BackTestStats](#6.1)\n",
        "    * [7.2. BackTestPlot](#6.2)   \n",
        "    * [7.3. Baseline Stats](#6.3)   \n",
        "    * [7.3. Compare to Stock Market Index](#6.4)             "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sApkDlD9LIZv"
      },
      "source": [
        "<a id='0'></a>\n",
        "# Part 1. Problem Definition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjLD2TZSLKZ-"
      },
      "source": [
        "This problem is to design an automated trading solution for single stock trading. We model the stock trading process as a Markov Decision Process (MDP). We then formulate our trading goal as a maximization problem.\n",
        "\n",
        "The algorithm is trained using Deep Reinforcement Learning (DRL) algorithms and the components of the reinforcement learning environment are:\n",
        "\n",
        "\n",
        "* Action: The action space describes the allowed actions that the agent interacts with the\n",
        "environment. Normally, a ∈ A includes three actions: a ∈ {−1, 0, 1}, where −1, 0, 1 represent\n",
        "selling, holding, and buying one stock. Also, an action can be carried upon multiple shares. We use\n",
        "an action space {−k, ..., −1, 0, 1, ..., k}, where k denotes the number of shares. For example, \"Buy\n",
        "10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or −10, respectively\n",
        "\n",
        "* Reward function: r(s, a, s′) is the incentive mechanism for an agent to learn a better action. The change of the portfolio value when action a is taken at state s and arriving at new state s',  i.e., r(s, a, s′) = v′ − v, where v′ and v represent the portfolio\n",
        "values at state s′ and s, respectively\n",
        "\n",
        "* State: The state space describes the observations that the agent receives from the environment. Just as a human trader needs to analyze various information before executing a trade, so\n",
        "our trading agent observes many different features to better learn in an interactive environment.\n",
        "\n",
        "* Environment: Dow 30 consituents\n",
        "\n",
        "\n",
        "The data of the single stock that we will be using for this case study is obtained from Yahoo Finance API. The data contains Open-High-Low-Close price and volume.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ffsre789LY08"
      },
      "source": [
        "<a id='1'></a>\n",
        "# Part 2. Getting Started- Load Python Packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uy5_PTmOh1hj"
      },
      "source": [
        "<a id='1.1'></a>\n",
        "## 2.1. Install all the packages through FinRL library\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mPT0ipYE28wL",
        "outputId": "9cef74c1-0ddd-4afb-e615-1e1a37378162"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wrds\n",
            "  Downloading wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Collecting psycopg2-binary\n",
            "  Downloading psycopg2_binary-2.9.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m35.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from wrds) (1.10.1)\n",
            "Collecting sqlalchemy<2\n",
            "  Downloading SQLAlchemy-1.4.47-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from wrds) (1.5.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from wrds) (1.22.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy<2->wrds) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->wrds) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->wrds) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas->wrds) (1.16.0)\n",
            "Installing collected packages: sqlalchemy, psycopg2-binary, wrds\n",
            "  Attempting uninstall: sqlalchemy\n",
            "    Found existing installation: SQLAlchemy 2.0.9\n",
            "    Uninstalling SQLAlchemy-2.0.9:\n",
            "      Successfully uninstalled SQLAlchemy-2.0.9\n",
            "Successfully installed psycopg2-binary-2.9.6 sqlalchemy-1.4.47 wrds-3.1.6\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting swig\n",
            "  Downloading swig-4.1.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: swig\n",
            "Successfully installed swig-4.1.1\n",
            "⏬ Downloading https://github.com/jaimergp/miniforge/releases/latest/download/Mambaforge-colab-Linux-x86_64.sh...\n",
            "📦 Installing...\n",
            "📌 Adjusting configuration...\n",
            "🩹 Patching environment...\n",
            "⏲ Done in 0:00:14\n",
            "🔁 Restarting kernel...\n",
            "Selecting previously unselected package libgl1-mesa-glx:amd64.\n",
            "(Reading database ... 122349 files and directories currently installed.)\n",
            "Preparing to unpack .../libgl1-mesa-glx_21.2.6-0ubuntu0.1~20.04.2_amd64.deb ...\n",
            "Unpacking libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../swig4.0_4.0.1-5build1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.1-5build1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_4.0.1-5build1_all.deb ...\n",
            "Unpacking swig (4.0.1-5build1) ...\n",
            "Setting up libgl1-mesa-glx:amd64 (21.2.6-0ubuntu0.1~20.04.2) ...\n",
            "Setting up swig4.0 (4.0.1-5build1) ...\n",
            "Setting up swig (4.0.1-5build1) ...\n",
            "Processing triggers for man-db (2.9.1-1) ...\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/AI4Finance-Foundation/FinRL.git\n",
            "  Cloning https://github.com/AI4Finance-Foundation/FinRL.git to /tmp/pip-req-build-8t6_vacn\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/FinRL.git /tmp/pip-req-build-8t6_vacn\n",
            "  Resolved https://github.com/AI4Finance-Foundation/FinRL.git to commit 8a75a4bbb28f86f88ee2d4bd9a8c19cce444badb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyfolio@ git+https://github.com/quantopian/pyfolio.git#egg=pyfolio-0.9.2\n",
            "  Cloning https://github.com/quantopian/pyfolio.git to /tmp/pip-install-jll7bazx/pyfolio_b963a8a6cc3a4ff6910dce6df7c4fffb\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/quantopian/pyfolio.git /tmp/pip-install-jll7bazx/pyfolio_b963a8a6cc3a4ff6910dce6df7c4fffb\n",
            "  Resolved https://github.com/quantopian/pyfolio.git to commit 4b901f6d73aa02ceb6d04b7d83502e5c6f2e81aa\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting elegantrl@ git+https://github.com/AI4Finance-Foundation/ElegantRL.git#egg=elegantrl\n",
            "  Cloning https://github.com/AI4Finance-Foundation/ElegantRL.git to /tmp/pip-install-jll7bazx/elegantrl_deb8e32902394d69ae1de405e39b2a09\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/AI4Finance-Foundation/ElegantRL.git /tmp/pip-install-jll7bazx/elegantrl_deb8e32902394d69ae1de405e39b2a09\n",
            "  Resolved https://github.com/AI4Finance-Foundation/ElegantRL.git to commit bf5ecff658f46c9c8c3e09a02e72be7383bd201a\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting numpy>=1.17.3\n",
            "  Downloading numpy-1.24.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alpaca_trade_api>=2.1.0\n",
            "  Downloading alpaca_trade_api-3.0.0-py3-none-any.whl (33 kB)\n",
            "Collecting stable-baselines3<2.0.0,>=1.6.2\n",
            "  Downloading stable_baselines3-1.8.0-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.5/174.5 kB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=1.1.5\n",
            "  Downloading pandas-2.0.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m88.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lz4\n",
            "  Downloading lz4-4.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ccxt>=1.66.32\n",
            "  Downloading ccxt-3.0.66-py2.py3-none-any.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting exchange_calendars==3.6.3\n",
            "  Downloading exchange_calendars-3.6.3.tar.gz (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.8/152.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ray[default,tune]>=2.0.0\n",
            "  Downloading ray-2.3.1-cp39-cp39-manylinux2014_x86_64.whl (58.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.6/58.6 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stockstats>=0.4.0\n",
            "  Downloading stockstats-0.5.2-py2.py3-none-any.whl (20 kB)\n",
            "Collecting gym>=0.17\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting importlib-metadata==4.13.0\n",
            "  Downloading importlib_metadata-4.13.0-py3-none-any.whl (23 kB)\n",
            "Collecting gputil\n",
            "  Downloading GPUtil-1.4.0.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yfinance\n",
            "  Downloading yfinance-0.2.17-py2.py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.3/60.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jqdatasdk\n",
            "  Downloading jqdatasdk-1.8.11-py3-none-any.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 kB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn>=0.21.0\n",
            "  Downloading scikit_learn-1.2.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m106.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib\n",
            "  Downloading matplotlib-3.7.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m116.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrds>=3.1.6\n",
            "  Using cached wrds-3.1.6-py3-none-any.whl (12 kB)\n",
            "Collecting pyluach\n",
            "  Downloading pyluach-2.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting python-dateutil\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: toolz in /usr/local/lib/python3.9/site-packages (from exchange_calendars==3.6.3->finrl==0.3.5) (0.12.0)\n",
            "Collecting korean_lunar_calendar\n",
            "  Downloading korean_lunar_calendar-0.3.1-py3-none-any.whl (9.0 kB)\n",
            "Collecting zipp>=0.5\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: urllib3<2,>1.24 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (1.26.15)\n",
            "Collecting aiohttp==3.8.1\n",
            "  Downloading aiohttp-3.8.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>2 in /usr/local/lib/python3.9/site-packages (from alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.28.2)\n",
            "Collecting PyYAML==6.0\n",
            "  Downloading PyYAML-6.0-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (661 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m661.8/661.8 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting deprecation==2.1.0\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting websockets<11,>=9.0\n",
            "  Downloading websockets-10.4-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.5/106.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websocket-client<2,>=0.56.0\n",
            "  Downloading websocket_client-1.5.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting msgpack==1.0.3\n",
            "  Downloading msgpack-1.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (322 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.2/322.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting attrs>=17.3.0\n",
            "  Downloading attrs-22.2.0-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/site-packages (from aiohttp==3.8.1->alpaca_trade_api>=2.1.0->finrl==0.3.5) (2.1.1)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging\n",
            "  Downloading packaging-23.1-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2018.1.18 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (2022.12.7)\n",
            "Collecting aiodns>=1.1.1\n",
            "  Downloading aiodns-3.0.0-py3-none-any.whl (5.0 kB)\n",
            "Requirement already satisfied: cryptography>=2.6.1 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (39.0.2)\n",
            "Requirement already satisfied: setuptools>=60.9.0 in /usr/local/lib/python3.9/site-packages (from ccxt>=1.66.32->finrl==0.3.5) (65.6.3)\n",
            "Collecting gym-notices>=0.0.4\n",
            "  Downloading gym_notices-0.0.8-py3-none-any.whl (3.0 kB)\n",
            "Collecting cloudpickle>=1.2.0\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting tzdata>=2022.1\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m39.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf!=3.19.5,>=3.15.3\n",
            "  Downloading protobuf-4.22.3-cp37-abi3-manylinux2014_x86_64.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.11.0-py3-none-any.whl (10.0 kB)\n",
            "Collecting jsonschema\n",
            "  Downloading jsonschema-4.17.3-py3-none-any.whl (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.4/90.4 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio>=1.32.0\n",
            "  Downloading grpcio-1.53.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting virtualenv>=20.0.24\n",
            "  Downloading virtualenv-20.21.0-py3-none-any.whl (8.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m73.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click>=7.0\n",
            "  Downloading click-8.1.3-py3-none-any.whl (96 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.6/96.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open\n",
            "  Downloading smart_open-6.3.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.8/56.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prometheus-client>=0.7.1\n",
            "  Downloading prometheus_client-0.16.0-py3-none-any.whl (122 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.5/122.5 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gpustat>=1.0.0\n",
            "  Downloading gpustat-1.1.tar.gz (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pydantic\n",
            "  Downloading pydantic-1.10.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp-cors\n",
            "  Downloading aiohttp_cors-0.7.0-py3-none-any.whl (27 kB)\n",
            "Collecting opencensus\n",
            "  Downloading opencensus-0.11.2-py2.py3-none-any.whl (128 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/128.2 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorful\n",
            "  Downloading colorful-0.5.5-py2.py3-none-any.whl (201 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.4/201.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting py-spy>=0.2.0\n",
            "  Downloading py_spy-0.3.14-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting scipy>=1.3.2\n",
            "  Downloading scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.1.1\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch>=1.11\n",
            "  Downloading torch-2.0.0-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gym>=0.17\n",
            "  Downloading gym-0.21.0.tar.gz (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf!=3.19.5,>=3.15.3\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sqlalchemy<2\n",
            "  Using cached SQLAlchemy-1.4.47-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.6 MB)\n",
            "Collecting psycopg2-binary\n",
            "  Using cached psycopg2_binary-2.9.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
            "Collecting six\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting thriftpy2>=0.3.9\n",
            "  Downloading thriftpy2-0.4.16.tar.gz (643 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m643.4/643.4 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pymysql>=0.7.6\n",
            "  Downloading PyMySQL-1.0.3-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyparsing>=2.3.1\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m12.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1.0.1\n",
            "  Downloading contourpy-1.0.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.7/299.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow>=6.2.0\n",
            "  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cycler>=0.10\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0\n",
            "  Downloading fonttools-4.39.3-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1\n",
            "  Downloading kiwisolver-1.4.4-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources>=3.2.0\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting ipython>=3.2.3\n",
            "  Downloading ipython-8.12.0-py3-none-any.whl (796 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.4/796.4 kB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting seaborn>=0.7.1\n",
            "  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m293.3/293.3 kB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting empyrical>=0.5.0\n",
            "  Downloading empyrical-0.5.5.tar.gz (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/52.8 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting frozendict>=2.3.4\n",
            "  Downloading frozendict-2.3.7-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.3/114.3 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multitasking>=0.0.7\n",
            "  Downloading multitasking-0.0.11-py3-none-any.whl (8.5 kB)\n",
            "Collecting beautifulsoup4>=4.11.1\n",
            "  Downloading beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting appdirs>=1.4.4\n",
            "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting lxml>=4.9.1\n",
            "  Downloading lxml-4.9.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (7.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.1/7.1 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting html5lib>=1.1\n",
            "  Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.2/112.2 kB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycares>=4.0.0\n",
            "  Downloading pycares-4.3.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting soupsieve>1.2\n",
            "  Downloading soupsieve-2.4-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.9/site-packages (from cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (1.15.1)\n",
            "Collecting pandas-datareader>=0.2\n",
            "  Downloading pandas_datareader-0.10.0-py3-none-any.whl (109 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.5/109.5 kB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-ml-py>=11.450.129\n",
            "  Downloading nvidia_ml_py-11.525.112-py3-none-any.whl (35 kB)\n",
            "Collecting psutil>=5.6.0\n",
            "  Downloading psutil-5.9.4-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (280 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting blessed>=1.17.1\n",
            "  Downloading blessed-1.20.0-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting webencodings\n",
            "  Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
            "Collecting traitlets>=5\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting decorator\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting jedi>=0.16\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments>=2.4.0\n",
            "  Downloading Pygments-2.15.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30\n",
            "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect>4.3\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting backcall\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting stack-data\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting typing-extensions\n",
            "  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
            "Collecting pickleshare\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests<3,>2->alpaca_trade_api>=2.1.0->finrl==0.3.5) (3.4)\n",
            "Collecting greenlet!=0.4.17\n",
            "  Downloading greenlet-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (610 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m610.9/610.9 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ply<4.0,>=3.4\n",
            "  Downloading ply-3.11-py2.py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.11.1-py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m96.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m79.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel in /usr/local/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch>=1.11->stable-baselines3<2.0.0,>=1.6.2->finrl==0.3.5) (0.38.4)\n",
            "Collecting cmake\n",
            "  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.0/24.0 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lit\n",
            "  Downloading lit-16.0.1.tar.gz (137 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting distlib<1,>=0.3.6\n",
            "  Downloading distlib-0.3.6-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.5/468.5 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting platformdirs<4,>=2.4\n",
            "  Downloading platformdirs-3.2.0-py3-none-any.whl (14 kB)\n",
            "Collecting gym[box2d]\n",
            "  Downloading gym-0.26.1.tar.gz (719 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.9/719.9 kB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.26.0.tar.gz (710 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m710.3/710.3 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.25.2.tar.gz (734 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m734.5/734.5 kB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.25.1.tar.gz (732 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m732.2/732.2 kB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.25.0.tar.gz (720 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m720.4/720.4 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.24.1.tar.gz (696 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m696.4/696.4 kB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.24.0.tar.gz (694 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m694.4/694.4 kB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.23.1.tar.gz (626 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.2/626.2 kB\u001b[0m \u001b[31m41.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.23.0.tar.gz (624 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 kB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading gym-0.22.0.tar.gz (631 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m631.1/631.1 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting box2d-py==2.3.5\n",
            "  Downloading box2d-py-2.3.5.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.4/374.4 kB\u001b[0m \u001b[31m39.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pyglet>=1.4.0\n",
            "  Downloading pyglet-2.0.5-py3-none-any.whl (831 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m831.3/831.3 kB\u001b[0m \u001b[31m64.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0\n",
            "  Downloading pyrsistent-0.19.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-api-core<3.0.0,>=1.0.0\n",
            "  Downloading google_api_core-2.11.0-py3-none-any.whl (120 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.3/120.3 kB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opencensus-context>=0.1.3\n",
            "  Downloading opencensus_context-0.1.3-py2.py3-none-any.whl (5.1 kB)\n",
            "Collecting wcwidth>=0.1.4\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=2.6.1->ccxt>=1.66.32->finrl==0.3.5) (2.21)\n",
            "Collecting googleapis-common-protos<2.0dev,>=1.56.2\n",
            "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth<3.0dev,>=2.14.1\n",
            "  Downloading google_auth-2.17.3-py2.py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.2/178.2 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting parso<0.9.0,>=0.8.0\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ptyprocess>=0.5\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Collecting executing>=1.2.0\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting pure-eval\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting asttokens>=2.1.0\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting mpmath>=0.19\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m54.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.3/155.3 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Downloading pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: finrl, exchange_calendars, gym, elegantrl, gputil, pyfolio, empyrical, gpustat, thriftpy2, box2d-py, lit\n",
            "  Building wheel for finrl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for finrl: filename=finrl-0.3.5-py3-none-any.whl size=4668722 sha256=b5d9990feddfce4dac1109677bd1616fcf78abb54bcf1b30c280638a7696b8d0\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_bdb72s8/wheels/ec/6a/08/c43694890a7c5a62c23af4b2a497bce5ee7edef607852cf53f\n",
            "  Building wheel for exchange_calendars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for exchange_calendars: filename=exchange_calendars-3.6.3-py3-none-any.whl size=182636 sha256=894685494a8614bdcf45d5fae49865b9da41176848947b122ee1e2f6a7889db4\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/02/f9/6c6eeb48a242879e357caf2813953fa8b6e26bd0110bd94226\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.21.0-py3-none-any.whl size=1616820 sha256=1bf46b61d1c74bf2dc11f4a9d42d3ddc300047b83217b43c7a7423b3391743c8\n",
            "  Stored in directory: /root/.cache/pip/wheels/b3/50/6c/0a82c1358b4da2dbd9c1bb17e0f89467db32812ab236dbf6d5\n",
            "  Building wheel for elegantrl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for elegantrl: filename=elegantrl-0.3.6-py3-none-any.whl size=195062 sha256=72622df0745126212c8f097d8ce8010345a03d4babbb45279ff31dab2efa9e76\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_bdb72s8/wheels/a3/c3/be/03eb1f20c8650f23ab13b823d93a297a917899f5d08b04b7b9\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gputil: filename=GPUtil-1.4.0-py3-none-any.whl size=7409 sha256=8b60afc2ad4ad7fec6cded4389e8f7058337e48e27f170efc4ee9bb942bca124\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/b5/24/fbb56595c286984f7315ee31821d6121e1b9828436021a88b3\n",
            "  Building wheel for pyfolio (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyfolio: filename=pyfolio-0.9.2+75.g4b901f6-py3-none-any.whl size=75773 sha256=6939b6d2cbadea683249388385197c4448b3d25e92f62827cd5383952eb10485\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_bdb72s8/wheels/da/0d/dd/aef7001cc1238aff04ec9eabfc002341f00c50deead3083855\n",
            "  Building wheel for empyrical (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for empyrical: filename=empyrical-0.5.5-py3-none-any.whl size=39776 sha256=810839e0a4a434759ff223be46e2bb3bbcf9bd8dee1a175c9e2225753ca3ec38\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/23/d1/a4ef8ff88dc9af7b0eeb1b6fd0d90c6057eaad5a2df25f4e3f\n",
            "  Building wheel for gpustat (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-1.1-py3-none-any.whl size=26298 sha256=fde3b531de4a950f6842de9bb259581b33be9a7c2a60c8b092899a54dd6d73be\n",
            "  Stored in directory: /root/.cache/pip/wheels/91/f0/b3/8566d6821307110981a5db015cbf8fd88697446f81e5f40a27\n",
            "  Building wheel for thriftpy2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for thriftpy2: filename=thriftpy2-0.4.16-cp39-cp39-linux_x86_64.whl size=529342 sha256=16f21a7021a798d82b201b32325743db8d3db5086f4f331eb24760cb98b9e8db\n",
            "  Stored in directory: /root/.cache/pip/wheels/88/a4/d5/907737b4c175aec82087b815fa93a8afea5c6c5a3e7bb748b9\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.5-cp39-cp39-linux_x86_64.whl size=494643 sha256=532b6ea9dc657f0105fb2a64b92da28634b1a452b231c554877a65afc5ef78b5\n",
            "  Stored in directory: /root/.cache/pip/wheels/a4/c2/c1/076651c394f05fe60990cd85616c2d95bc1619aa113f559d7d\n",
            "  Building wheel for lit (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lit: filename=lit-16.0.1-py3-none-any.whl size=88189 sha256=eba4c6e617e258b5b2d9a1695cbeee881c237d76b1116bd87684b25a4091391d\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/35/e6/2ba4f52d2763592eb8474f60e192f06e3d57be198526ef1048\n",
            "Successfully built finrl exchange_calendars gym elegantrl gputil pyfolio empyrical gpustat thriftpy2 box2d-py lit\n",
            "Installing collected packages: webencodings, wcwidth, pytz, pyglet, pyasn1, py-spy, pure-eval, ptyprocess, ply, pickleshare, opencensus-context, nvidia-ml-py, multitasking, msgpack, mpmath, lit, korean_lunar_calendar, gputil, executing, distlib, colorful, cmake, box2d-py, backcall, appdirs, zipp, websockets, websocket-client, tzdata, typing-extensions, traitlets, threadpoolctl, tabulate, sympy, soupsieve, smart-open, six, rsa, PyYAML, pyrsistent, pyparsing, pymysql, pyluach, pygments, pyasn1-modules, psycopg2-binary, psutil, protobuf, prompt-toolkit, prometheus-client, platformdirs, pillow, pexpect, parso, packaging, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, networkx, multidict, MarkupSafe, lz4, lxml, kiwisolver, joblib, grpcio, greenlet, frozenlist, frozendict, fonttools, filelock, decorator, cycler, cloudpickle, click, cachetools, attrs, async-timeout, yarl, virtualenv, thriftpy2, tensorboardX, sqlalchemy, scipy, python-dateutil, pydantic, pycares, nvidia-cusolver-cu11, nvidia-cudnn-cu11, matplotlib-inline, jsonschema, jinja2, jedi, importlib-resources, importlib-metadata, html5lib, gym, googleapis-common-protos, google-auth, deprecation, contourpy, blessed, beautifulsoup4, asttokens, aiosignal, stack-data, scikit-learn, ray, pandas, matplotlib, gpustat, google-api-core, aiohttp, aiodns, yfinance, wrds, stockstats, seaborn, pandas-datareader, opencensus, jqdatasdk, ipython, exchange_calendars, ccxt, alpaca_trade_api, aiohttp-cors, empyrical, pyfolio, triton, torch, stable-baselines3, elegantrl, finrl\n",
            "Successfully installed MarkupSafe-2.1.2 PyYAML-6.0 aiodns-3.0.0 aiohttp-3.8.1 aiohttp-cors-0.7.0 aiosignal-1.3.1 alpaca_trade_api-3.0.0 appdirs-1.4.4 asttokens-2.2.1 async-timeout-4.0.2 attrs-22.2.0 backcall-0.2.0 beautifulsoup4-4.12.2 blessed-1.20.0 box2d-py-2.3.5 cachetools-5.3.0 ccxt-3.0.66 click-8.1.3 cloudpickle-2.2.1 cmake-3.26.3 colorful-0.5.5 contourpy-1.0.7 cycler-0.11.0 decorator-5.1.1 deprecation-2.1.0 distlib-0.3.6 elegantrl-0.3.6 empyrical-0.5.5 exchange_calendars-3.6.3 executing-1.2.0 filelock-3.11.0 finrl-0.3.5 fonttools-4.39.3 frozendict-2.3.7 frozenlist-1.3.3 google-api-core-2.11.0 google-auth-2.17.3 googleapis-common-protos-1.59.0 gpustat-1.1 gputil-1.4.0 greenlet-2.0.2 grpcio-1.53.0 gym-0.21.0 html5lib-1.1 importlib-metadata-4.13.0 importlib-resources-5.12.0 ipython-8.12.0 jedi-0.18.2 jinja2-3.1.2 joblib-1.2.0 jqdatasdk-1.8.11 jsonschema-4.17.3 kiwisolver-1.4.4 korean_lunar_calendar-0.3.1 lit-16.0.1 lxml-4.9.2 lz4-4.3.2 matplotlib-3.7.1 matplotlib-inline-0.1.6 mpmath-1.3.0 msgpack-1.0.3 multidict-6.0.4 multitasking-0.0.11 networkx-3.1 numpy-1.24.2 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-ml-py-11.525.112 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 opencensus-0.11.2 opencensus-context-0.1.3 packaging-23.1 pandas-2.0.0 pandas-datareader-0.10.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.5.0 platformdirs-3.2.0 ply-3.11 prometheus-client-0.16.0 prompt-toolkit-3.0.38 protobuf-3.20.3 psutil-5.9.4 psycopg2-binary-2.9.6 ptyprocess-0.7.0 pure-eval-0.2.2 py-spy-0.3.14 pyasn1-0.4.8 pyasn1-modules-0.2.8 pycares-4.3.0 pydantic-1.10.7 pyfolio-0.9.2+75.g4b901f6 pyglet-2.0.5 pygments-2.15.0 pyluach-2.2.0 pymysql-1.0.3 pyparsing-3.0.9 pyrsistent-0.19.3 python-dateutil-2.8.2 pytz-2023.3 ray-2.3.1 rsa-4.9 scikit-learn-1.2.2 scipy-1.10.1 seaborn-0.12.2 six-1.16.0 smart-open-6.3.0 soupsieve-2.4 sqlalchemy-1.4.47 stable-baselines3-1.8.0 stack-data-0.6.2 stockstats-0.5.2 sympy-1.11.1 tabulate-0.9.0 tensorboardX-2.6 threadpoolctl-3.1.0 thriftpy2-0.4.16 torch-2.0.0 traitlets-5.9.0 triton-2.0.0 typing-extensions-4.5.0 tzdata-2023.3 virtualenv-20.21.0 wcwidth-0.2.6 webencodings-0.5.1 websocket-client-1.5.1 websockets-10.4 wrds-3.1.6 yarl-1.8.2 yfinance-0.2.17 zipp-3.15.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "google",
                  "importlib_resources",
                  "kiwisolver",
                  "matplotlib",
                  "matplotlib_inline",
                  "mpl_toolkits",
                  "pexpect",
                  "pickleshare",
                  "prompt_toolkit",
                  "psutil",
                  "six",
                  "wcwidth",
                  "zipp"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# ## install finrl library\n",
        "!pip install wrds\n",
        "!pip install swig\n",
        "!pip install -q condacolab\n",
        "import condacolab\n",
        "condacolab.install()\n",
        "!apt-get update -y -qq && apt-get install -y -qq cmake libopenmpi-dev python3-dev zlib1g-dev libgl1-mesa-glx swig\n",
        "!pip install git+https://github.com/AI4Finance-Foundation/FinRL.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlN1SUG8U16c",
        "outputId": "03b147df-072e-4912-e832-783b80716223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pandas==1.5.3 in /usr/local/lib/python3.9/site-packages (1.5.3)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (1.24.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (2023.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/site-packages (from pandas==1.5.3) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3) (1.16.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install pandas==1.5.3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "osBHhVysOEzi"
      },
      "source": [
        "\n",
        "<a id='1.2'></a>\n",
        "## 2.2. Check if the additional packages needed are present, if not install them. \n",
        "* Yahoo Finance API\n",
        "* pandas\n",
        "* numpy\n",
        "* matplotlib\n",
        "* stockstats\n",
        "* OpenAI gym\n",
        "* stable-baselines\n",
        "* tensorflow\n",
        "* pyfolio"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGv01K8Sh1hn"
      },
      "source": [
        "<a id='1.3'></a>\n",
        "## 2.3. Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "EeMK7Uentj1V"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "KeNEHDWSuaJh"
      },
      "outputs": [],
      "source": [
        "tickers = ['BAJAJ-AUTO.NS',\t\n",
        "'TITAN.NS',\t\n",
        "'TATASTEEL.NS',\t\n",
        "'NESTLEIND.NS',\t\n",
        "'BRITANNIA.NS',\t\n",
        "'TATACONSUM.NS',\n",
        "'CIPLA.NS',\t\n",
        "'ULTRACEMCO.NS',\t\n",
        "'RELIANCE.NS',\t\n",
        "'ITC.NS',\t\n",
        "'BHARTIARTL.NS',\t\n",
        "'MARUTI.NS',\t\n",
        "'ONGC.NS',\t\n",
        "'BAJFINANCE.NS',\t\n",
        "'COALINDIA.NS',\t\n",
        "'ICICIBANK.NS',\t\n",
        "'WIPRO.NS',\t\n",
        "'HINDALCO.NS',\t\n",
        "'HEROMOTOCO.NS',\t\n",
        "'ADANIENT.NS',\t\n",
        "'LT.NS',\t\n",
        "'KOTAKBANK.NS',\t\n",
        "'BAJAJFINSV.NS',\t\n",
        "'NTPC.NS',\t \n",
        "'TCS.NS',\t\n",
        "'APOLLOHOSP.NS',\t\n",
        "'HDFCLIFE.NS',\t\n",
        "'INDUSINDBK.NS',\t\n",
        "'DRREDDY.NS',\t\t\t\t\t\n",
        "'TECHM.NS']\t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "lPqeTTwoh1hn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# matplotlib.use('Agg')\n",
        "import datetime\n",
        "\n",
        "%matplotlib inline\n",
        "from finrl.config_tickers import DOW_30_TICKER\n",
        "from finrl.meta.preprocessor.yahoodownloader import YahooDownloader\n",
        "from finrl.meta.preprocessor.preprocessors import FeatureEngineer, data_split\n",
        "from finrl.meta.env_stock_trading.env_stocktrading import StockTradingEnv\n",
        "from finrl.agents.stablebaselines3.models import DRLAgent,DRLEnsembleAgent\n",
        "from finrl.plot import backtest_stats, backtest_plot, get_daily_return, get_baseline\n",
        "\n",
        "from pprint import pprint\n",
        "\n",
        "import sys\n",
        "sys.path.append(\"../FinRL-Library\")\n",
        "\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2owTj985RW4"
      },
      "source": [
        "<a id='1.4'></a>\n",
        "## 2.4. Create Folders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "w9A8CN5R5PuZ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from finrl.main import check_and_make_directories\n",
        "from finrl.config import (\n",
        "    DATA_SAVE_DIR,\n",
        "    TRAINED_MODEL_DIR,\n",
        "    TENSORBOARD_LOG_DIR,\n",
        "    RESULTS_DIR,\n",
        "    INDICATORS,\n",
        "    TRAIN_START_DATE,\n",
        "    TRAIN_END_DATE,\n",
        "    TEST_START_DATE,\n",
        "    TEST_END_DATE,\n",
        "    TRADE_START_DATE,\n",
        "    TRADE_END_DATE,\n",
        ")\n",
        "\n",
        "check_and_make_directories([DATA_SAVE_DIR, TRAINED_MODEL_DIR, TENSORBOARD_LOG_DIR, RESULTS_DIR])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A289rQWMh1hq"
      },
      "source": [
        "<a id='2'></a>\n",
        "# Part 3. Download Data\n",
        "Yahoo Finance is a website that provides stock data, financial news, financial reports, etc. All the data provided by Yahoo Finance is free.\n",
        "* FinRL uses a class **YahooDownloader** to fetch data from Yahoo Finance API\n",
        "* Call Limit: Using the Public API (without authentication), you are limited to 2,000 requests per hour per IP (or up to a total of 48,000 requests a day).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPeQ7iS-LoMm"
      },
      "source": [
        "\n",
        "\n",
        "-----\n",
        "class YahooDownloader:\n",
        "    Provides methods for retrieving daily stock data from\n",
        "    Yahoo Finance API\n",
        "\n",
        "    Attributes\n",
        "    ----------\n",
        "        start_date : str\n",
        "            start date of the data (modified from config.py)\n",
        "        end_date : str\n",
        "            end date of the data (modified from config.py)\n",
        "        ticker_list : list\n",
        "            a list of stock tickers (modified from config.py)\n",
        "\n",
        "    Methods\n",
        "    -------\n",
        "    fetch_data()\n",
        "        Fetches data from yahoo API\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzqRRTOX6aFu",
        "outputId": "ec37227e-1201-4712-b107-363a9be40b38"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['BAJAJ-AUTO.NS', 'TITAN.NS', 'TATASTEEL.NS', 'NESTLEIND.NS', 'BRITANNIA.NS', 'TATACONSUM.NS', 'CIPLA.NS', 'ULTRACEMCO.NS', 'RELIANCE.NS', 'ITC.NS', 'BHARTIARTL.NS', 'MARUTI.NS', 'ONGC.NS', 'BAJFINANCE.NS', 'COALINDIA.NS', 'ICICIBANK.NS', 'WIPRO.NS', 'HINDALCO.NS', 'HEROMOTOCO.NS', 'ADANIENT.NS', 'LT.NS', 'KOTAKBANK.NS', 'BAJAJFINSV.NS', 'NTPC.NS', 'TCS.NS', 'APOLLOHOSP.NS', 'HDFCLIFE.NS', 'INDUSINDBK.NS', 'DRREDDY.NS', 'TECHM.NS']\n"
          ]
        }
      ],
      "source": [
        "print(tickers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCKm4om-s9kE",
        "outputId": "2b2560f0-9eef-40b5-e6c4-fa13498a7d7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (130112, 8)\n"
          ]
        }
      ],
      "source": [
        "# TRAIN_START_DATE = '2009-04-01'\n",
        "# TRAIN_END_DATE = '2021-01-01'\n",
        "# TEST_START_DATE = '2021-01-01'\n",
        "# TEST_END_DATE = '2022-06-01'\n",
        "\n",
        "TRAIN_START_DATE = '2005-01-01'\n",
        "TRAIN_END_DATE = '2021-10-01'\n",
        "TEST_START_DATE = '2021-10-01'\n",
        "TEST_END_DATE = '2023-04-01'\n",
        "\n",
        "df = YahooDownloader(start_date = TRAIN_START_DATE,\n",
        "                     end_date = TEST_END_DATE,\n",
        "                     ticker_list = tickers).fetch_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "GiRuFOTOtj1Y",
        "outputId": "cbac556a-6ed8-4ec3-ea72-c85b6e48b85a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-5ea59462-4e1c-4778-8083-a9bd183b83e3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>5.962399</td>\n",
              "      <td>6.054364</td>\n",
              "      <td>5.901089</td>\n",
              "      <td>4.469341</td>\n",
              "      <td>6912918</td>\n",
              "      <td>ADANIENT.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>115.371017</td>\n",
              "      <td>164838</td>\n",
              "      <td>APOLLOHOSP.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>287.250000</td>\n",
              "      <td>289.950012</td>\n",
              "      <td>281.299988</td>\n",
              "      <td>190.725143</td>\n",
              "      <td>778286</td>\n",
              "      <td>BAJAJ-AUTO.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>1149.000000</td>\n",
              "      <td>1159.800049</td>\n",
              "      <td>1125.199951</td>\n",
              "      <td>1121.040283</td>\n",
              "      <td>389100</td>\n",
              "      <td>BAJAJFINSV.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>11.490891</td>\n",
              "      <td>11.703667</td>\n",
              "      <td>11.322807</td>\n",
              "      <td>9.849681</td>\n",
              "      <td>179573</td>\n",
              "      <td>BAJFINANCE.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5ea59462-4e1c-4778-8083-a9bd183b83e3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5ea59462-4e1c-4778-8083-a9bd183b83e3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5ea59462-4e1c-4778-8083-a9bd183b83e3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         date         open         high          low        close   volume  \\\n",
              "0  2005-01-03     5.962399     6.054364     5.901089     4.469341  6912918   \n",
              "1  2005-01-03   126.000000   131.000000   126.000000   115.371017   164838   \n",
              "2  2005-01-03   287.250000   289.950012   281.299988   190.725143   778286   \n",
              "3  2005-01-03  1149.000000  1159.800049  1125.199951  1121.040283   389100   \n",
              "4  2005-01-03    11.490891    11.703667    11.322807     9.849681   179573   \n",
              "\n",
              "             tic  day  \n",
              "0    ADANIENT.NS    0  \n",
              "1  APOLLOHOSP.NS    0  \n",
              "2  BAJAJ-AUTO.NS    0  \n",
              "3  BAJAJFINSV.NS    0  \n",
              "4  BAJFINANCE.NS    0  "
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DSw4ZEzVtj1Z",
        "outputId": "f71d0002-2eb2-4af1-8252-6c2205036765"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c6b903fc-4503-4003-9832-f465a1fd69b2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>130107</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>3189.949951</td>\n",
              "      <td>3213.000000</td>\n",
              "      <td>3152.000000</td>\n",
              "      <td>3205.899902</td>\n",
              "      <td>2382581</td>\n",
              "      <td>TCS.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130108</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>1095.000000</td>\n",
              "      <td>1106.000000</td>\n",
              "      <td>1091.449951</td>\n",
              "      <td>1101.849976</td>\n",
              "      <td>2281085</td>\n",
              "      <td>TECHM.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130109</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>2526.949951</td>\n",
              "      <td>2536.750000</td>\n",
              "      <td>2500.000000</td>\n",
              "      <td>2514.899902</td>\n",
              "      <td>848456</td>\n",
              "      <td>TITAN.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130110</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>7575.100098</td>\n",
              "      <td>7644.299805</td>\n",
              "      <td>7547.049805</td>\n",
              "      <td>7622.149902</td>\n",
              "      <td>378456</td>\n",
              "      <td>ULTRACEMCO.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130111</th>\n",
              "      <td>2023-03-31</td>\n",
              "      <td>363.350006</td>\n",
              "      <td>365.750000</td>\n",
              "      <td>361.299988</td>\n",
              "      <td>365.250000</td>\n",
              "      <td>3957106</td>\n",
              "      <td>WIPRO.NS</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c6b903fc-4503-4003-9832-f465a1fd69b2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c6b903fc-4503-4003-9832-f465a1fd69b2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c6b903fc-4503-4003-9832-f465a1fd69b2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              date         open         high          low        close  \\\n",
              "130107  2023-03-31  3189.949951  3213.000000  3152.000000  3205.899902   \n",
              "130108  2023-03-31  1095.000000  1106.000000  1091.449951  1101.849976   \n",
              "130109  2023-03-31  2526.949951  2536.750000  2500.000000  2514.899902   \n",
              "130110  2023-03-31  7575.100098  7644.299805  7547.049805  7622.149902   \n",
              "130111  2023-03-31   363.350006   365.750000   361.299988   365.250000   \n",
              "\n",
              "         volume            tic  day  \n",
              "130107  2382581         TCS.NS    4  \n",
              "130108  2281085       TECHM.NS    4  \n",
              "130109   848456       TITAN.NS    4  \n",
              "130110   378456  ULTRACEMCO.NS    4  \n",
              "130111  3957106       WIPRO.NS    4  "
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV3HrZHLh1hy",
        "outputId": "3d01235d-637f-4b08-e5fc-1bba885a9b5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(130112, 8)"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4hYkeaPiICHS",
        "outputId": "3c381cde-ec98-4626-d9e2-8bf7b0775628"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-45e03bbe-9b81-459f-9a32-fadc8ec62701\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>5.962399</td>\n",
              "      <td>6.054364</td>\n",
              "      <td>5.901089</td>\n",
              "      <td>4.469341</td>\n",
              "      <td>6912918</td>\n",
              "      <td>ADANIENT.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>131.000000</td>\n",
              "      <td>126.000000</td>\n",
              "      <td>115.371017</td>\n",
              "      <td>164838</td>\n",
              "      <td>APOLLOHOSP.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>287.250000</td>\n",
              "      <td>289.950012</td>\n",
              "      <td>281.299988</td>\n",
              "      <td>190.725143</td>\n",
              "      <td>778286</td>\n",
              "      <td>BAJAJ-AUTO.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>1149.000000</td>\n",
              "      <td>1159.800049</td>\n",
              "      <td>1125.199951</td>\n",
              "      <td>1121.040283</td>\n",
              "      <td>389100</td>\n",
              "      <td>BAJAJFINSV.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2005-01-03</td>\n",
              "      <td>11.490891</td>\n",
              "      <td>11.703667</td>\n",
              "      <td>11.322807</td>\n",
              "      <td>9.849681</td>\n",
              "      <td>179573</td>\n",
              "      <td>BAJFINANCE.NS</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-45e03bbe-9b81-459f-9a32-fadc8ec62701')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-45e03bbe-9b81-459f-9a32-fadc8ec62701 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-45e03bbe-9b81-459f-9a32-fadc8ec62701');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         date         open         high          low        close   volume  \\\n",
              "0  2005-01-03     5.962399     6.054364     5.901089     4.469341  6912918   \n",
              "1  2005-01-03   126.000000   131.000000   126.000000   115.371017   164838   \n",
              "2  2005-01-03   287.250000   289.950012   281.299988   190.725143   778286   \n",
              "3  2005-01-03  1149.000000  1159.800049  1125.199951  1121.040283   389100   \n",
              "4  2005-01-03    11.490891    11.703667    11.322807     9.849681   179573   \n",
              "\n",
              "             tic  day  \n",
              "0    ADANIENT.NS    0  \n",
              "1  APOLLOHOSP.NS    0  \n",
              "2  BAJAJ-AUTO.NS    0  \n",
              "3  BAJAJFINSV.NS    0  \n",
              "4  BAJFINANCE.NS    0  "
            ]
          },
          "execution_count": 80,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.sort_values(['date','tic']).head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2vryMsdNL9H",
        "outputId": "2cd67710-ac91-4805-ba70-a7215ab99506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(df.tic.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XcNyXa7RNPrF",
        "outputId": "74a7ce21-e99e-4632-8b39-8c6809127b5c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ADANIENT.NS      4505\n",
              "APOLLOHOSP.NS    4505\n",
              "WIPRO.NS         4505\n",
              "ULTRACEMCO.NS    4505\n",
              "TITAN.NS         4505\n",
              "TCS.NS           4505\n",
              "TATASTEEL.NS     4505\n",
              "TATACONSUM.NS    4505\n",
              "RELIANCE.NS      4505\n",
              "ONGC.NS          4505\n",
              "NTPC.NS          4505\n",
              "NESTLEIND.NS     4505\n",
              "MARUTI.NS        4505\n",
              "LT.NS            4505\n",
              "ICICIBANK.NS     4505\n",
              "HINDALCO.NS      4505\n",
              "HEROMOTOCO.NS    4505\n",
              "DRREDDY.NS       4505\n",
              "CIPLA.NS         4505\n",
              "BRITANNIA.NS     4505\n",
              "BHARTIARTL.NS    4505\n",
              "BAJFINANCE.NS    4505\n",
              "BAJAJ-AUTO.NS    4505\n",
              "KOTAKBANK.NS     4504\n",
              "ITC.NS           4504\n",
              "BAJAJFINSV.NS    4504\n",
              "INDUSINDBK.NS    4503\n",
              "TECHM.NS         4094\n",
              "COALINDIA.NS     3060\n",
              "HDFCLIFE.NS      1328\n",
              "Name: tic, dtype: int64"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.tic.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqC6c40Zh1iH"
      },
      "source": [
        "# Part 4: Preprocess Data\n",
        "Data preprocessing is a crucial step for training a high quality machine learning model. We need to check for missing data and do feature engineering in order to convert the data into a model-ready state.\n",
        "* Add technical indicators. In practical trading, various information needs to be taken into account, for example the historical stock prices, current holding shares, technical indicators, etc. In this article, we demonstrate two trend-following technical indicators: MACD and RSI.\n",
        "* Add turbulence index. Risk-aversion reflects whether an investor will choose to preserve the capital. It also influences one's trading strategy when facing different market volatility level. To control the risk in a worst-case scenario, such as financial crisis of 2007–2008, FinRL employs the financial turbulence index that measures extreme asset price fluctuation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "kM5bH9uroCeg"
      },
      "outputs": [],
      "source": [
        "#  INDICATORS = ['macd',\n",
        "#                'rsi_30',\n",
        "#                'cci_30',\n",
        "#                'dx_30']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jgXfBcjxtj1a",
        "outputId": "83f9dc78-6e68-4a05-dc0b-5934d6434abc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully added technical indicators\n",
            "Successfully added turbulence index\n"
          ]
        }
      ],
      "source": [
        "fe = FeatureEngineer(use_technical_indicator=True,\n",
        "                     tech_indicator_list = INDICATORS,\n",
        "                     use_turbulence=True,\n",
        "                     user_defined_feature = False)\n",
        "\n",
        "processed = fe.preprocess_data(df)\n",
        "processed = processed.copy()\n",
        "processed = processed.fillna(0)\n",
        "processed = processed.replace(np.inf,0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "grvhGJJII3Xn",
        "outputId": "5341dcb8-c005-407a-fdbb-3c45ddfd5b20"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c8c0c89a-66c8-497e-a29c-53590da40bad\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>open</th>\n",
              "      <th>high</th>\n",
              "      <th>low</th>\n",
              "      <th>close</th>\n",
              "      <th>volume</th>\n",
              "      <th>tic</th>\n",
              "      <th>day</th>\n",
              "      <th>macd</th>\n",
              "      <th>boll_ub</th>\n",
              "      <th>boll_lb</th>\n",
              "      <th>rsi_30</th>\n",
              "      <th>cci_30</th>\n",
              "      <th>dx_30</th>\n",
              "      <th>close_30_sma</th>\n",
              "      <th>close_60_sma</th>\n",
              "      <th>turbulence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>83018</th>\n",
              "      <td>2019-08-22</td>\n",
              "      <td>1302.000000</td>\n",
              "      <td>1327.449951</td>\n",
              "      <td>1283.150024</td>\n",
              "      <td>1211.883057</td>\n",
              "      <td>3780476</td>\n",
              "      <td>LT.NS</td>\n",
              "      <td>3</td>\n",
              "      <td>-29.560253</td>\n",
              "      <td>1319.670456</td>\n",
              "      <td>1218.401908</td>\n",
              "      <td>38.991589</td>\n",
              "      <td>-143.006084</td>\n",
              "      <td>44.694582</td>\n",
              "      <td>1292.164994</td>\n",
              "      <td>1357.786255</td>\n",
              "      <td>25.203318</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37752</th>\n",
              "      <td>2011-08-18</td>\n",
              "      <td>143.850006</td>\n",
              "      <td>143.850006</td>\n",
              "      <td>136.600006</td>\n",
              "      <td>124.278252</td>\n",
              "      <td>6934947</td>\n",
              "      <td>HINDALCO.NS</td>\n",
              "      <td>3</td>\n",
              "      <td>-8.498843</td>\n",
              "      <td>168.881343</td>\n",
              "      <td>122.885890</td>\n",
              "      <td>33.135901</td>\n",
              "      <td>-165.287972</td>\n",
              "      <td>55.382055</td>\n",
              "      <td>151.947807</td>\n",
              "      <td>158.281349</td>\n",
              "      <td>27.952856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93892</th>\n",
              "      <td>2021-07-20</td>\n",
              "      <td>972.000000</td>\n",
              "      <td>974.099976</td>\n",
              "      <td>952.650024</td>\n",
              "      <td>945.316956</td>\n",
              "      <td>1520300</td>\n",
              "      <td>CIPLA.NS</td>\n",
              "      <td>1</td>\n",
              "      <td>4.651400</td>\n",
              "      <td>976.244551</td>\n",
              "      <td>937.805742</td>\n",
              "      <td>53.289599</td>\n",
              "      <td>-45.651393</td>\n",
              "      <td>2.855959</td>\n",
              "      <td>955.750079</td>\n",
              "      <td>931.915501</td>\n",
              "      <td>12.212724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4196</th>\n",
              "      <td>2005-09-22</td>\n",
              "      <td>104.181816</td>\n",
              "      <td>105.909088</td>\n",
              "      <td>102.454544</td>\n",
              "      <td>82.652740</td>\n",
              "      <td>7640226</td>\n",
              "      <td>ICICIBANK.NS</td>\n",
              "      <td>3</td>\n",
              "      <td>3.247231</td>\n",
              "      <td>84.659721</td>\n",
              "      <td>63.563626</td>\n",
              "      <td>66.442348</td>\n",
              "      <td>200.083890</td>\n",
              "      <td>51.443574</td>\n",
              "      <td>73.386908</td>\n",
              "      <td>70.097499</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75612</th>\n",
              "      <td>2018-04-30</td>\n",
              "      <td>1381.300049</td>\n",
              "      <td>1405.000000</td>\n",
              "      <td>1381.300049</td>\n",
              "      <td>1278.667114</td>\n",
              "      <td>1309980</td>\n",
              "      <td>LT.NS</td>\n",
              "      <td>0</td>\n",
              "      <td>14.990357</td>\n",
              "      <td>1280.746841</td>\n",
              "      <td>1190.907896</td>\n",
              "      <td>57.967632</td>\n",
              "      <td>138.484642</td>\n",
              "      <td>21.383904</td>\n",
              "      <td>1218.424337</td>\n",
              "      <td>1214.914813</td>\n",
              "      <td>26.434689</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c8c0c89a-66c8-497e-a29c-53590da40bad')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c8c0c89a-66c8-497e-a29c-53590da40bad button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c8c0c89a-66c8-497e-a29c-53590da40bad');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             date         open         high          low        close  \\\n",
              "83018  2019-08-22  1302.000000  1327.449951  1283.150024  1211.883057   \n",
              "37752  2011-08-18   143.850006   143.850006   136.600006   124.278252   \n",
              "93892  2021-07-20   972.000000   974.099976   952.650024   945.316956   \n",
              "4196   2005-09-22   104.181816   105.909088   102.454544    82.652740   \n",
              "75612  2018-04-30  1381.300049  1405.000000  1381.300049  1278.667114   \n",
              "\n",
              "        volume           tic  day       macd      boll_ub      boll_lb  \\\n",
              "83018  3780476         LT.NS    3 -29.560253  1319.670456  1218.401908   \n",
              "37752  6934947   HINDALCO.NS    3  -8.498843   168.881343   122.885890   \n",
              "93892  1520300      CIPLA.NS    1   4.651400   976.244551   937.805742   \n",
              "4196   7640226  ICICIBANK.NS    3   3.247231    84.659721    63.563626   \n",
              "75612  1309980         LT.NS    0  14.990357  1280.746841  1190.907896   \n",
              "\n",
              "          rsi_30      cci_30      dx_30  close_30_sma  close_60_sma  \\\n",
              "83018  38.991589 -143.006084  44.694582   1292.164994   1357.786255   \n",
              "37752  33.135901 -165.287972  55.382055    151.947807    158.281349   \n",
              "93892  53.289599  -45.651393   2.855959    955.750079    931.915501   \n",
              "4196   66.442348  200.083890  51.443574     73.386908     70.097499   \n",
              "75612  57.967632  138.484642  21.383904   1218.424337   1214.914813   \n",
              "\n",
              "       turbulence  \n",
              "83018   25.203318  \n",
              "37752   27.952856  \n",
              "93892   12.212724  \n",
              "4196     0.000000  \n",
              "75612   26.434689  "
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "processed.sample(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QsYaY0Dh1iw"
      },
      "source": [
        "<a id='4'></a>\n",
        "# Part 5. Design Environment\n",
        "Considering the stochastic and interactive nature of the automated stock trading tasks, a financial task is modeled as a **Markov Decision Process (MDP)** problem. The training process involves observing stock price change, taking an action and reward's calculation to have the agent adjusting its strategy accordingly. By interacting with the environment, the trading agent will derive a trading strategy with the maximized rewards as time proceeds.\n",
        "\n",
        "Our trading environments, based on OpenAI Gym framework, simulate live stock markets with real market data according to the principle of time-driven simulation.\n",
        "\n",
        "The action space describes the allowed actions that the agent interacts with the environment. Normally, action a includes three actions: {-1, 0, 1}, where -1, 0, 1 represent selling, holding, and buying one share. Also, an action can be carried upon multiple shares. We use an action space {-k,…,-1, 0, 1, …, k}, where k denotes the number of shares to buy and -k denotes the number of shares to sell. For example, \"Buy 10 shares of AAPL\" or \"Sell 10 shares of AAPL\" are 10 or -10, respectively. The continuous action space needs to be normalized to [-1, 1], since the policy is defined on a Gaussian distribution, which needs to be normalized and symmetric."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2zqII8rMIqn",
        "outputId": "7fc1f122-b1e3-4acc-c4b9-6ee8585d980b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Stock Dimension: 23, State Space: 231\n"
          ]
        }
      ],
      "source": [
        "stock_dimension = len(processed.tic.unique())\n",
        "state_space = 1 + 2*stock_dimension + len(INDICATORS)*stock_dimension\n",
        "print(f\"Stock Dimension: {stock_dimension}, State Space: {state_space}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ixKb7tM08cI",
        "outputId": "9a6ca9b5-6c97-4c64-9a00-418b70db87bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['macd',\n",
              " 'boll_ub',\n",
              " 'boll_lb',\n",
              " 'rsi_30',\n",
              " 'cci_30',\n",
              " 'dx_30',\n",
              " 'close_30_sma',\n",
              " 'close_60_sma']"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "INDICATORS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "AWyp84Ltto19"
      },
      "outputs": [],
      "source": [
        "env_kwargs = {\n",
        "    \"hmax\": 100, \n",
        "    \"initial_amount\": 1000000, \n",
        "    \"buy_cost_pct\": 0.001, \n",
        "    \"sell_cost_pct\": 0.001, \n",
        "    \"state_space\": state_space, \n",
        "    \"stock_dim\": stock_dimension, \n",
        "    \"tech_indicator_list\": INDICATORS,\n",
        "    \"action_space\": stock_dimension, \n",
        "    \"reward_scaling\": 1e-4,\n",
        "    \"print_verbosity\":5\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMNR5nHjh1iz"
      },
      "source": [
        "<a id='5'></a>\n",
        "# Part 6: Implement DRL Algorithms\n",
        "* The implementation of the DRL algorithms are based on **OpenAI Baselines** and **Stable Baselines**. Stable Baselines is a fork of OpenAI Baselines, with a major structural refactoring, and code cleanups.\n",
        "* FinRL library includes fine-tuned standard DRL algorithms, such as DQN, DDPG,\n",
        "Multi-Agent DDPG, PPO, SAC, A2C and TD3. We also allow users to\n",
        "design their own DRL algorithms by adapting these DRL algorithms.\n",
        "\n",
        "* In this notebook, we are training and validating 3 agents (A2C, PPO, DDPG) using Rolling-window Ensemble Method ([reference code](https://github.com/AI4Finance-LLC/Deep-Reinforcement-Learning-for-Automated-Stock-Trading-Ensemble-Strategy-ICAIF-2020/blob/80415db8fa7b2179df6bd7e81ce4fe8dbf913806/model/models.py#L92))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "v-gthCxMtj1d"
      },
      "outputs": [],
      "source": [
        "rebalance_window = 63 # rebalance_window is the number of days to retrain the model\n",
        "validation_window = 63 # validation_window is the number of days to do validation and trading (e.g. if validation_window=63, then both validation and trading period will be 63 days)\n",
        "\n",
        "ensemble_agent = DRLEnsembleAgent(df=processed,\n",
        "                 train_period=(TRAIN_START_DATE,TRAIN_END_DATE),\n",
        "                 val_test_period=(TEST_START_DATE,TEST_END_DATE),\n",
        "                 rebalance_window=rebalance_window, \n",
        "                 validation_window=validation_window, \n",
        "                 **env_kwargs)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "KsfEHa_Etj1d",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "A2C_model_kwargs = {\n",
        "                    'n_steps': 5,\n",
        "                    'ent_coef': 0.005,\n",
        "                    'learning_rate': 0.0007\n",
        "                    }\n",
        "\n",
        "PPO_model_kwargs = {\n",
        "                    \"ent_coef\":0.01,\n",
        "                    \"n_steps\": 2048,\n",
        "                    \"learning_rate\": 0.00025,\n",
        "                    \"batch_size\": 128\n",
        "                    }\n",
        "\n",
        "DDPG_model_kwargs = {\n",
        "                      #\"action_noise\":\"ornstein_uhlenbeck\",\n",
        "                      \"buffer_size\": 20_000,\n",
        "                      \"learning_rate\": 0.0005,\n",
        "                      \"batch_size\": 64\n",
        "                    }\n",
        "\n",
        "timesteps_dict = {'a2c' : 30_000, \n",
        "                 'ppo' : 30_000, \n",
        "                 'ddpg' : 30_000\n",
        "                 }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1lyCECstj1e",
        "outputId": "dee070f2-e7ca-411b-b15b-eb70a4136c2c",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 1900       |\n",
            "|    time_elapsed       | 128        |\n",
            "|    total_timesteps    | 9500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1899       |\n",
            "|    policy_loss        | 9.79       |\n",
            "|    reward             | 0.18406807 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.252      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 133         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | -12.6       |\n",
            "|    reward             | -0.10680804 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.183       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 140       |\n",
            "|    total_timesteps    | 10500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | -23.7     |\n",
            "|    reward             | 0.3835987 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.589     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2200        |\n",
            "|    time_elapsed       | 148         |\n",
            "|    total_timesteps    | 11000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.6       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2199        |\n",
            "|    policy_loss        | 16.5        |\n",
            "|    reward             | -0.64075565 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.385       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 154        |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | -46.5      |\n",
            "|    reward             | 0.12748471 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 2.25       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 159         |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | -30.2       |\n",
            "|    reward             | -0.56685233 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 1.05        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2500        |\n",
            "|    time_elapsed       | 167         |\n",
            "|    total_timesteps    | 12500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.8       |\n",
            "|    explained_variance | -64.9       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2499        |\n",
            "|    policy_loss        | 2.96        |\n",
            "|    reward             | -0.07343521 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0375      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 2600         |\n",
            "|    time_elapsed       | 174          |\n",
            "|    total_timesteps    | 13000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.9        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2599         |\n",
            "|    policy_loss        | -0.509       |\n",
            "|    reward             | -0.028675286 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.00157      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 179         |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.1       |\n",
            "|    explained_variance | 0.0184      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | -0.347      |\n",
            "|    reward             | 0.029727958 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.0114      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 186         |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | -8.36       |\n",
            "|    reward             | 0.024370383 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.064       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 194         |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | -2.78       |\n",
            "|    reward             | -0.23144175 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0175      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 200         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.4       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | -4.36       |\n",
            "|    reward             | 0.017040411 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0215      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 3100         |\n",
            "|    time_elapsed       | 206          |\n",
            "|    total_timesteps    | 15500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.5        |\n",
            "|    explained_variance | 1.79e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3099         |\n",
            "|    policy_loss        | 29.7         |\n",
            "|    reward             | -0.027466562 |\n",
            "|    std                | 1.09         |\n",
            "|    value_loss         | 0.715        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 214        |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | 13.5       |\n",
            "|    reward             | 0.19366774 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.17       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 3300     |\n",
            "|    time_elapsed       | 220      |\n",
            "|    total_timesteps    | 16500    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -34.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 3299     |\n",
            "|    policy_loss        | 7.9      |\n",
            "|    reward             | 1.253231 |\n",
            "|    std                | 1.09     |\n",
            "|    value_loss         | 0.0704   |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3400        |\n",
            "|    time_elapsed       | 226         |\n",
            "|    total_timesteps    | 17000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3399        |\n",
            "|    policy_loss        | 3.82        |\n",
            "|    reward             | 0.060860857 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.0119      |\n",
            "---------------------------------------\n",
            "------------------------------------------\n",
            "| time/                 |                |\n",
            "|    fps                | 74             |\n",
            "|    iterations         | 3500           |\n",
            "|    time_elapsed       | 233            |\n",
            "|    total_timesteps    | 17500          |\n",
            "| train/                |                |\n",
            "|    entropy_loss       | -34.7          |\n",
            "|    explained_variance | 0.00017        |\n",
            "|    learning_rate      | 0.0007         |\n",
            "|    n_updates          | 3499           |\n",
            "|    policy_loss        | -12.9          |\n",
            "|    reward             | -1.8679623e-06 |\n",
            "|    std                | 1.09           |\n",
            "|    value_loss         | 0.152          |\n",
            "------------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 241        |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | 13.4       |\n",
            "|    reward             | -0.1728343 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.162      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 246         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -13.1       |\n",
            "|    reward             | -0.16962257 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.147       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 252        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | -11.3      |\n",
            "|    reward             | 0.19085173 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.167      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 3900        |\n",
            "|    time_elapsed       | 260         |\n",
            "|    total_timesteps    | 19500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35         |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3899        |\n",
            "|    policy_loss        | 8.85        |\n",
            "|    reward             | -0.14673607 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.29        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 267       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -35       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 19.2      |\n",
            "|    reward             | 1.1477484 |\n",
            "|    std                | 1.11      |\n",
            "|    value_loss         | 0.52      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 272        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | -31.9      |\n",
            "|    reward             | -0.6076489 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.27       |\n",
            "--------------------------------------\n",
            "day: 4132, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1199457.69\n",
            "total_reward: 199457.69\n",
            "total_cost: 15211.27\n",
            "total_trades: 62565\n",
            "Sharpe: 0.452\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 4200         |\n",
            "|    time_elapsed       | 279          |\n",
            "|    total_timesteps    | 21000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35          |\n",
            "|    explained_variance | 0.133        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4199         |\n",
            "|    policy_loss        | 0.592        |\n",
            "|    reward             | -0.077773154 |\n",
            "|    std                | 1.11         |\n",
            "|    value_loss         | 0.00682      |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 287          |\n",
            "|    total_timesteps    | 21500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35.1        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | -1.06        |\n",
            "|    reward             | 0.0012310698 |\n",
            "|    std                | 1.12         |\n",
            "|    value_loss         | 0.0035       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4400        |\n",
            "|    time_elapsed       | 292         |\n",
            "|    total_timesteps    | 22000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35.2       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4399        |\n",
            "|    policy_loss        | -0.902      |\n",
            "|    reward             | 0.018938638 |\n",
            "|    std                | 1.12        |\n",
            "|    value_loss         | 0.0217      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4500       |\n",
            "|    time_elapsed       | 298        |\n",
            "|    total_timesteps    | 22500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4499       |\n",
            "|    policy_loss        | 8.88       |\n",
            "|    reward             | -0.0380955 |\n",
            "|    std                | 1.12       |\n",
            "|    value_loss         | 0.102      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 4600      |\n",
            "|    time_elapsed       | 307       |\n",
            "|    total_timesteps    | 23000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -35.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4599      |\n",
            "|    policy_loss        | 44.3      |\n",
            "|    reward             | 0.1619427 |\n",
            "|    std                | 1.12      |\n",
            "|    value_loss         | 2.22      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 313        |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35.3      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | 6.43       |\n",
            "|    reward             | 0.06780327 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.0597     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 318        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4799       |\n",
            "|    policy_loss        | 4.11       |\n",
            "|    reward             | -0.0670923 |\n",
            "|    std                | 1.13       |\n",
            "|    value_loss         | 0.0331     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 326         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | 7.86        |\n",
            "|    reward             | -0.13153635 |\n",
            "|    std                | 1.13        |\n",
            "|    value_loss         | 0.0601      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 333        |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -12.3      |\n",
            "|    reward             | -0.0643754 |\n",
            "|    std                | 1.14       |\n",
            "|    value_loss         | 0.135      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 5100      |\n",
            "|    time_elapsed       | 339       |\n",
            "|    total_timesteps    | 25500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -35.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5099      |\n",
            "|    policy_loss        | -29.2     |\n",
            "|    reward             | 1.2084525 |\n",
            "|    std                | 1.14      |\n",
            "|    value_loss         | 0.781     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 5200      |\n",
            "|    time_elapsed       | 345       |\n",
            "|    total_timesteps    | 26000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -35.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5199      |\n",
            "|    policy_loss        | 14.8      |\n",
            "|    reward             | 0.2461666 |\n",
            "|    std                | 1.15      |\n",
            "|    value_loss         | 0.234     |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 353          |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35.9        |\n",
            "|    explained_variance | -0.0583      |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | -27.4        |\n",
            "|    reward             | -0.015321564 |\n",
            "|    std                | 1.15         |\n",
            "|    value_loss         | 0.739        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 359         |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36         |\n",
            "|    explained_variance | -3.58e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | 28.6        |\n",
            "|    reward             | -0.25008607 |\n",
            "|    std                | 1.16        |\n",
            "|    value_loss         | 0.68        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 364        |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -36        |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | -25.7      |\n",
            "|    reward             | 0.59702694 |\n",
            "|    std                | 1.16       |\n",
            "|    value_loss         | 0.696      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 5600      |\n",
            "|    time_elapsed       | 372       |\n",
            "|    total_timesteps    | 28000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5599      |\n",
            "|    policy_loss        | 2.38      |\n",
            "|    reward             | 0.6036278 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.0444    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 379        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -36.1      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | 3.61       |\n",
            "|    reward             | 0.08679126 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.0125     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 5800         |\n",
            "|    time_elapsed       | 385          |\n",
            "|    total_timesteps    | 29000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -36.2        |\n",
            "|    explained_variance | 0.444        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5799         |\n",
            "|    policy_loss        | -0.0226      |\n",
            "|    reward             | -0.003939932 |\n",
            "|    std                | 1.17         |\n",
            "|    value_loss         | 0.000393     |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 391         |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36.4       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -0.892      |\n",
            "|    reward             | 0.049361393 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 0.00779     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 399         |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36.5       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | -0.6        |\n",
            "|    reward             | -0.07508584 |\n",
            "|    std                | 1.18        |\n",
            "|    value_loss         | 0.00154     |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2021-10-04 to  2022-01-04\n",
            "A2C Sharpe Ratio:  0.10749539540831748\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_126_3\n",
            "---------------------------------\n",
            "| time/              |          |\n",
            "|    fps             | 81       |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 25       |\n",
            "|    total_timesteps | 2048     |\n",
            "| train/             |          |\n",
            "|    reward          | 3.601017 |\n",
            "---------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 81          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 50          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014017813 |\n",
            "|    clip_fraction        | 0.198       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | 0.00108     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 21          |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0263     |\n",
            "|    reward               | -4.0463247  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 37.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 81          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 75          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016580459 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.00195    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 117         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0132     |\n",
            "|    reward               | 0.0472736   |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 206         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 81          |\n",
            "|    iterations           | 4           |\n",
            "|    time_elapsed         | 100         |\n",
            "|    total_timesteps      | 8192        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019406963 |\n",
            "|    clip_fraction        | 0.259       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.8       |\n",
            "|    explained_variance   | 0.0271      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.91        |\n",
            "|    n_updates            | 30          |\n",
            "|    policy_gradient_loss | -0.0191     |\n",
            "|    reward               | -1.1750824  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 10.3        |\n",
            "-----------------------------------------\n",
            "day: 4132, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 260525.06\n",
            "total_reward: -739474.94\n",
            "total_cost: 311314.81\n",
            "total_trades: 60205\n",
            "Sharpe: 0.311\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 81           |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 125          |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.016052842  |\n",
            "|    clip_fraction        | 0.245        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.9        |\n",
            "|    explained_variance   | 0.0852       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.0634      |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00332     |\n",
            "|    reward               | -0.009328367 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.449        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 80           |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 152          |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.018352058  |\n",
            "|    clip_fraction        | 0.213        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33          |\n",
            "|    explained_variance   | 0.0914       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.282       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.0156      |\n",
            "|    reward               | -0.012361936 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 4.43         |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 80            |\n",
            "|    iterations           | 7             |\n",
            "|    time_elapsed         | 178           |\n",
            "|    total_timesteps      | 14336         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.021031493   |\n",
            "|    clip_fraction        | 0.238         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -33.1         |\n",
            "|    explained_variance   | 0.144         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.273        |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | -0.0106       |\n",
            "|    reward               | 0.00018458458 |\n",
            "|    std                  | 1.02          |\n",
            "|    value_loss           | 0.0629        |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 80          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 204         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017936725 |\n",
            "|    clip_fraction        | 0.192       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | 0.09        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.345      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0154     |\n",
            "|    reward               | 0.022705916 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.33        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 230         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016986294 |\n",
            "|    clip_fraction        | 0.215       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | 0.133       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.346      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0103     |\n",
            "|    reward               | 0.020246953 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.0106      |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 80            |\n",
            "|    iterations           | 10            |\n",
            "|    time_elapsed         | 255           |\n",
            "|    total_timesteps      | 20480         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.018946601   |\n",
            "|    clip_fraction        | 0.193         |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -33.2         |\n",
            "|    explained_variance   | 0.109         |\n",
            "|    learning_rate        | 0.00025       |\n",
            "|    loss                 | -0.303        |\n",
            "|    n_updates            | 90            |\n",
            "|    policy_gradient_loss | -0.0119       |\n",
            "|    reward               | -0.0050682668 |\n",
            "|    std                  | 1.03          |\n",
            "|    value_loss           | 4.09          |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 80           |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 281          |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.022376932  |\n",
            "|    clip_fraction        | 0.225        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.3        |\n",
            "|    explained_variance   | 0.274        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.324       |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.0125      |\n",
            "|    reward               | -0.029240686 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.022        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 80          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 306         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016589448 |\n",
            "|    clip_fraction        | 0.215       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | 0.12        |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.23       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0106     |\n",
            "|    reward               | -0.01428573 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.1         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 80          |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 331         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.02125462  |\n",
            "|    clip_fraction        | 0.227       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | -0.121      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.355      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0123     |\n",
            "|    reward               | -0.28393734 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.0228      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 80          |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 357         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014169484 |\n",
            "|    clip_fraction        | 0.152       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.5       |\n",
            "|    explained_variance   | 0.104       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.161      |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    reward               | -0.16151097 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 4.43        |\n",
            "-----------------------------------------\n",
            "day: 4132, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 662072.06\n",
            "total_reward: -337927.94\n",
            "total_cost: 590951.65\n",
            "total_trades: 63759\n",
            "Sharpe: 0.318\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 80           |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 383          |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.018245233  |\n",
            "|    clip_fraction        | 0.185        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.5        |\n",
            "|    explained_variance   | -0.0087      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.331        |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.0166      |\n",
            "|    reward               | -0.037156958 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 1.37         |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2021-10-04 to  2022-01-04\n",
            "PPO Sharpe Ratio:  0.15471031203887434\n",
            "======DDPG Training========\n",
            "{'buffer_size': 20000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_126_3\n",
            "day: 4132, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1037883.27\n",
            "total_reward: 37883.27\n",
            "total_cost: 999.00\n",
            "total_trades: 45452\n",
            "Sharpe: 0.443\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 61        |\n",
            "|    time_elapsed    | 270       |\n",
            "|    total_timesteps | 16532     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -88.4     |\n",
            "|    critic_loss     | 16.8      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 12399     |\n",
            "|    reward          | -1.912724 |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 58        |\n",
            "|    time_elapsed    | 568       |\n",
            "|    total_timesteps | 33064     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -39.5     |\n",
            "|    critic_loss     | 23.8      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 28931     |\n",
            "|    reward          | -1.912724 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2021-10-04 to  2022-01-04\n",
            "======Best Model Retraining from:  2005-01-01 to  2022-01-04\n",
            "======Trading from:  2022-01-04 to  2022-04-06\n",
            "============================================\n",
            "turbulence_threshold:  120.32455577846844\n",
            "======Model training from:  2005-01-01 to  2022-01-04\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_189_3\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 79          |\n",
            "|    iterations         | 100         |\n",
            "|    time_elapsed       | 6           |\n",
            "|    total_timesteps    | 500         |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.7       |\n",
            "|    explained_variance | -0.291      |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 99          |\n",
            "|    policy_loss        | 154         |\n",
            "|    reward             | 0.048636843 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 28.2        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 85       |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 11       |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.8    |\n",
            "|    explained_variance | 0.0566   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -101     |\n",
            "|    reward             | 2.716154 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 13.3     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | -0.0231   |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -9.6      |\n",
            "|    reward             | -2.388664 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 4.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 26         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | -0.283     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -7.76      |\n",
            "|    reward             | -2.0691755 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 5.51       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 78       |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 2500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.8    |\n",
            "|    explained_variance | -0.0538  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | -79.7    |\n",
            "|    reward             | 4.009851 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 34.1     |\n",
            "------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 38         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | -161       |\n",
            "|    reward             | -5.4966435 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 27.6       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 46       |\n",
            "|    total_timesteps    | 3500     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.7    |\n",
            "|    explained_variance | 1.19e-07 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 148      |\n",
            "|    reward             | 13.42058 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 35.5     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.6     |\n",
            "|    explained_variance | 1.19e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -1.32e+03 |\n",
            "|    reward             | 34.35306  |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 1.76e+03  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 900       |\n",
            "|    time_elapsed       | 57        |\n",
            "|    total_timesteps    | 4500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 899       |\n",
            "|    policy_loss        | -12       |\n",
            "|    reward             | 0.2514918 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.199     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 1000      |\n",
            "|    time_elapsed       | 65        |\n",
            "|    total_timesteps    | 5000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | 0.0289    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 999       |\n",
            "|    policy_loss        | -152      |\n",
            "|    reward             | 1.6483153 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 29.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 72        |\n",
            "|    total_timesteps    | 5500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | -0.299    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | -20.2     |\n",
            "|    reward             | 3.9772182 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 0.638     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 78         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | -40.7      |\n",
            "|    reward             | -1.7166765 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 2.05       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 1300       |\n",
            "|    time_elapsed       | 84         |\n",
            "|    total_timesteps    | 6500       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1299       |\n",
            "|    policy_loss        | -24.1      |\n",
            "|    reward             | 0.38874525 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 1.09       |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 75            |\n",
            "|    iterations         | 1400          |\n",
            "|    time_elapsed       | 92            |\n",
            "|    total_timesteps    | 7000          |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -32.7         |\n",
            "|    explained_variance | -1.19e-07     |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 1399          |\n",
            "|    policy_loss        | -63.2         |\n",
            "|    reward             | 0.00019772523 |\n",
            "|    std                | 1             |\n",
            "|    value_loss         | 3.61          |\n",
            "-----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 98        |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.7     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -35.8     |\n",
            "|    reward             | 0.9793694 |\n",
            "|    std                | 1         |\n",
            "|    value_loss         | 2.24      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 77         |\n",
            "|    iterations         | 1600       |\n",
            "|    time_elapsed       | 103        |\n",
            "|    total_timesteps    | 8000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1599       |\n",
            "|    policy_loss        | 53.1       |\n",
            "|    reward             | -1.6730548 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 3.66       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 111         |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -6.52       |\n",
            "|    reward             | 0.114984564 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0429      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 118         |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | 7.5         |\n",
            "|    reward             | -0.12640883 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0538      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 1900        |\n",
            "|    time_elapsed       | 124         |\n",
            "|    total_timesteps    | 9500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1899        |\n",
            "|    policy_loss        | -20.5       |\n",
            "|    reward             | -0.10251521 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.601       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 130        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | -1.09      |\n",
            "|    reward             | 0.34981325 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.0587     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 2100         |\n",
            "|    time_elapsed       | 138          |\n",
            "|    total_timesteps    | 10500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.1        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 2099         |\n",
            "|    policy_loss        | -3.87        |\n",
            "|    reward             | -0.118016295 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.0411       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 144        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33        |\n",
            "|    explained_variance | -0.301     |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 9.26       |\n",
            "|    reward             | 0.16945173 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.157      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 149       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | 31        |\n",
            "|    reward             | 1.1343942 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.923     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 157         |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | -8.96       |\n",
            "|    reward             | -0.37342423 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.221       |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 2500      |\n",
            "|    time_elapsed       | 164       |\n",
            "|    total_timesteps    | 12500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2499      |\n",
            "|    policy_loss        | -166      |\n",
            "|    reward             | 2.2043083 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 28.5      |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 76          |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 170         |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.1       |\n",
            "|    explained_variance | 0.222       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | -14.3       |\n",
            "|    reward             | -0.27644768 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 2.01        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 177       |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.1     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | -103      |\n",
            "|    reward             | 1.7922746 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 13.4      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 2800      |\n",
            "|    time_elapsed       | 185       |\n",
            "|    total_timesteps    | 14000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.2     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2799      |\n",
            "|    policy_loss        | 444       |\n",
            "|    reward             | 1.1581435 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 181       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 190        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | 201        |\n",
            "|    reward             | 0.17218034 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 33.1       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 76       |\n",
            "|    iterations         | 3000     |\n",
            "|    time_elapsed       | 196      |\n",
            "|    total_timesteps    | 15000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -33.2    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2999     |\n",
            "|    policy_loss        | -51.3    |\n",
            "|    reward             | 2.628194 |\n",
            "|    std                | 1.03     |\n",
            "|    value_loss         | 12       |\n",
            "------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3100        |\n",
            "|    time_elapsed       | 204         |\n",
            "|    total_timesteps    | 15500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3099        |\n",
            "|    policy_loss        | 192         |\n",
            "|    reward             | -0.58097756 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 31.7        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 3200      |\n",
            "|    time_elapsed       | 211       |\n",
            "|    total_timesteps    | 16000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3199      |\n",
            "|    policy_loss        | 18.1      |\n",
            "|    reward             | 3.5174427 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 5.98      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 3300      |\n",
            "|    time_elapsed       | 216       |\n",
            "|    total_timesteps    | 16500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.3     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3299      |\n",
            "|    policy_loss        | 370       |\n",
            "|    reward             | 3.0766058 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 209       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 3400      |\n",
            "|    time_elapsed       | 223       |\n",
            "|    total_timesteps    | 17000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.3     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3399      |\n",
            "|    policy_loss        | 0.747     |\n",
            "|    reward             | 0.1359029 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 0.00376   |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3500       |\n",
            "|    time_elapsed       | 231        |\n",
            "|    total_timesteps    | 17500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3499       |\n",
            "|    policy_loss        | -48.8      |\n",
            "|    reward             | -0.4273714 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 2.32       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 236         |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | -22.5       |\n",
            "|    reward             | -0.18217166 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.553       |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 76           |\n",
            "|    iterations         | 3700         |\n",
            "|    time_elapsed       | 242          |\n",
            "|    total_timesteps    | 18500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.4        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3699         |\n",
            "|    policy_loss        | 23.5         |\n",
            "|    reward             | -0.045028765 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.873        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 3800       |\n",
            "|    time_elapsed       | 250        |\n",
            "|    total_timesteps    | 19000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.5      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3799       |\n",
            "|    policy_loss        | -56.1      |\n",
            "|    reward             | 0.55615616 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 3.1        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 257       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.4     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 1.93      |\n",
            "|    reward             | -0.796777 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.0936    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 4000      |\n",
            "|    time_elapsed       | 262       |\n",
            "|    total_timesteps    | 20000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3999      |\n",
            "|    policy_loss        | 0.952     |\n",
            "|    reward             | 1.1210681 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.0985    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 270         |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -50.5       |\n",
            "|    reward             | -0.22303227 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 2.7         |\n",
            "---------------------------------------\n",
            "day: 4195, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1069638.95\n",
            "total_reward: 69638.95\n",
            "total_cost: 2274.37\n",
            "total_trades: 47472\n",
            "Sharpe: 0.424\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 278         |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.6       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -2.83       |\n",
            "|    reward             | 0.012347315 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.0123      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 283        |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | -0.483     |\n",
            "|    reward             | 0.16317862 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.00185    |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4400        |\n",
            "|    time_elapsed       | 289         |\n",
            "|    total_timesteps    | 22000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4399        |\n",
            "|    policy_loss        | 5.08        |\n",
            "|    reward             | -0.19031505 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0284      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 297         |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.9       |\n",
            "|    explained_variance | 1.79e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 11.8        |\n",
            "|    reward             | -0.12821157 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.192       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 303        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | -10.9      |\n",
            "|    reward             | 0.13775656 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.109      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 4700      |\n",
            "|    time_elapsed       | 309       |\n",
            "|    total_timesteps    | 23500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4699      |\n",
            "|    policy_loss        | -17.1     |\n",
            "|    reward             | -1.411665 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.474     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4800        |\n",
            "|    time_elapsed       | 316         |\n",
            "|    total_timesteps    | 24000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4799        |\n",
            "|    policy_loss        | 9.58        |\n",
            "|    reward             | -0.35100302 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.169       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 4900        |\n",
            "|    time_elapsed       | 324         |\n",
            "|    total_timesteps    | 24500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4899        |\n",
            "|    policy_loss        | -80.5       |\n",
            "|    reward             | -0.21078248 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 7.66        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 5000      |\n",
            "|    time_elapsed       | 329       |\n",
            "|    total_timesteps    | 25000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34.1     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 4999      |\n",
            "|    policy_loss        | -29.3     |\n",
            "|    reward             | 1.1267658 |\n",
            "|    std                | 1.07      |\n",
            "|    value_loss         | 3.66      |\n",
            "-------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 5100         |\n",
            "|    time_elapsed       | 336          |\n",
            "|    total_timesteps    | 25500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.4        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5099         |\n",
            "|    policy_loss        | -0.833       |\n",
            "|    reward             | -0.100757025 |\n",
            "|    std                | 1.08         |\n",
            "|    value_loss         | 0.00335      |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 344         |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | 13.1        |\n",
            "|    reward             | 0.081209786 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.174       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5300       |\n",
            "|    time_elapsed       | 350        |\n",
            "|    total_timesteps    | 26500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5299       |\n",
            "|    policy_loss        | 6.09       |\n",
            "|    reward             | 0.16674417 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.0506     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5400       |\n",
            "|    time_elapsed       | 355        |\n",
            "|    total_timesteps    | 27000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5399       |\n",
            "|    policy_loss        | -13.5      |\n",
            "|    reward             | 0.11747343 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.221      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 75         |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 363        |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | 7.79       |\n",
            "|    reward             | 0.40179086 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.111      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5600        |\n",
            "|    time_elapsed       | 370         |\n",
            "|    total_timesteps    | 28000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5599        |\n",
            "|    policy_loss        | 1.66        |\n",
            "|    reward             | 0.112050146 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.08        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 375         |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.9       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | 12.2        |\n",
            "|    reward             | -0.40795907 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.664       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5800        |\n",
            "|    time_elapsed       | 382         |\n",
            "|    total_timesteps    | 29000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5799        |\n",
            "|    policy_loss        | 25.8        |\n",
            "|    reward             | -0.32923716 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 4.04        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 5900        |\n",
            "|    time_elapsed       | 390         |\n",
            "|    total_timesteps    | 29500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5899        |\n",
            "|    policy_loss        | -0.22       |\n",
            "|    reward             | 0.036671568 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.000203    |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 75           |\n",
            "|    iterations         | 6000         |\n",
            "|    time_elapsed       | 396          |\n",
            "|    total_timesteps    | 30000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35.2        |\n",
            "|    explained_variance | -2.38e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5999         |\n",
            "|    policy_loss        | 0.665        |\n",
            "|    reward             | -0.011950625 |\n",
            "|    std                | 1.12         |\n",
            "|    value_loss         | 0.00105      |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2022-01-04 to  2022-04-06\n",
            "A2C Sharpe Ratio:  -0.11718635328037759\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_189_3\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 81        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 25        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 14.920049 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 80          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016350873 |\n",
            "|    clip_fraction        | 0.2         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.00451    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 228         |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0199     |\n",
            "|    reward               | -1.2283734  |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 224         |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 77          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013563768 |\n",
            "|    clip_fraction        | 0.108       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -7.51e-06   |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 694         |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0118     |\n",
            "|    reward               | 0.036861364 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 1.22e+03    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 78           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.021038147  |\n",
            "|    clip_fraction        | 0.259        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.8        |\n",
            "|    explained_variance   | 0.0165       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 118          |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0177      |\n",
            "|    reward               | -0.017885242 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 113          |\n",
            "------------------------------------------\n",
            "day: 4195, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 91051.58\n",
            "total_reward: -908948.42\n",
            "total_cost: 153943.27\n",
            "total_trades: 58647\n",
            "Sharpe: 0.180\n",
            "=================================\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 78           |\n",
            "|    iterations           | 5            |\n",
            "|    time_elapsed         | 130          |\n",
            "|    total_timesteps      | 10240        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.017379927  |\n",
            "|    clip_fraction        | 0.257        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.9        |\n",
            "|    explained_variance   | 0.423        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.309       |\n",
            "|    n_updates            | 40           |\n",
            "|    policy_gradient_loss | -0.00571     |\n",
            "|    reward               | -0.028024178 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 0.175        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 78           |\n",
            "|    iterations           | 6            |\n",
            "|    time_elapsed         | 155          |\n",
            "|    total_timesteps      | 12288        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.020193927  |\n",
            "|    clip_fraction        | 0.218        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33          |\n",
            "|    explained_variance   | -0.0708      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.264       |\n",
            "|    n_updates            | 50           |\n",
            "|    policy_gradient_loss | -0.0104      |\n",
            "|    reward               | -0.009561345 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 5.24         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 7           |\n",
            "|    time_elapsed         | 181         |\n",
            "|    total_timesteps      | 14336       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017341357 |\n",
            "|    clip_fraction        | 0.215       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.1       |\n",
            "|    explained_variance   | 0.344       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.271      |\n",
            "|    n_updates            | 60          |\n",
            "|    policy_gradient_loss | -0.00799    |\n",
            "|    reward               | 0.030798662 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 0.153       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 206         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019244393 |\n",
            "|    clip_fraction        | 0.227       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | -0.0671     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.295      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0173     |\n",
            "|    reward               | 0.036890525 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 5.21        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 231         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013999281 |\n",
            "|    clip_fraction        | 0.169       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | 0.622       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.329      |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.00538    |\n",
            "|    reward               | 0.026102757 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.0322      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 257         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.024640208 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.3       |\n",
            "|    explained_variance   | -0.084      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 40.4        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0173     |\n",
            "|    reward               | 0.014580423 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 5.23        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 11          |\n",
            "|    time_elapsed         | 283         |\n",
            "|    total_timesteps      | 22528       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016257614 |\n",
            "|    clip_fraction        | 0.209       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.3       |\n",
            "|    explained_variance   | 0.659       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.359      |\n",
            "|    n_updates            | 100         |\n",
            "|    policy_gradient_loss | -0.00672    |\n",
            "|    reward               | -0.08707882 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.0124      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 310         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015596466 |\n",
            "|    clip_fraction        | 0.171       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | -0.0943     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.549       |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0152     |\n",
            "|    reward               | -0.45459318 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 6.04        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 79           |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 336          |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.013937177  |\n",
            "|    clip_fraction        | 0.202        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.4        |\n",
            "|    explained_variance   | 0.0232       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 0.466        |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -0.0114      |\n",
            "|    reward               | -0.106226236 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 1.85         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 362         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018082406 |\n",
            "|    clip_fraction        | 0.199       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | 0.121       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.72        |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0142     |\n",
            "|    reward               | 0.057368074 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 6.66        |\n",
            "-----------------------------------------\n",
            "day: 4195, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 312860.40\n",
            "total_reward: -687139.60\n",
            "total_cost: 420950.96\n",
            "total_trades: 63575\n",
            "Sharpe: 0.260\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 387         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017091386 |\n",
            "|    clip_fraction        | 0.17        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.5       |\n",
            "|    explained_variance   | 0.153       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.194      |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.00373    |\n",
            "|    reward               | 0.03587027  |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 0.373       |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-01-04 to  2022-04-06\n",
            "PPO Sharpe Ratio:  0.075292362784689\n",
            "======DDPG Training========\n",
            "{'buffer_size': 20000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_189_3\n",
            "day: 4195, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1032215.91\n",
            "total_reward: 32215.91\n",
            "total_cost: 999.00\n",
            "total_trades: 33561\n",
            "Sharpe: 0.416\n",
            "=================================\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 60        |\n",
            "|    time_elapsed    | 275       |\n",
            "|    total_timesteps | 16784     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -109      |\n",
            "|    critic_loss     | 86.2      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 12588     |\n",
            "|    reward          | 0.7170478 |\n",
            "----------------------------------\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 8         |\n",
            "|    fps             | 57        |\n",
            "|    time_elapsed    | 578       |\n",
            "|    total_timesteps | 33568     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -48.3     |\n",
            "|    critic_loss     | 3.93      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 29372     |\n",
            "|    reward          | 0.7170478 |\n",
            "----------------------------------\n",
            "======DDPG Validation from:  2022-01-04 to  2022-04-06\n",
            "======Best Model Retraining from:  2005-01-01 to  2022-04-06\n",
            "======Trading from:  2022-04-06 to  2022-07-07\n",
            "============================================\n",
            "turbulence_threshold:  120.32455577846844\n",
            "======Model training from:  2005-01-01 to  2022-04-06\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_252_3\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 69         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 7          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.6      |\n",
            "|    explained_variance | -0.0583    |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | 32         |\n",
            "|    reward             | -2.7528505 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 8.24       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 79        |\n",
            "|    iterations         | 200       |\n",
            "|    time_elapsed       | 12        |\n",
            "|    total_timesteps    | 1000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.5     |\n",
            "|    explained_variance | 0.0084    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 199       |\n",
            "|    policy_loss        | -329      |\n",
            "|    reward             | 2.5069432 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 143       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | -644      |\n",
            "|    reward             | 3.1298053 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 623       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 72          |\n",
            "|    iterations         | 400         |\n",
            "|    time_elapsed       | 27          |\n",
            "|    total_timesteps    | 2000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.5       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 399         |\n",
            "|    policy_loss        | 129         |\n",
            "|    reward             | -0.45407498 |\n",
            "|    std                | 0.995       |\n",
            "|    value_loss         | 78.8        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 75        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | -570      |\n",
            "|    reward             | 21.431494 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 1.26e+03  |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 77        |\n",
            "|    iterations         | 600       |\n",
            "|    time_elapsed       | 38        |\n",
            "|    total_timesteps    | 3000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.5     |\n",
            "|    explained_variance | -0.255    |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 599       |\n",
            "|    policy_loss        | -19.1     |\n",
            "|    reward             | -3.997847 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 20.6      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 47        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | 646       |\n",
            "|    reward             | 13.046778 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 382       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 53        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -628      |\n",
            "|    reward             | 30.998775 |\n",
            "|    std                | 0.993     |\n",
            "|    value_loss         | 536       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 59          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.5       |\n",
            "|    explained_variance | -6.57       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | 17.3        |\n",
            "|    reward             | -0.12568209 |\n",
            "|    std                | 0.995       |\n",
            "|    value_loss         | 0.31        |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 1000        |\n",
            "|    time_elapsed       | 67          |\n",
            "|    total_timesteps    | 5000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.6       |\n",
            "|    explained_variance | 0.238       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 999         |\n",
            "|    policy_loss        | -10.1       |\n",
            "|    reward             | 0.084830105 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.107       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 74          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 11.8        |\n",
            "|    reward             | -0.05018544 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.136       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 1200       |\n",
            "|    time_elapsed       | 80         |\n",
            "|    total_timesteps    | 6000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1199       |\n",
            "|    policy_loss        | 10.2       |\n",
            "|    reward             | 0.07034168 |\n",
            "|    std                | 1.01       |\n",
            "|    value_loss         | 0.107      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 1300        |\n",
            "|    time_elapsed       | 87          |\n",
            "|    total_timesteps    | 6500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1299        |\n",
            "|    policy_loss        | 1.49        |\n",
            "|    reward             | -0.57199425 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0143      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 1400       |\n",
            "|    time_elapsed       | 95         |\n",
            "|    total_timesteps    | 7000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1399       |\n",
            "|    policy_loss        | 71.1       |\n",
            "|    reward             | -2.4259288 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 6.69       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 1500        |\n",
            "|    time_elapsed       | 101         |\n",
            "|    total_timesteps    | 7500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1499        |\n",
            "|    policy_loss        | 1.22        |\n",
            "|    reward             | -0.21427336 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 2.46        |\n",
            "---------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 74       |\n",
            "|    iterations         | 1600     |\n",
            "|    time_elapsed       | 107      |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -33      |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1599     |\n",
            "|    policy_loss        | -204     |\n",
            "|    reward             | 2.291145 |\n",
            "|    std                | 1.01     |\n",
            "|    value_loss         | 49.4     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 115       |\n",
            "|    total_timesteps    | 8500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33       |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | -272      |\n",
            "|    reward             | 7.741812  |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 151       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 1800        |\n",
            "|    time_elapsed       | 122         |\n",
            "|    total_timesteps    | 9000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1799        |\n",
            "|    policy_loss        | -7.62       |\n",
            "|    reward             | -0.02782517 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0583      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 1900         |\n",
            "|    time_elapsed       | 128          |\n",
            "|    total_timesteps    | 9500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.1        |\n",
            "|    explained_variance | -3.16        |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1899         |\n",
            "|    policy_loss        | 2.94         |\n",
            "|    reward             | -0.031796355 |\n",
            "|    std                | 1.02         |\n",
            "|    value_loss         | 0.0105       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2000       |\n",
            "|    time_elapsed       | 135        |\n",
            "|    total_timesteps    | 10000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1999       |\n",
            "|    policy_loss        | 7.98       |\n",
            "|    reward             | 0.09973935 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.0606     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2100       |\n",
            "|    time_elapsed       | 143        |\n",
            "|    total_timesteps    | 10500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2099       |\n",
            "|    policy_loss        | 20.9       |\n",
            "|    reward             | 0.73987025 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.438      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 148        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 245        |\n",
            "|    reward             | 0.52723336 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 61.4       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 2300       |\n",
            "|    time_elapsed       | 155        |\n",
            "|    total_timesteps    | 11500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2299       |\n",
            "|    policy_loss        | 433        |\n",
            "|    reward             | -1.5529885 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 210        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2400        |\n",
            "|    time_elapsed       | 163         |\n",
            "|    total_timesteps    | 12000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2399        |\n",
            "|    policy_loss        | 329         |\n",
            "|    reward             | -11.4563675 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 266         |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 169        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.3      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | 1.94e+03   |\n",
            "|    reward             | -27.868662 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 4.07e+03   |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 175         |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | -2.12       |\n",
            "|    reward             | 0.062941715 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.00607     |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 2700      |\n",
            "|    time_elapsed       | 183       |\n",
            "|    total_timesteps    | 13500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.5     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2699      |\n",
            "|    policy_loss        | -4.05     |\n",
            "|    reward             | 0.1339444 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.0284    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 190         |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | -1.66       |\n",
            "|    reward             | -0.15864623 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0121      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 2900        |\n",
            "|    time_elapsed       | 195         |\n",
            "|    total_timesteps    | 14500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.7       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2899        |\n",
            "|    policy_loss        | -14.6       |\n",
            "|    reward             | 0.027703563 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.203       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 3000        |\n",
            "|    time_elapsed       | 202         |\n",
            "|    total_timesteps    | 15000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2999        |\n",
            "|    policy_loss        | 17.5        |\n",
            "|    reward             | -0.19067681 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.52        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 211        |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.8      |\n",
            "|    explained_variance | 2.38e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | 112        |\n",
            "|    reward             | -1.7823339 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 11.1       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3200       |\n",
            "|    time_elapsed       | 216        |\n",
            "|    total_timesteps    | 16000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3199       |\n",
            "|    policy_loss        | -592       |\n",
            "|    reward             | 0.45480657 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 326        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3300       |\n",
            "|    time_elapsed       | 222        |\n",
            "|    total_timesteps    | 16500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3299       |\n",
            "|    policy_loss        | 595        |\n",
            "|    reward             | -1.9898343 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 615        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 231        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.8      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | 565        |\n",
            "|    reward             | -22.770218 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 744        |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 3500         |\n",
            "|    time_elapsed       | 237          |\n",
            "|    total_timesteps    | 17500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.9        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3499         |\n",
            "|    policy_loss        | -0.962       |\n",
            "|    reward             | -0.042244185 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.00182      |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3600       |\n",
            "|    time_elapsed       | 243        |\n",
            "|    total_timesteps    | 18000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3599       |\n",
            "|    policy_loss        | -19        |\n",
            "|    reward             | 0.48452112 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.346      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 3700        |\n",
            "|    time_elapsed       | 251         |\n",
            "|    total_timesteps    | 18500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3699        |\n",
            "|    policy_loss        | -62.8       |\n",
            "|    reward             | 0.016260162 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 3.59        |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3800      |\n",
            "|    time_elapsed       | 258       |\n",
            "|    total_timesteps    | 19000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.9     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3799      |\n",
            "|    policy_loss        | -1.69     |\n",
            "|    reward             | 0.3191359 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.0481    |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3900      |\n",
            "|    time_elapsed       | 263       |\n",
            "|    total_timesteps    | 19500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -34       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3899      |\n",
            "|    policy_loss        | 26.5      |\n",
            "|    reward             | 0.1260504 |\n",
            "|    std                | 1.06      |\n",
            "|    value_loss         | 0.654     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4000        |\n",
            "|    time_elapsed       | 270         |\n",
            "|    total_timesteps    | 20000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.9       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3999        |\n",
            "|    policy_loss        | 16.3        |\n",
            "|    reward             | -0.15753676 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.318       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4100       |\n",
            "|    time_elapsed       | 279        |\n",
            "|    total_timesteps    | 20500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4099       |\n",
            "|    policy_loss        | 2.15       |\n",
            "|    reward             | 0.09980015 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.104      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4200        |\n",
            "|    time_elapsed       | 285         |\n",
            "|    total_timesteps    | 21000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4199        |\n",
            "|    policy_loss        | -7.77       |\n",
            "|    reward             | -0.47010568 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.254       |\n",
            "---------------------------------------\n",
            "day: 4258, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 410356.16\n",
            "total_reward: -589643.84\n",
            "total_cost: 18535.39\n",
            "total_trades: 53241\n",
            "Sharpe: 0.367\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 4300         |\n",
            "|    time_elapsed       | 291          |\n",
            "|    total_timesteps    | 21500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.2        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4299         |\n",
            "|    policy_loss        | -7.98        |\n",
            "|    reward             | -0.046632838 |\n",
            "|    std                | 1.07         |\n",
            "|    value_loss         | 0.0859       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4400       |\n",
            "|    time_elapsed       | 299        |\n",
            "|    total_timesteps    | 22000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.4      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4399       |\n",
            "|    policy_loss        | 4.12       |\n",
            "|    reward             | -0.1102743 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.0182     |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 306         |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 0.142       |\n",
            "|    reward             | -0.14258836 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.000853    |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4600        |\n",
            "|    time_elapsed       | 311         |\n",
            "|    total_timesteps    | 23000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4599        |\n",
            "|    policy_loss        | -11.9       |\n",
            "|    reward             | -0.12570156 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.183       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4700       |\n",
            "|    time_elapsed       | 319        |\n",
            "|    total_timesteps    | 23500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.8      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4699       |\n",
            "|    policy_loss        | -12.1      |\n",
            "|    reward             | 0.10584824 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.126      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4800       |\n",
            "|    time_elapsed       | 326        |\n",
            "|    total_timesteps    | 24000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4799       |\n",
            "|    policy_loss        | -6.65      |\n",
            "|    reward             | 0.29186183 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.0706     |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 4900         |\n",
            "|    time_elapsed       | 332          |\n",
            "|    total_timesteps    | 24500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -34.9        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 4899         |\n",
            "|    policy_loss        | 3.01         |\n",
            "|    reward             | -0.041386653 |\n",
            "|    std                | 1.1          |\n",
            "|    value_loss         | 0.0132       |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 338        |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | -37.6      |\n",
            "|    reward             | 0.56129634 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.32       |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 347        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | -11        |\n",
            "|    reward             | -0.1773862 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.204      |\n",
            "--------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 73            |\n",
            "|    iterations         | 5200          |\n",
            "|    time_elapsed       | 353           |\n",
            "|    total_timesteps    | 26000         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -35.3         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 5199          |\n",
            "|    policy_loss        | -1.06         |\n",
            "|    reward             | -0.0140354885 |\n",
            "|    std                | 1.12          |\n",
            "|    value_loss         | 0.00105       |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 5300         |\n",
            "|    time_elapsed       | 358          |\n",
            "|    total_timesteps    | 26500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -35.8        |\n",
            "|    explained_variance | -1.19e-07    |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5299         |\n",
            "|    policy_loss        | 0.705        |\n",
            "|    reward             | -0.025408318 |\n",
            "|    std                | 1.15         |\n",
            "|    value_loss         | 0.00089      |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 5400      |\n",
            "|    time_elapsed       | 366       |\n",
            "|    total_timesteps    | 27000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36.1     |\n",
            "|    explained_variance | 2.38e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5399      |\n",
            "|    policy_loss        | 12.8      |\n",
            "|    reward             | 0.6234724 |\n",
            "|    std                | 1.16      |\n",
            "|    value_loss         | 0.165     |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 373        |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -36.1      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | 22.9       |\n",
            "|    reward             | -0.9291153 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.666      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 379        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -36.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | 24.4       |\n",
            "|    reward             | 0.55328894 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 0.666      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 5700        |\n",
            "|    time_elapsed       | 386         |\n",
            "|    total_timesteps    | 28500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -36.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5699        |\n",
            "|    policy_loss        | 5.08        |\n",
            "|    reward             | -0.69462955 |\n",
            "|    std                | 1.17        |\n",
            "|    value_loss         | 0.0591      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 5800      |\n",
            "|    time_elapsed       | 394       |\n",
            "|    total_timesteps    | 29000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -36.3     |\n",
            "|    explained_variance | 1.79e-07  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 5799      |\n",
            "|    policy_loss        | 131       |\n",
            "|    reward             | 0.4431023 |\n",
            "|    std                | 1.17      |\n",
            "|    value_loss         | 16.9      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5900       |\n",
            "|    time_elapsed       | 400        |\n",
            "|    total_timesteps    | 29500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -36.3      |\n",
            "|    explained_variance | 5.96e-08   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5899       |\n",
            "|    policy_loss        | 116        |\n",
            "|    reward             | 0.09064494 |\n",
            "|    std                | 1.17       |\n",
            "|    value_loss         | 9.12       |\n",
            "--------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 6000         |\n",
            "|    time_elapsed       | 406          |\n",
            "|    total_timesteps    | 30000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -36.4        |\n",
            "|    explained_variance | 5.96e-08     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 5999         |\n",
            "|    policy_loss        | -0.231       |\n",
            "|    reward             | -5.53372e-06 |\n",
            "|    std                | 1.18         |\n",
            "|    value_loss         | 4.62e-05     |\n",
            "----------------------------------------\n",
            "======A2C Validation from:  2022-04-06 to  2022-07-07\n",
            "A2C Sharpe Ratio:  -0.18443978620640375\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_252_3\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    fps             | 77        |\n",
            "|    iterations      | 1         |\n",
            "|    time_elapsed    | 26        |\n",
            "|    total_timesteps | 2048      |\n",
            "| train/             |           |\n",
            "|    reward          | 5.0559955 |\n",
            "----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 53          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015328064 |\n",
            "|    clip_fraction        | 0.167       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | 0.0166      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 27.9        |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.029      |\n",
            "|    reward               | -0.87538254 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 54.1        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 76          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 80          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019002005 |\n",
            "|    clip_fraction        | 0.184       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.00253    |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 81.7        |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.00904    |\n",
            "|    reward               | -0.00668407 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 199         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 77           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 106          |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.016359247  |\n",
            "|    clip_fraction        | 0.193        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.8        |\n",
            "|    explained_variance   | -0.0137      |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | 7.46         |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.017       |\n",
            "|    reward               | 0.0039657406 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 35.5         |\n",
            "------------------------------------------\n",
            "day: 4258, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 6080.38\n",
            "total_reward: -993919.62\n",
            "total_cost: 38151.54\n",
            "total_trades: 56000\n",
            "Sharpe: -0.175\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 131         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019443344 |\n",
            "|    clip_fraction        | 0.265       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.9       |\n",
            "|    explained_variance   | 0.888       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.303      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0112     |\n",
            "|    reward               | 0.035159178 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.0706      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 157         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.020692939 |\n",
            "|    clip_fraction        | 0.247       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | 0.125       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.338      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0119     |\n",
            "|    reward               | 0.005056585 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.22        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 77           |\n",
            "|    iterations           | 7            |\n",
            "|    time_elapsed         | 184          |\n",
            "|    total_timesteps      | 14336        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0140416715 |\n",
            "|    clip_fraction        | 0.187        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.1        |\n",
            "|    explained_variance   | 0.913        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.34        |\n",
            "|    n_updates            | 60           |\n",
            "|    policy_gradient_loss | -0.00836     |\n",
            "|    reward               | 0.025139268  |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.0233       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 211         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.01960808  |\n",
            "|    clip_fraction        | 0.228       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.1       |\n",
            "|    explained_variance   | 0.145       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.283      |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.0188     |\n",
            "|    reward               | 0.055854704 |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 4.28        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 76           |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 239          |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.014051278  |\n",
            "|    clip_fraction        | 0.209        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.1        |\n",
            "|    explained_variance   | 0.422        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.248       |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.00788     |\n",
            "|    reward               | -0.007991159 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.201        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 77           |\n",
            "|    iterations           | 10           |\n",
            "|    time_elapsed         | 265          |\n",
            "|    total_timesteps      | 20480        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.018942488  |\n",
            "|    clip_fraction        | 0.237        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.1        |\n",
            "|    explained_variance   | 0.152        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.26        |\n",
            "|    n_updates            | 90           |\n",
            "|    policy_gradient_loss | -0.017       |\n",
            "|    reward               | -0.037145473 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 4.18         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 77           |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 291          |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.015151325  |\n",
            "|    clip_fraction        | 0.195        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.2        |\n",
            "|    explained_variance   | 0.559        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.329       |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.00557     |\n",
            "|    reward               | 0.0018901852 |\n",
            "|    std                  | 1.03         |\n",
            "|    value_loss           | 0.0338       |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 316         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019656762 |\n",
            "|    clip_fraction        | 0.233       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | 0.155       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.338      |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0159     |\n",
            "|    reward               | -0.02173699 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.14        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 77         |\n",
            "|    iterations           | 13         |\n",
            "|    time_elapsed         | 342        |\n",
            "|    total_timesteps      | 26624      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01847425 |\n",
            "|    clip_fraction        | 0.219      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -33.3      |\n",
            "|    explained_variance   | 0.138      |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | -0.255     |\n",
            "|    n_updates            | 120        |\n",
            "|    policy_gradient_loss | -0.0137    |\n",
            "|    reward               | 0.09298043 |\n",
            "|    std                  | 1.03       |\n",
            "|    value_loss           | 0.173      |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 369         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019725338 |\n",
            "|    clip_fraction        | 0.257       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | 0.163       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.182      |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0163     |\n",
            "|    reward               | 1.2586322   |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 4.11        |\n",
            "-----------------------------------------\n",
            "day: 4258, episode: 15\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 491671.73\n",
            "total_reward: -508328.27\n",
            "total_cost: 604916.59\n",
            "total_trades: 64169\n",
            "Sharpe: 0.317\n",
            "=================================\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 15          |\n",
            "|    time_elapsed         | 396         |\n",
            "|    total_timesteps      | 30720       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.0154119   |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.5       |\n",
            "|    explained_variance   | -0.0404     |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.265       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0194     |\n",
            "|    reward               | 0.027972486 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 1.27        |\n",
            "-----------------------------------------\n",
            "======PPO Validation from:  2022-04-06 to  2022-07-07\n",
            "PPO Sharpe Ratio:  -0.26094579524484485\n",
            "======DDPG Training========\n",
            "{'buffer_size': 20000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_252_3\n",
            "day: 4258, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1001766.99\n",
            "total_reward: 1766.99\n",
            "total_cost: 999.00\n",
            "total_trades: 55353\n",
            "Sharpe: 0.461\n",
            "=================================\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 4          |\n",
            "|    fps             | 60         |\n",
            "|    time_elapsed    | 282        |\n",
            "|    total_timesteps | 17036      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 86.2       |\n",
            "|    critic_loss     | 49.2       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 12777      |\n",
            "|    reward          | -0.8128672 |\n",
            "-----------------------------------\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    episodes        | 8          |\n",
            "|    fps             | 57         |\n",
            "|    time_elapsed    | 594        |\n",
            "|    total_timesteps | 34072      |\n",
            "| train/             |            |\n",
            "|    actor_loss      | 31.1       |\n",
            "|    critic_loss     | 5.68       |\n",
            "|    learning_rate   | 0.0005     |\n",
            "|    n_updates       | 29813      |\n",
            "|    reward          | -0.8128672 |\n",
            "-----------------------------------\n",
            "======DDPG Validation from:  2022-04-06 to  2022-07-07\n",
            "======Best Model Retraining from:  2005-01-01 to  2022-07-07\n",
            "======Trading from:  2022-07-07 to  2022-10-10\n",
            "============================================\n",
            "turbulence_threshold:  120.32455577846844\n",
            "======Model training from:  2005-01-01 to  2022-07-07\n",
            "======A2C Training========\n",
            "{'n_steps': 5, 'ent_coef': 0.005, 'learning_rate': 0.0007}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/a2c/a2c_315_3\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 90         |\n",
            "|    iterations         | 100        |\n",
            "|    time_elapsed       | 5          |\n",
            "|    total_timesteps    | 500        |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.6      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 99         |\n",
            "|    policy_loss        | 83.2       |\n",
            "|    reward             | -1.0070544 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 14.6       |\n",
            "--------------------------------------\n",
            "------------------------------------\n",
            "| time/                 |          |\n",
            "|    fps                | 75       |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 1000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -32.6    |\n",
            "|    explained_variance | 0        |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | -129     |\n",
            "|    reward             | 9.092485 |\n",
            "|    std                | 1        |\n",
            "|    value_loss         | 43.5     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 71        |\n",
            "|    iterations         | 300       |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 1500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.6     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 299       |\n",
            "|    policy_loss        | 148       |\n",
            "|    reward             | 3.8559809 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 99.1      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 76         |\n",
            "|    iterations         | 400        |\n",
            "|    time_elapsed       | 26         |\n",
            "|    total_timesteps    | 2000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 399        |\n",
            "|    policy_loss        | -101       |\n",
            "|    reward             | -13.266887 |\n",
            "|    std                | 1          |\n",
            "|    value_loss         | 25.3       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 500       |\n",
            "|    time_elapsed       | 32        |\n",
            "|    total_timesteps    | 2500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.6     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 499       |\n",
            "|    policy_loss        | 367       |\n",
            "|    reward             | 6.3114533 |\n",
            "|    std                | 0.999     |\n",
            "|    value_loss         | 222       |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 600        |\n",
            "|    time_elapsed       | 40         |\n",
            "|    total_timesteps    | 3000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 599        |\n",
            "|    policy_loss        | 51.9       |\n",
            "|    reward             | -18.782887 |\n",
            "|    std                | 0.998      |\n",
            "|    value_loss         | 328        |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 700       |\n",
            "|    time_elapsed       | 46        |\n",
            "|    total_timesteps    | 3500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.6     |\n",
            "|    explained_variance | -0.00403  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 699       |\n",
            "|    policy_loss        | -70.4     |\n",
            "|    reward             | 11.462243 |\n",
            "|    std                | 0.997     |\n",
            "|    value_loss         | 79.1      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 76        |\n",
            "|    iterations         | 800       |\n",
            "|    time_elapsed       | 52        |\n",
            "|    total_timesteps    | 4000      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -32.5     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 799       |\n",
            "|    policy_loss        | -308      |\n",
            "|    reward             | 29.110567 |\n",
            "|    std                | 0.995     |\n",
            "|    value_loss         | 261       |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 900         |\n",
            "|    time_elapsed       | 60          |\n",
            "|    total_timesteps    | 4500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 899         |\n",
            "|    policy_loss        | -4.16       |\n",
            "|    reward             | 0.040970568 |\n",
            "|    std                | 0.995       |\n",
            "|    value_loss         | 0.0194      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 1000       |\n",
            "|    time_elapsed       | 67         |\n",
            "|    total_timesteps    | 5000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -32.6      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 999        |\n",
            "|    policy_loss        | 7.81       |\n",
            "|    reward             | 0.04167925 |\n",
            "|    std                | 0.999      |\n",
            "|    value_loss         | 0.06       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 75          |\n",
            "|    iterations         | 1100        |\n",
            "|    time_elapsed       | 73          |\n",
            "|    total_timesteps    | 5500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.7       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1099        |\n",
            "|    policy_loss        | 0.249       |\n",
            "|    reward             | -0.22320165 |\n",
            "|    std                | 1           |\n",
            "|    value_loss         | 0.321       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 1200        |\n",
            "|    time_elapsed       | 80          |\n",
            "|    total_timesteps    | 6000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1199        |\n",
            "|    policy_loss        | -7.09       |\n",
            "|    reward             | -0.11894466 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.0768      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 1300         |\n",
            "|    time_elapsed       | 88           |\n",
            "|    total_timesteps    | 6500         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -32.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1299         |\n",
            "|    policy_loss        | 13.7         |\n",
            "|    reward             | -0.047920235 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.184        |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 74           |\n",
            "|    iterations         | 1400         |\n",
            "|    time_elapsed       | 94           |\n",
            "|    total_timesteps    | 7000         |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -32.9        |\n",
            "|    explained_variance | 1.19e-07     |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 1399         |\n",
            "|    policy_loss        | 13           |\n",
            "|    reward             | -0.017506273 |\n",
            "|    std                | 1.01         |\n",
            "|    value_loss         | 0.222        |\n",
            "----------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 100       |\n",
            "|    total_timesteps    | 7500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33       |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -7.94     |\n",
            "|    reward             | 0.5889005 |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.139     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 1600        |\n",
            "|    time_elapsed       | 108         |\n",
            "|    total_timesteps    | 8000        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33         |\n",
            "|    explained_variance | 4.59e-06    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1599        |\n",
            "|    policy_loss        | -1.27       |\n",
            "|    reward             | -0.17499647 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.0399      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 74          |\n",
            "|    iterations         | 1700        |\n",
            "|    time_elapsed       | 114         |\n",
            "|    total_timesteps    | 8500        |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -32.9       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1699        |\n",
            "|    policy_loss        | -5.23       |\n",
            "|    reward             | 0.121452644 |\n",
            "|    std                | 1.01        |\n",
            "|    value_loss         | 0.258       |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 1800       |\n",
            "|    time_elapsed       | 120        |\n",
            "|    total_timesteps    | 9000       |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 1799       |\n",
            "|    policy_loss        | -9.82      |\n",
            "|    reward             | 0.40297443 |\n",
            "|    std                | 1.02       |\n",
            "|    value_loss         | 0.148      |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 74        |\n",
            "|    iterations         | 1900      |\n",
            "|    time_elapsed       | 127       |\n",
            "|    total_timesteps    | 9500      |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.1     |\n",
            "|    explained_variance | -1.19e-07 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1899      |\n",
            "|    policy_loss        | -3.96     |\n",
            "|    reward             | 0.3624    |\n",
            "|    std                | 1.02      |\n",
            "|    value_loss         | 0.126     |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2000        |\n",
            "|    time_elapsed       | 135         |\n",
            "|    total_timesteps    | 10000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.2       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 1999        |\n",
            "|    policy_loss        | 13.2        |\n",
            "|    reward             | -0.16888332 |\n",
            "|    std                | 1.02        |\n",
            "|    value_loss         | 0.181       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2100        |\n",
            "|    time_elapsed       | 142         |\n",
            "|    total_timesteps    | 10500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2099        |\n",
            "|    policy_loss        | 8.74        |\n",
            "|    reward             | -0.42050236 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0784      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2200       |\n",
            "|    time_elapsed       | 149        |\n",
            "|    total_timesteps    | 11000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2199       |\n",
            "|    policy_loss        | 3.82       |\n",
            "|    reward             | -0.9291038 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.41       |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 2300      |\n",
            "|    time_elapsed       | 157       |\n",
            "|    total_timesteps    | 11500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.2     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2299      |\n",
            "|    policy_loss        | -46.2     |\n",
            "|    reward             | 0.7397846 |\n",
            "|    std                | 1.03      |\n",
            "|    value_loss         | 2.29      |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2400       |\n",
            "|    time_elapsed       | 162        |\n",
            "|    total_timesteps    | 12000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.2      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2399       |\n",
            "|    policy_loss        | -4.94      |\n",
            "|    reward             | 0.28466976 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 0.789      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2500       |\n",
            "|    time_elapsed       | 168        |\n",
            "|    total_timesteps    | 12500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.2      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2499       |\n",
            "|    policy_loss        | 139        |\n",
            "|    reward             | -0.2722799 |\n",
            "|    std                | 1.03       |\n",
            "|    value_loss         | 17.7       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2600        |\n",
            "|    time_elapsed       | 177         |\n",
            "|    total_timesteps    | 13000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.2       |\n",
            "|    explained_variance | -4.95       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2599        |\n",
            "|    policy_loss        | 0.0279      |\n",
            "|    reward             | 0.035198096 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.00133     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2700        |\n",
            "|    time_elapsed       | 183         |\n",
            "|    total_timesteps    | 13500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 5.96e-08    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2699        |\n",
            "|    policy_loss        | -4.22       |\n",
            "|    reward             | 0.023600481 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0223      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 2800        |\n",
            "|    time_elapsed       | 189         |\n",
            "|    total_timesteps    | 14000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 2799        |\n",
            "|    policy_loss        | -5.68       |\n",
            "|    reward             | -0.07583821 |\n",
            "|    std                | 1.03        |\n",
            "|    value_loss         | 0.0625      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 2900       |\n",
            "|    time_elapsed       | 197        |\n",
            "|    total_timesteps    | 14500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.4      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 2899       |\n",
            "|    policy_loss        | -3.17      |\n",
            "|    reward             | 0.22952633 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.0161     |\n",
            "--------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3000      |\n",
            "|    time_elapsed       | 204       |\n",
            "|    total_timesteps    | 15000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.5     |\n",
            "|    explained_variance | 5.96e-08  |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2999      |\n",
            "|    policy_loss        | -4.08     |\n",
            "|    reward             | 0.2420506 |\n",
            "|    std                | 1.04      |\n",
            "|    value_loss         | 0.0199    |\n",
            "-------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3100       |\n",
            "|    time_elapsed       | 210        |\n",
            "|    total_timesteps    | 15500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.5      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3099       |\n",
            "|    policy_loss        | 26.8       |\n",
            "|    reward             | 0.11407583 |\n",
            "|    std                | 1.04       |\n",
            "|    value_loss         | 0.71       |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 3200        |\n",
            "|    time_elapsed       | 216         |\n",
            "|    total_timesteps    | 16000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.5       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3199        |\n",
            "|    policy_loss        | -20         |\n",
            "|    reward             | 0.111706786 |\n",
            "|    std                | 1.04        |\n",
            "|    value_loss         | 0.46        |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 3300         |\n",
            "|    time_elapsed       | 224          |\n",
            "|    total_timesteps    | 16500        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.6        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3299         |\n",
            "|    policy_loss        | -22.5        |\n",
            "|    reward             | -0.044021465 |\n",
            "|    std                | 1.04         |\n",
            "|    value_loss         | 0.579        |\n",
            "----------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 3400       |\n",
            "|    time_elapsed       | 230        |\n",
            "|    total_timesteps    | 17000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.6      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3399       |\n",
            "|    policy_loss        | 3.6        |\n",
            "|    reward             | 0.17368688 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.0291     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 74         |\n",
            "|    iterations         | 3500       |\n",
            "|    time_elapsed       | 236        |\n",
            "|    total_timesteps    | 17500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.7      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 3499       |\n",
            "|    policy_loss        | -10.5      |\n",
            "|    reward             | 0.09319966 |\n",
            "|    std                | 1.05       |\n",
            "|    value_loss         | 0.102      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 3600        |\n",
            "|    time_elapsed       | 244         |\n",
            "|    total_timesteps    | 18000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3599        |\n",
            "|    policy_loss        | -9.11       |\n",
            "|    reward             | -0.01779874 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.0715      |\n",
            "---------------------------------------\n",
            "-------------------------------------\n",
            "| time/                 |           |\n",
            "|    fps                | 73        |\n",
            "|    iterations         | 3700      |\n",
            "|    time_elapsed       | 251       |\n",
            "|    total_timesteps    | 18500     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -33.8     |\n",
            "|    explained_variance | 0         |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 3699      |\n",
            "|    policy_loss        | -3.9      |\n",
            "|    reward             | 0.3591298 |\n",
            "|    std                | 1.05      |\n",
            "|    value_loss         | 0.0217    |\n",
            "-------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 3800        |\n",
            "|    time_elapsed       | 257         |\n",
            "|    total_timesteps    | 19000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.8       |\n",
            "|    explained_variance | 1.19e-07    |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 3799        |\n",
            "|    policy_loss        | 22.8        |\n",
            "|    reward             | -0.49535602 |\n",
            "|    std                | 1.05        |\n",
            "|    value_loss         | 0.567       |\n",
            "---------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                 |               |\n",
            "|    fps                | 73            |\n",
            "|    iterations         | 3900          |\n",
            "|    time_elapsed       | 264           |\n",
            "|    total_timesteps    | 19500         |\n",
            "| train/                |               |\n",
            "|    entropy_loss       | -33.9         |\n",
            "|    explained_variance | 0             |\n",
            "|    learning_rate      | 0.0007        |\n",
            "|    n_updates          | 3899          |\n",
            "|    policy_loss        | 4.52          |\n",
            "|    reward             | -0.0007293604 |\n",
            "|    std                | 1.06          |\n",
            "|    value_loss         | 0.288         |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                 |              |\n",
            "|    fps                | 73           |\n",
            "|    iterations         | 4000         |\n",
            "|    time_elapsed       | 272          |\n",
            "|    total_timesteps    | 20000        |\n",
            "| train/                |              |\n",
            "|    entropy_loss       | -33.9        |\n",
            "|    explained_variance | 0            |\n",
            "|    learning_rate      | 0.0007       |\n",
            "|    n_updates          | 3999         |\n",
            "|    policy_loss        | 20           |\n",
            "|    reward             | -0.007884031 |\n",
            "|    std                | 1.06         |\n",
            "|    value_loss         | 0.456        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4100        |\n",
            "|    time_elapsed       | 278         |\n",
            "|    total_timesteps    | 20500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -33.9       |\n",
            "|    explained_variance | -1.19e-07   |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4099        |\n",
            "|    policy_loss        | -4.55       |\n",
            "|    reward             | 0.039580405 |\n",
            "|    std                | 1.06        |\n",
            "|    value_loss         | 0.06        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4200       |\n",
            "|    time_elapsed       | 284        |\n",
            "|    total_timesteps    | 21000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4199       |\n",
            "|    policy_loss        | 7.22       |\n",
            "|    reward             | 0.43267992 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 0.172      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4300       |\n",
            "|    time_elapsed       | 292        |\n",
            "|    total_timesteps    | 21500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -33.9      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4299       |\n",
            "|    policy_loss        | -46.4      |\n",
            "|    reward             | -1.7899743 |\n",
            "|    std                | 1.06       |\n",
            "|    value_loss         | 2.44       |\n",
            "--------------------------------------\n",
            "day: 4321, episode: 5\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1046508.35\n",
            "total_reward: 46508.35\n",
            "total_cost: 215706.96\n",
            "total_trades: 53647\n",
            "Sharpe: 0.384\n",
            "=================================\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4400        |\n",
            "|    time_elapsed       | 299         |\n",
            "|    total_timesteps    | 22000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.1       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4399        |\n",
            "|    policy_loss        | -4.17       |\n",
            "|    reward             | 0.085661225 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.0645      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4500        |\n",
            "|    time_elapsed       | 304         |\n",
            "|    total_timesteps    | 22500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.2       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4499        |\n",
            "|    policy_loss        | 4.34        |\n",
            "|    reward             | -0.08679118 |\n",
            "|    std                | 1.07        |\n",
            "|    value_loss         | 0.0338      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4600       |\n",
            "|    time_elapsed       | 312        |\n",
            "|    total_timesteps    | 23000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.3      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4599       |\n",
            "|    policy_loss        | -10.8      |\n",
            "|    reward             | 0.05703772 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.114      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4700        |\n",
            "|    time_elapsed       | 320         |\n",
            "|    total_timesteps    | 23500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.3       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4699        |\n",
            "|    policy_loss        | 1.16        |\n",
            "|    reward             | 0.015296328 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.0237      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 4800        |\n",
            "|    time_elapsed       | 325         |\n",
            "|    total_timesteps    | 24000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.4       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 4799        |\n",
            "|    policy_loss        | -4.42       |\n",
            "|    reward             | -0.24518202 |\n",
            "|    std                | 1.08        |\n",
            "|    value_loss         | 0.06        |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 4900       |\n",
            "|    time_elapsed       | 332        |\n",
            "|    total_timesteps    | 24500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4899       |\n",
            "|    policy_loss        | -17.8      |\n",
            "|    reward             | 0.14176583 |\n",
            "|    std                | 1.08       |\n",
            "|    value_loss         | 0.421      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5000       |\n",
            "|    time_elapsed       | 341        |\n",
            "|    total_timesteps    | 25000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.5      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 4999       |\n",
            "|    policy_loss        | 18         |\n",
            "|    reward             | 0.11896526 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.434      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5100       |\n",
            "|    time_elapsed       | 346        |\n",
            "|    total_timesteps    | 25500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.6      |\n",
            "|    explained_variance | -1.19e-07  |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5099       |\n",
            "|    policy_loss        | 32.4       |\n",
            "|    reward             | 0.07227537 |\n",
            "|    std                | 1.09       |\n",
            "|    value_loss         | 0.877      |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 5200        |\n",
            "|    time_elapsed       | 352         |\n",
            "|    total_timesteps    | 26000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.6       |\n",
            "|    explained_variance | 0.751       |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5199        |\n",
            "|    policy_loss        | -1.45       |\n",
            "|    reward             | 0.010540224 |\n",
            "|    std                | 1.09        |\n",
            "|    value_loss         | 0.00169     |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 5300        |\n",
            "|    time_elapsed       | 361         |\n",
            "|    total_timesteps    | 26500       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.7       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5299        |\n",
            "|    policy_loss        | -15         |\n",
            "|    reward             | -0.04159391 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.209       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 5400        |\n",
            "|    time_elapsed       | 367         |\n",
            "|    total_timesteps    | 27000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -34.8       |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5399        |\n",
            "|    policy_loss        | 8.19        |\n",
            "|    reward             | -0.10354716 |\n",
            "|    std                | 1.1         |\n",
            "|    value_loss         | 0.0756      |\n",
            "---------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5500       |\n",
            "|    time_elapsed       | 373        |\n",
            "|    total_timesteps    | 27500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5499       |\n",
            "|    policy_loss        | -3.81      |\n",
            "|    reward             | 0.39607072 |\n",
            "|    std                | 1.1        |\n",
            "|    value_loss         | 0.0321     |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5600       |\n",
            "|    time_elapsed       | 381        |\n",
            "|    total_timesteps    | 28000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5599       |\n",
            "|    policy_loss        | 14         |\n",
            "|    reward             | -0.6185014 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.151      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5700       |\n",
            "|    time_elapsed       | 388        |\n",
            "|    total_timesteps    | 28500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5699       |\n",
            "|    policy_loss        | -41.2      |\n",
            "|    reward             | -0.9996493 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 1.6        |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5800       |\n",
            "|    time_elapsed       | 393        |\n",
            "|    total_timesteps    | 29000      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -35        |\n",
            "|    explained_variance | 0          |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5799       |\n",
            "|    policy_loss        | 14.3       |\n",
            "|    reward             | 0.02291054 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.615      |\n",
            "--------------------------------------\n",
            "--------------------------------------\n",
            "| time/                 |            |\n",
            "|    fps                | 73         |\n",
            "|    iterations         | 5900       |\n",
            "|    time_elapsed       | 401        |\n",
            "|    total_timesteps    | 29500      |\n",
            "| train/                |            |\n",
            "|    entropy_loss       | -34.9      |\n",
            "|    explained_variance | 1.19e-07   |\n",
            "|    learning_rate      | 0.0007     |\n",
            "|    n_updates          | 5899       |\n",
            "|    policy_loss        | -26.6      |\n",
            "|    reward             | -0.6129975 |\n",
            "|    std                | 1.11       |\n",
            "|    value_loss         | 0.7        |\n",
            "--------------------------------------\n",
            "---------------------------------------\n",
            "| time/                 |             |\n",
            "|    fps                | 73          |\n",
            "|    iterations         | 6000        |\n",
            "|    time_elapsed       | 409         |\n",
            "|    total_timesteps    | 30000       |\n",
            "| train/                |             |\n",
            "|    entropy_loss       | -35         |\n",
            "|    explained_variance | 0           |\n",
            "|    learning_rate      | 0.0007      |\n",
            "|    n_updates          | 5999        |\n",
            "|    policy_loss        | -9.48       |\n",
            "|    reward             | -0.16473803 |\n",
            "|    std                | 1.11        |\n",
            "|    value_loss         | 0.732       |\n",
            "---------------------------------------\n",
            "======A2C Validation from:  2022-07-07 to  2022-10-10\n",
            "A2C Sharpe Ratio:  0.4420157837880598\n",
            "======PPO Training========\n",
            "{'ent_coef': 0.01, 'n_steps': 2048, 'learning_rate': 0.00025, 'batch_size': 128}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ppo/ppo_315_3\n",
            "-----------------------------------\n",
            "| time/              |            |\n",
            "|    fps             | 80         |\n",
            "|    iterations      | 1          |\n",
            "|    time_elapsed    | 25         |\n",
            "|    total_timesteps | 2048       |\n",
            "| train/             |            |\n",
            "|    reward          | 0.22599432 |\n",
            "-----------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 80          |\n",
            "|    iterations           | 2           |\n",
            "|    time_elapsed         | 51          |\n",
            "|    total_timesteps      | 4096        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010187187 |\n",
            "|    clip_fraction        | 0.122       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | -0.023      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.284      |\n",
            "|    n_updates            | 10          |\n",
            "|    policy_gradient_loss | -0.0201     |\n",
            "|    reward               | 0.052846853 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 4.58        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 79          |\n",
            "|    iterations           | 3           |\n",
            "|    time_elapsed         | 76          |\n",
            "|    total_timesteps      | 6144        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012663604 |\n",
            "|    clip_fraction        | 0.148       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.7       |\n",
            "|    explained_variance   | 0.0652      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.227      |\n",
            "|    n_updates            | 20          |\n",
            "|    policy_gradient_loss | -0.0129     |\n",
            "|    reward               | -0.06543873 |\n",
            "|    std                  | 1           |\n",
            "|    value_loss           | 0.22        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 79           |\n",
            "|    iterations           | 4            |\n",
            "|    time_elapsed         | 103          |\n",
            "|    total_timesteps      | 8192         |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.016931823  |\n",
            "|    clip_fraction        | 0.178        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -32.7        |\n",
            "|    explained_variance   | 0.0333       |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.249       |\n",
            "|    n_updates            | 30           |\n",
            "|    policy_gradient_loss | -0.0201      |\n",
            "|    reward               | -0.008240468 |\n",
            "|    std                  | 1.01         |\n",
            "|    value_loss           | 4.52         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 5           |\n",
            "|    time_elapsed         | 130         |\n",
            "|    total_timesteps      | 10240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015804946 |\n",
            "|    clip_fraction        | 0.183       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.8       |\n",
            "|    explained_variance   | 0.117       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.316      |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0104     |\n",
            "|    reward               | -0.10079539 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 0.0645      |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 6           |\n",
            "|    time_elapsed         | 158         |\n",
            "|    total_timesteps      | 12288       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013891982 |\n",
            "|    clip_fraction        | 0.145       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.8       |\n",
            "|    explained_variance   | 0.077       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.0407      |\n",
            "|    n_updates            | 50          |\n",
            "|    policy_gradient_loss | -0.0176     |\n",
            "|    reward               | 0.18823297  |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 5.25        |\n",
            "-----------------------------------------\n",
            "day: 4321, episode: 10\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 322232.89\n",
            "total_reward: -677767.11\n",
            "total_cost: 792757.05\n",
            "total_trades: 68576\n",
            "Sharpe: 0.169\n",
            "=================================\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 77         |\n",
            "|    iterations           | 7          |\n",
            "|    time_elapsed         | 184        |\n",
            "|    total_timesteps      | 14336      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01607021 |\n",
            "|    clip_fraction        | 0.171      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -32.9      |\n",
            "|    explained_variance   | -0.0798    |\n",
            "|    learning_rate        | 0.00025    |\n",
            "|    loss                 | 0.284      |\n",
            "|    n_updates            | 60         |\n",
            "|    policy_gradient_loss | -0.0144    |\n",
            "|    reward               | 0.18340608 |\n",
            "|    std                  | 1.01       |\n",
            "|    value_loss           | 1.48       |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 8           |\n",
            "|    time_elapsed         | 210         |\n",
            "|    total_timesteps      | 16384       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015061506 |\n",
            "|    clip_fraction        | 0.179       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.9       |\n",
            "|    explained_variance   | 0.0794      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.123       |\n",
            "|    n_updates            | 70          |\n",
            "|    policy_gradient_loss | -0.00908    |\n",
            "|    reward               | -0.32172188 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 6.34        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 9           |\n",
            "|    time_elapsed         | 236         |\n",
            "|    total_timesteps      | 18432       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012992622 |\n",
            "|    clip_fraction        | 0.156       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -32.9       |\n",
            "|    explained_variance   | 0.0376      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 0.597       |\n",
            "|    n_updates            | 80          |\n",
            "|    policy_gradient_loss | -0.0148     |\n",
            "|    reward               | -0.03247691 |\n",
            "|    std                  | 1.01        |\n",
            "|    value_loss           | 1.65        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 10          |\n",
            "|    time_elapsed         | 261         |\n",
            "|    total_timesteps      | 20480       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015694905 |\n",
            "|    clip_fraction        | 0.196       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33         |\n",
            "|    explained_variance   | 0.0588      |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | 1.15        |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.00967    |\n",
            "|    reward               | 0.04349726  |\n",
            "|    std                  | 1.02        |\n",
            "|    value_loss           | 6.41        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 78           |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 288          |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.018305637  |\n",
            "|    clip_fraction        | 0.208        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.1        |\n",
            "|    explained_variance   | 0.53         |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.298       |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.0143      |\n",
            "|    reward               | -0.102872185 |\n",
            "|    std                  | 1.02         |\n",
            "|    value_loss           | 0.163        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 77          |\n",
            "|    iterations           | 12          |\n",
            "|    time_elapsed         | 315         |\n",
            "|    total_timesteps      | 24576       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016995825 |\n",
            "|    clip_fraction        | 0.208       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.2       |\n",
            "|    explained_variance   | 0.113       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.189      |\n",
            "|    n_updates            | 110         |\n",
            "|    policy_gradient_loss | -0.0195     |\n",
            "|    reward               | 0.023549505 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 4.08        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 13          |\n",
            "|    time_elapsed         | 340         |\n",
            "|    total_timesteps      | 26624       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017044812 |\n",
            "|    clip_fraction        | 0.187       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.3       |\n",
            "|    explained_variance   | 0.6         |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.287      |\n",
            "|    n_updates            | 120         |\n",
            "|    policy_gradient_loss | -0.0126     |\n",
            "|    reward               | 0.061178315 |\n",
            "|    std                  | 1.03        |\n",
            "|    value_loss           | 0.125       |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 78          |\n",
            "|    iterations           | 14          |\n",
            "|    time_elapsed         | 365         |\n",
            "|    total_timesteps      | 28672       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.018921744 |\n",
            "|    clip_fraction        | 0.21        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -33.4       |\n",
            "|    explained_variance   | 0.123       |\n",
            "|    learning_rate        | 0.00025     |\n",
            "|    loss                 | -0.192      |\n",
            "|    n_updates            | 130         |\n",
            "|    policy_gradient_loss | -0.0131     |\n",
            "|    reward               | 0.000997672 |\n",
            "|    std                  | 1.04        |\n",
            "|    value_loss           | 4.43        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 78           |\n",
            "|    iterations           | 15           |\n",
            "|    time_elapsed         | 390          |\n",
            "|    total_timesteps      | 30720        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.017524285  |\n",
            "|    clip_fraction        | 0.191        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -33.5        |\n",
            "|    explained_variance   | 0.721        |\n",
            "|    learning_rate        | 0.00025      |\n",
            "|    loss                 | -0.348       |\n",
            "|    n_updates            | 140          |\n",
            "|    policy_gradient_loss | -0.0113      |\n",
            "|    reward               | -0.053615734 |\n",
            "|    std                  | 1.04         |\n",
            "|    value_loss           | 0.0472       |\n",
            "------------------------------------------\n",
            "======PPO Validation from:  2022-07-07 to  2022-10-10\n",
            "PPO Sharpe Ratio:  0.2884908050159045\n",
            "======DDPG Training========\n",
            "{'buffer_size': 20000, 'learning_rate': 0.0005, 'batch_size': 64}\n",
            "Using cuda device\n",
            "Logging to tensorboard_log/ddpg/ddpg_315_3\n",
            "----------------------------------\n",
            "| time/              |           |\n",
            "|    episodes        | 4         |\n",
            "|    fps             | 60        |\n",
            "|    time_elapsed    | 285       |\n",
            "|    total_timesteps | 17288     |\n",
            "| train/             |           |\n",
            "|    actor_loss      | -87.2     |\n",
            "|    critic_loss     | 64.9      |\n",
            "|    learning_rate   | 0.0005    |\n",
            "|    n_updates       | 12966     |\n",
            "|    reward          | 3.1638875 |\n",
            "----------------------------------\n",
            "day: 4321, episode: 20\n",
            "begin_total_asset: 1000000.00\n",
            "end_total_asset: 1040352.60\n",
            "total_reward: 40352.60\n",
            "total_cost: 999.00\n",
            "total_trades: 64815\n",
            "Sharpe: 0.439\n",
            "=================================\n",
            "======DDPG Validation from:  2022-07-07 to  2022-10-10\n",
            "======Best Model Retraining from:  2005-01-01 to  2022-10-10\n",
            "======Trading from:  2022-10-10 to  2023-01-09\n",
            "Ensemble Strategy took:  92.63844995896021  minutes\n"
          ]
        }
      ],
      "source": [
        "df_summary = ensemble_agent.run_ensemble_strategy(A2C_model_kwargs,\n",
        "                                                 PPO_model_kwargs,\n",
        "                                                 DDPG_model_kwargs,\n",
        "                                                 timesteps_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "-0qd8acMtj1f",
        "outputId": "9e3df8d7-18eb-4e85-fdf9-bdd26c33bb66"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-dac46c48-cd55-4adb-946b-f6674db13a74\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Iter</th>\n",
              "      <th>Val Start</th>\n",
              "      <th>Val End</th>\n",
              "      <th>Model Used</th>\n",
              "      <th>A2C Sharpe</th>\n",
              "      <th>PPO Sharpe</th>\n",
              "      <th>DDPG Sharpe</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>126</td>\n",
              "      <td>2021-10-04</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>PPO</td>\n",
              "      <td>0.107495</td>\n",
              "      <td>0.15471</td>\n",
              "      <td>0.135445</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>189</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>2022-04-06</td>\n",
              "      <td>PPO</td>\n",
              "      <td>-0.117186</td>\n",
              "      <td>0.075292</td>\n",
              "      <td>0.034589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>252</td>\n",
              "      <td>2022-04-06</td>\n",
              "      <td>2022-07-07</td>\n",
              "      <td>A2C</td>\n",
              "      <td>-0.18444</td>\n",
              "      <td>-0.260946</td>\n",
              "      <td>-0.229677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>315</td>\n",
              "      <td>2022-07-07</td>\n",
              "      <td>2022-10-10</td>\n",
              "      <td>A2C</td>\n",
              "      <td>0.442016</td>\n",
              "      <td>0.288491</td>\n",
              "      <td>0.090582</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dac46c48-cd55-4adb-946b-f6674db13a74')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dac46c48-cd55-4adb-946b-f6674db13a74 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dac46c48-cd55-4adb-946b-f6674db13a74');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "  Iter   Val Start     Val End Model Used A2C Sharpe PPO Sharpe DDPG Sharpe\n",
              "0  126  2021-10-04  2022-01-04        PPO   0.107495    0.15471    0.135445\n",
              "1  189  2022-01-04  2022-04-06        PPO  -0.117186   0.075292    0.034589\n",
              "2  252  2022-04-06  2022-07-07        A2C   -0.18444  -0.260946   -0.229677\n",
              "3  315  2022-07-07  2022-10-10        A2C   0.442016   0.288491    0.090582"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6vvNSC6h1jZ"
      },
      "source": [
        "<a id='6'></a>\n",
        "# Part 7: Backtest Our Strategy\n",
        "Backtesting plays a key role in evaluating the performance of a trading strategy. Automated backtesting tool is preferred because it reduces the human error. We usually use the Quantopian pyfolio package to backtest our trading strategies. It is easy to use and consists of various individual plots that provide a comprehensive image of the performance of a trading strategy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "X4JKB--8tj1g"
      },
      "outputs": [],
      "source": [
        "unique_trade_date = processed[(processed.date > TEST_START_DATE)&(processed.date <= TEST_END_DATE)].date.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q9mKF7GGtj1g",
        "outputId": "b781c89c-6771-49c1-e8c0-04cbe12e2865",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sharpe Ratio:  -0.42440723843624606\n"
          ]
        }
      ],
      "source": [
        "df_trade_date = pd.DataFrame({'datadate':unique_trade_date})\n",
        "\n",
        "df_account_value=pd.DataFrame()\n",
        "for i in range(rebalance_window+validation_window, len(unique_trade_date)+1,rebalance_window):\n",
        "    temp = pd.read_csv('results/account_value_trade_{}_{}.csv'.format('ensemble',i))\n",
        "    df_account_value = df_account_value.append(temp,ignore_index=True)\n",
        "sharpe=(252**0.5)*df_account_value.account_value.pct_change(1).mean()/df_account_value.account_value.pct_change(1).std()\n",
        "print('Sharpe Ratio: ',sharpe)\n",
        "df_account_value=df_account_value.join(df_trade_date[validation_window:].reset_index(drop=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "oyosyW7_tj1g",
        "outputId": "2b54393a-7359-4a2d-efd1-2b326afb73e1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8f16dd47-f051-4bb5-8eff-f1386aa560dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>account_value</th>\n",
              "      <th>date</th>\n",
              "      <th>daily_return</th>\n",
              "      <th>datadate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.000000e+06</td>\n",
              "      <td>2022-01-04</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2022-01-04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.003203e+06</td>\n",
              "      <td>2022-01-05</td>\n",
              "      <td>0.003203</td>\n",
              "      <td>2022-01-05</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>9.919141e+05</td>\n",
              "      <td>2022-01-06</td>\n",
              "      <td>-0.011253</td>\n",
              "      <td>2022-01-06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9.959933e+05</td>\n",
              "      <td>2022-01-07</td>\n",
              "      <td>0.004112</td>\n",
              "      <td>2022-01-07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.009521e+06</td>\n",
              "      <td>2022-01-10</td>\n",
              "      <td>0.013582</td>\n",
              "      <td>2022-01-10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f16dd47-f051-4bb5-8eff-f1386aa560dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8f16dd47-f051-4bb5-8eff-f1386aa560dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8f16dd47-f051-4bb5-8eff-f1386aa560dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   account_value        date  daily_return    datadate\n",
              "0   1.000000e+06  2022-01-04           NaN  2022-01-04\n",
              "1   1.003203e+06  2022-01-05      0.003203  2022-01-05\n",
              "2   9.919141e+05  2022-01-06     -0.011253  2022-01-06\n",
              "3   9.959933e+05  2022-01-07      0.004112  2022-01-07\n",
              "4   1.009521e+06  2022-01-10      0.013582  2022-01-10"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_account_value.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "wLsRdw2Ctj1h",
        "outputId": "be82cbfa-c015-43b6-cd95-6712b347f109"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABMYAAAG7CAYAAAAoiZl0AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC+RklEQVR4nOzdd3hb9fUG8Pdqe++97ThxnL03JBAIe4+yCaOFNqUlbWnhRxmllA5IoS2jZY+yCTM0BAKBQPbew7HjvffUvL8/ru61Hcu2JEuWZL+f58nzgDX8dYYtnXvOewRRFEUQERERERERERGNMipfH4CIiIiIiIiIiMgXWBgjIiIiIiIiIqJRiYUxIiIiIiIiIiIalVgYIyIiIiIiIiKiUYmFMSIiIiIiIiIiGpVYGCMiIiIiIiIiolGJhTEiIiIiIiIiIhqVWBgjIiIiIiIiIqJRiYUxIiIiIiIiIiIalVgYIyIiIiIiIiKiUWnEFca+++47XHjhhUhOToYgCPjoo49cfg5RFPH4449j7Nix0Ov1SElJwaOPPur5wxIRERERERERkc9ofH0AT2tvb8eUKVNwyy234LLLLnPrOX7xi19g3bp1ePzxxzFp0iQ0NDSgoaHBwyclIiIiIiIiIiJfEkRRFH19CG8RBAEffvghLrnkEuVjRqMR//d//4e33noLTU1NmDhxIv7yl79g8eLFAIDDhw9j8uTJOHDgAMaNG+ebgxMRERERERERkdeNuFHKwaxYsQKbN2/G22+/jX379uHKK6/EOeecg+PHjwMAPv30U2RnZ+Ozzz5DVlYWMjMzcdttt7FjjIiIiIiIiIhohBlVhbGSkhK8/PLLeO+997Bo0SLk5OTg17/+NRYuXIiXX34ZAFBYWIji4mK89957eO211/DKK69g586duOKKK3x8eiIiIiIiIiIi8qQRlzE2kP3798NqtWLs2LG9Pm40GhETEwMAsNlsMBqNeO2115T7vfjii5gxYwaOHj3K8UoiIiIiIiIiohFiVBXG2traoFarsXPnTqjV6l63hYaGAgCSkpKg0Wh6Fc/Gjx8PQOo4Y2GMiIiIiIiIiGhkGFWFsWnTpsFqtaKmpgaLFi1yeJ8FCxbAYrHgxIkTyMnJAQAcO3YMAJCRkTFsZyUiIiIiIiIiIu8acVsp29raUFBQAEAqhK1atQpLlixBdHQ00tPTcf311+OHH37AE088gWnTpqG2thbr16/H5MmTcf7558Nms2HWrFkIDQ3Fk08+CZvNhp/97GcIDw/HunXrfPzVERERERERERGRp4y4wtiGDRuwZMmSPh+/6aab8Morr8BsNuOPf/wjXnvtNZSXlyM2NhZz587Fww8/jEmTJgEAKioq8POf/xzr1q1DSEgIzj33XDzxxBOIjo4e7i+HiIiIiIiIiIi8ZMQVxoiIiIiIiIiIiJyh8vUBiIiIiIiIiIiIfGFEhO/bbDZUVFQgLCwMgiD4+jhERERERERERORDoiiitbUVycnJUKn67wsbEYWxiooKpKWl+foYRERERERERETkR0pLS5Gamtrv7SOiMBYWFgZA+mLDw8N9fBoiIiIiIiIiIvKllpYWpKWlKTWj/oyIwpg8PhkeHs7CGBERERERERERAcCgkVsM3yciIiIiIiIiolGJhTEiIiIiIiIiIhqVWBgjIiIiIiIiIqJRiYUxIiIiIiIiIiIalVgYIyIiIiIiIiKiUYmFMSIiIiIiIiIiGpVYGCMiIiIiIiIiolGJhTEiIiIiIiIiIhqVWBgjIiIiIiIiIqJRiYUxIiIiIiIiIiIalVgYIyIiIiIiIiKiUYmFMSIiIiIiIiIiGpVYGCMiIiIiIiIiolGJhbERrKXLjMLaNoii6OujEBERERERERH5HY2vD0Dec8vL27GjuBHZcSG4bFoKLp6agrToYF8fi4iIiIiIiIjIL7BjbIRq7jRjR3EjAKCwth2PrzuGRX/9Bte9sAU1rV0+Ph0RERERERERke+xMDZC7S9rBgCkRgXhb1dMxvycGAgC8ENBPf669qiPT0dERERERERE5HssjI1Qe8uaAADT0qNw5cw0vHn7XLz7k3kAgA93l6O4vt2HpyMiIiIiIiIi8j0WxkaovaVNAIApqRHKx2ZlRmPxuDhYbSL+9XWBw8cxqJ+IiIiIiIiIRgsWxkaoffZRysmpkb0+/oszcwEAqx10jR0ob8bixzfg/o/2s0BGRERERERERCMeC2MjUE1LF6pauqASgIkp4b1um5YehdPHSl1jT3/T3TVW2tCBm1/ejuL6DryxpQQf76kY7mMTEREREREREQ0rFsZGoL32brHc+DAE6zR9bv/FUqlr7INd5Sip70BDuwk3vbQNdW1GhOql+z/4yUFUt3B7JRERERERERGNXCyMjUD77MH7k3vki/U0PT0Kp9m7xp748ihue3U7CuvakRIZhLW/XIRJKRFo7jTjvtUcqSQiIiIiIiKikYuFsQCxr6wJd7y+Ewcrmge9714lX8xxYQzozhr7eE8FdpU0IdygwSvLZyE1KhiPXzkFOrUK64/U4INd5Z75AoiIiIiIiIiI/AwLYwGgqK4dN720DWsPVuHZDScGvK8oij06xiL7vd+MDKlrDAB0GhVeuGkWchPCAADjEsPwy7OkwtnDnx5EZXPn0L8IIiIiIiIiIiI/43Jh7LvvvsOFF16I5ORkCIKAjz76aNDHbNiwAdOnT4der8eYMWPwyiuv9LnP008/jczMTBgMBsyZMwfbtm1z9WgjUn2bEctf3obGDjMAYGtRw4DjjaUNnWjqMEOrFpCXFDbgcz9wQT4W5cbi39fPwOys6F63/XhRNqakRaK1y4J7V+8f+hdCRERERERERORnXC6Mtbe3Y8qUKXj66aedun9RURHOP/98LFmyBHv27MEvf/lL3Hbbbfjiiy+U+7zzzjtYuXIlHnzwQezatQtTpkzBsmXLUFNT4+rxRpQusxW3vbYDJ+s7kBoVBJ1GhdpWI4rq2vt9zF57t9j4pHDoNeoBn39MfChev3UOluTF97lNo1bhiSsnQ6sWsOFordKFRkREREREREQ0UrhcGDv33HPxxz/+EZdeeqlT93/uueeQlZWFJ554AuPHj8eKFStwxRVX4O9//7tyn1WrVuH222/H8uXLkZ+fj+eeew7BwcF46aWXXD3eiGG1ifjF27uxu6QJEUFavLJ8FqamRQIAthQ29Pu4wYL3XTEmPgznTUoCALy5tWTIz0dERERERERE5E+8njG2efNmLF26tNfHli1bhs2bNwMATCYTdu7c2es+KpUKS5cuVe5zKqPRiJaWll6/RppH1xzGFweroVOr8J8bZmBMfBjmZscAALYW1ff7uO7g/UiPnOO6ORkApJD+li6zR56TiIiIiIiIiMgfeL0wVlVVhYSEhF4fS0hIQEtLCzo7O1FXVwer1erwPlVVVQ6f87HHHkNERITyKy0tzWvn9wWjxYrDlVKx7/GrpmCOvSA2154DtqWw3mHOmNUm4kC5VBib4qHC2KzMKOTGh6LTbMXHu7mhkoiIiIiIiIhGjoDcSnnvvfeiublZ+VVaWurrI3mUXqPGq7fMxks3z8RFU5KVj09Lj4JOrUJ1ixHF9R19Hneitg0dJiuCdWqMiQ/1yFkEQcB1c9IBAP/dWjJg8D8RERERERERUSDxemEsMTER1dXVvT5WXV2N8PBwBAUFITY2Fmq12uF9EhMTHT6nXq9HeHh4r18jjU6jwhl5vbvognRqTEmTssO2FPYdp9xb2gQAmJgcAbVK8NhZLp2eCoNWhSNVrdhV0uix5yUiIiIiIiIi8iWvF8bmzZuH9evX9/rYl19+iXnz5gEAdDodZsyY0es+NpsN69evV+5D3bpzxvoG8O9T8sWGHrzfU0SQVulc++8WhvATERERERER0cjgcmGsra0Ne/bswZ49ewAARUVF2LNnD0pKpILJvffeixtvvFG5/x133IHCwkLcc889OHLkCJ555hm8++67uPvuu5X7rFy5Es8//zxeffVVHD58GHfeeSfa29uxfPnyIX55I8+cLKkw5ihnTNlIad9e6UnX2kP4P9tficZ2k8efn4iIiIiIiIhouGlcfcCOHTuwZMkS5f9XrlwJALjpppvwyiuvoLKyUimSAUBWVhbWrFmDu+++G0899RRSU1PxwgsvYNmyZcp9rr76atTW1uKBBx5AVVUVpk6dirVr1/YJ5CdgekYktGoBlc1dKG3oRHpMMACg3WjB4cpWAMAUD3eMyc85ITkcByta8MGuMty2KNvjn4OIiIiIiIiIaDgJ4ghIU29paUFERASam5tHZN7YqS5/dhN2Fjfir5dPxlWzpI2c93+0H29sKUFadBC++80SCILnMsZkb24twX0f7kd2bAjW/+p0r3wOIiIiIiIiIqKhcrZWFJBbKUe7udnRAIAtRVIA/7fHavGGPfvrz5dN9lrB6uKpyQjVa1BY14795c1e+RxERERERERERMOFhbEAJOeMbS1sQFOHCfe8vxcAcPP8TCwYE+u1zxui12BsQigAoKKp02ufh4iIiIiIiIhoOLAwFoBmZERBoxJQ3tSJO9/YheoWI7JjQ/Dbc/K8/rmjQ/QAgHoG8BMRERERERFRgGNhLACF6DWYZA/Y31xYD7VKwKqrpyJIp/b6544J0QEAGtpYGCMiIiIiIiKiwMbCWICamx2j/PfPFudgalrksHzemFCpMMaOMSIiIiIiIiIKdCyMBail4xMAAJNTI7DijNxh+7zRISyMEREREREREdHIoPH1Acg9MzKi8MUvT0N6dDB0muGrb8odYw3txmH7nERERERERERE3sDCWAAblxg27J9TCd9nxhgRERERERERBTiOUpJLlPB9jlISERERERERUYBjYYxcImeMNXaYIIqij09DREREREREROQ+FsbIJXJhzGwV0dJl8fFpiIiIiIiIiIjcx8IYucSgVSNEpwYA1LcxgJ+IiIiIiIiIAhcLY+SymFApgJ85Y0REREREREQUyFgYI5fJ45T1LIwRERERERERUQBjYYxcxs2URERERERERDQSsDBGLotmYYyIiIiIiIiIRgAWxshl0aH2Uco2FsaIiIiIiIiIKHCxMEYu6x6l5FZKIiIiIiIiIgpcLIyRy6JDpK2UDN8nIiIiIiIiokDGwhi5LIajlEREREREREQ0ArAwRi7jVkoiIiIiIiIiGglYGCOX9dxKKYqij09DREREREREROQeFsbIZTH2jDGT1YY2o8XHpyEiIiIiIiIicg8LY+SyIJ0aQVo1AI5TEhEREREREVHgYmGM3CKPU3IzJREREREREREFKhbGyC3yZsoGbqYkIiIiIiIiogDFwhi5pbtjzOjjkxARERERERERuYeFMXKLHMDPUUoiIiIiIiIiClQsjJFbOEpJRERERERERIGOhTFyizxKya2URERERERERBSoWBgjt3ArJREREREREREFOhbGyC0x7BgjIiIiIiIiogDHwhi5haOURERERERERBToWBgjt8hbKevajBBF0cenISIiIiIiIiJyHQtj5JZo+1ZKo8WGDpPVx6chIiIiIiIiInIdC2PklhCdGnqN9NeH45REREREREREFIhYGCO3CIKgBPBzMyURERERERERBSIWxsht8jhlQ7vRxychIiIiIiIiInIdC2Pktmh7AH99GzvGiIiIiIiIiCjwsDBGbpNHKZkxRkRERERERESBiIUxcls0M8aIiIiIiIiIKICxMEZuUwpjHKUkIiIiIiIiogDEwhi5rXuUkuH7RERERERERBR4WBgjt8WESuH7zBgjIiIiIiIiokDEwhi5jRljRERERERERBTIWBgjt3ErJREREREREREFMhbGyG3RoVJhrMNkRafJ6uPTEBERERERERG5hoUxcluYXgOtWgAA1DOAn4iIiIiIiIgCDAtj5DZBEJScMY5TEhEREREREVGgYWGMhiQ6RNpMyQB+IiIiIiIiIgo0LIzRkCgB/G0sjBERERERERFRYGFhjIYkxh7AX9vGjDEiIiIiIiIiCiwsjNGQZMWGAACOVbf6+CRERERERERERK5hYYyGZHxSOADgSCULY0REREREREQUWFgYoyEZnygVxgpq2mC22nx8GiIiIiIiIiIi57EwRkOSGhWEUL0GJqsNhbXtvj4OEREREREREZHTWBijIVGpBIxLDAMAHKlq8fFpiIiIiIiIiIicx8IYDdn4JKkwdqiShTEiIiIiIiIiChwsjNGQ5SUygJ+IiIiIiIiIAg8LYzRk8mbKw+wYIyIiIiIiIqIAwsIYDZmcMVbTakR9m9HHpyEaGR5dcwhXPLsJ1S1dvj4KERERERHRiMXCGA1ZqF6D9OhgAMDRKo5TEg1VTUsXXvi+CDuKG3H7azvQabL6+khEREREREQjEgtj5BEM4CfynDX7KyGK0n/vK2vGr9/fC1H+ABEREREREXkMC2PkEUoAPzvGiIbsk70VAICLpiRDoxKwZl8lnlp/3MenIiIiIiIiGnlYGCOP6C+AXxRFvL6lGFsK631xLKKAU9rQgd0lTVAJwP0XjMejl04EADz51XF8ai+YERERERERkWe4VRh7+umnkZmZCYPBgDlz5mDbtm393tdsNuMPf/gDcnJyYDAYMGXKFKxdu7bXfR566CEIgtDrV15enjtHIx+RRymPV7fBYrUpH//fgSr8/qMD+NW7e311NBrFjBYr7nh9J178vsjXR3HaZ/sqAQBzs2MQH2bA1bPScdvCLADAr9/bi80nWGQmIiIiIiLyFJcLY++88w5WrlyJBx98ELt27cKUKVOwbNky1NTUOLz//fffj3//+9/45z//iUOHDuGOO+7ApZdeit27d/e634QJE1BZWan8+v777937isgn0qKCEaJTw2S1obCuXfn48xsLAQDlTZ1oM1p8dTwapXYWN2LtwSqsWncUVpvjjK6Cmla8u6O0V0HXl+SusAunJCsfu/e88TgjLx5Giw03vbQN/9tf6avjERERERERjSguF8ZWrVqF22+/HcuXL0d+fj6ee+45BAcH46WXXnJ4/9dffx333XcfzjvvPGRnZ+POO+/EeeedhyeeeKLX/TQaDRITE5VfsbGx/Z7BaDSipaWl1y/yLZVKwLhEqWtMHqfcWdyI3SVNyn1O9iiYEQ2HsoZOAEC7yYqCmjaH9/nVu3txz/v78M+vC4bzaA4V1LThUGULNCoB50xIVD6uVgl45rrpODs/ASarDT99cxfe2FI86PO9t6MUH+4u8+aRiYiIiIiIAppLhTGTyYSdO3di6dKl3U+gUmHp0qXYvHmzw8cYjUYYDIZeHwsKCurTEXb8+HEkJycjOzsb1113HUpKSvo9x2OPPYaIiAjlV1pamitfBnlJd86YFMD/gr1bTHai1nFhgshbyho7lP/eU9rY5/Y2owX7y5sBAP/6pgC7S/reZzjJ3WKnjY1DVIiu120GrRrPXj8D18xOhygC9390AH//8li/2yqL69vxm/f3YeW7e1HbavT62YmIiIiIiAKRS4Wxuro6WK1WJCQk9Pp4QkICqqqqHD5m2bJlWLVqFY4fPw6bzYYvv/wSq1evRmVl9yjQnDlz8Morr2Dt2rV49tlnUVRUhEWLFqG11fGGw3vvvRfNzc3Kr9LSUle+DPKSvCR5M2ULSuo78MVB6e/EtPRIAEARO8ZomJU2dir/vae0qc/te0qaIE9YWm0i7n5nDzpMvhn5FUURn+6TxyiTHN5HrRLwp0sn4hdn5gIAnlp/vN/8tC8PVdufF9haxFwyIiIiIiIiR7y+lfKpp55Cbm4u8vLyoNPpsGLFCixfvhwqVfenPvfcc3HllVdi8uTJWLZsGT7//HM0NTXh3Xffdficer0e4eHhvX6R7+XbA/iPVLbi5U1FsIlS58sy+0hYYS0LYzS8enaM9Rzrle0obgAALBkXh6QIA07Wd+DRNYeH63i9HKpsQWFtO/QaFZaOT+j3foIg4O6zxuKec8YBAF7fUuywa2zdwWrlv7kVloiIiIiIyDGXCmOxsbFQq9Worq7u9fHq6mokJiY6fExcXBw++ugjtLe3o7i4GEeOHEFoaCiys7P7/TyRkZEYO3YsCgp8n/lDzhuXKBUoq1q68NY2aRT2toVZyIoNAcCOMRp+pQ3dHWPHqlvRfsoCiJ3F0ujkGXnxePzKKQCA/24twTdHHC8T8aZP7GOUZ+TFI8ygHfT+N8/PRJBWjeL6jj7dcHVtRqXoBwBbChtAREREREREfblUGNPpdJgxYwbWr1+vfMxms2H9+vWYN2/egI81GAxISUmBxWLBBx98gIsvvrjf+7a1teHEiRNISnI8TkT+KVSvQXp0MACgy2zDuIQwLMqNRU5cd2GsvzwkIk8zWqyobu0CIP3dtIlQ8sQAaXRS7iKbkRGNBWNiccuCLADAb97fh7q24cvlEkURn+2Vxssv6rGNciDBOg3OniB1ln28p6LXbV8froFNBLJiQyAIUqg/c8aIiALPvrImXP7sJmxl5y8REZHXuDxKuXLlSjz//PN49dVXcfjwYdx5551ob2/H8uXLAQA33ngj7r33XuX+W7duxerVq1FYWIiNGzfinHPOgc1mwz333KPc59e//jW+/fZbnDx5Eps2bcKll14KtVqNa665xgNfIg2nPPtmSgC4dVEWBEFAWnQwVIIUdM435zRcKpq6IIpAkFaNBWNiAPTOGTta1Yo2owWheo2yUfWec8YhNz4UdW1GXPyvH7BrmML4d5U0obypEyE6NZbkxTv9uEumpgAAPttXAYvVpnx83SEp3+/SaSkYb+/kZM4YEVHgeXt7KXYWN+JX7+1Fl9nq6+MQERGNSC4Xxq6++mo8/vjjeOCBBzB16lTs2bMHa9euVQL5S0pKegXrd3V14f7770d+fj4uvfRSpKSk4Pvvv0dkZKRyn7KyMlxzzTUYN24crrrqKsTExGDLli2Ii4sb+ldIw0reTBkbqsfFU6XOF71GjdQoqZOskOOUNEzkfLHUqCBMS48CAOztURjbaR81nJYeCbVKACBvfpyOjJhglDd14qrnNuOFjYVe73SUt1GePSERBq3a6cctzI1FdIgOdW0mbDohFb7ajRZ8d7zO/nwJmJstFQWZM0ZEFHiK66XXTWWNnf0uWyEiIqKh0bjzoBUrVmDFihUOb9uwYUOv/z/99NNx6NChAZ/v7bffducY5Icum56C9UeqccfpOdBrut/gZ8eFoKShA4W17cobdSJvkvPFUqOCMDUtEkDvjrEd9nyxGRlRvR43Jj4Mn/58Ie79YD/W7K/EH9ccxpbCejxx5VREBA+e/eUqq03Emv3SxYT+tlH2R6tW4fxJSXh9SzE+2lOO08bGYePxWpgsNqRHB2NcQhjmZkfjpR+KmDNGRBSATtZ1L5F5+psCXDEjFQnhBh+eiIiIaOTx+lZKGl0yYkLw2c8X4YLJvXOSugP423xxLBqF5I6xtOhgTEqJgEoAKpu7UN0i5Y7JwfszM6L7PDbcoMW/rp2GRy6ZCJ1Gha8O1+DhTw965ZxbC+tR22pERJAWC8e43iUrd2Z+caAKXWarso3y7PwECIKA2VnRzBkjIgpAXWYrKpqlizxj4kPRYbLir2uP+vhUREREIw8LYzQssrmZkoZZaWN3x1iIXoOxCVKO2O6SJlS3dKGssRMqAZiaHunw8YIg4Ia5GXju+ukAgO+O13llpPLTfdIY5XmTEqHTuP4teUZGFFKjgtBusuKLg1VYb9+oefYEaVNwZLCOOWNERAGorLEDogiE6NTK5uQPdpX1igUgIiKioWNhjIZFdlwoAKCwloUxGh5Kx5g9367nOOWOk1K3WF5iOEL1A0+Uz8+JhVoloK7NiMrmLo+e0WSx4X8HpKD8Cyc7t43yVIIgKJss//y/I2juNCM6RNdrRJQ5Y0REgUceo8yMDcHUtEhcNl1auPLwpwe55ZuIiMiDWBijYSGPUpY0dMDcY3sekbd0Z4ydWhhrxA578P7MzCiHj+3JoFUr21Y9fZX++4JaNHWYERuqx5whZO9dbN9OKRfulo6PVxYKAMDcbGlclDljRESB46Q9eD8zRnoN9dtz8hCsU2NXSRM+3lPhy6MRERGNKCyM0bBIDDfAoFXBYhNRZh9xI/KWLrMVdW1SnlZadBCA7pHJ/WXN2H5SKhCdGrzfnylyUa2syaPn/HSvFLp/weSkXoUsV41LDFOKdwBwdn5ir9uZM0ZEFHjkwlhGjHSBJyHcgJ8uzgEAvLb5pK+ORURENOKwMEbDQqUSkBUrj1MygJ+8Sx6jDNVrEBEkbZLMjQ9DiE6NdpMVB8pbAAAzM/sG7zsyNTUSALCnpMljZ5SC8u1jlC5uo3RE7hoL0qqxMDe2123MGSMiCjzF9d2jlLJl9vzII1WtsNk4TklEROQJLIzRsGEAPw2XnsH7giB1YqlVAialRij3SQw3IDnCuZX3csfY/vJmWD30RuSbIzVoN1mREhmE6enOda4N5OpZaZiZEYUVZ4yBQavucztzxoiIAsupo5SAVCTTqVXoMFnZgU9EROQhLIzRsJFzxk4wgJ+8rKxBusou54vJ5AIXAMzIjFKKZoMZEx+KEJ0aHSYrCmo80/H4yV4pH+aCKUlOn2Mg0SE6vH/nfPxsyRiHtzNnjIgocJgsNpTbC1+ZMd0/y7RqFXLipQ78I1UtPjkbERHRSMPCGA2b7Di5Y4yjlORd8lV0OV9MNq1HYWymk/liQO9uM08E8Ld2mfH1kRoA7m+jdFXPnLGaVs9u1yQiIs8qbeyATQSCdWrEhel73SZnSh6tavXF0YiIiEYcFsZo2GRxlJKGSWmj446xqWndxbCZGc7li8nkbrPdHiiMvb6lGEaLDdmxIZiQHD7k53NGZLAOE5Ol4t4XB6uH5XMSEZF7ipXg/ZA+XcXj7IWxI9UsjBEREXkCC2M0bLLt4fvVLUa0GS0+Pg2NZErHWFTvjrHECAOumZ2O8yclId/FgpQcwD/UjrGyxg78Y/1xAMDPlozxyBilsy6eKnWnvb+jdNg+JxERua6ozh68HxPc57Zx7BgjIiLyKBbGaNhEBGsRE6IDAJxk1xh5Uak9Yywtuu8biscum4Snr5sOtcq1gtTU9EgAwNHqVnSarG6f7aFPDqHLbMPsrGhcNj3F7edxxyXTUqBRCdhb1oxj7DQgIvJbcsdYz42UMnmUsqiuHUaL+z+PiIiISMLCGA2r7gB+5oyRd7QZLWjsMAOQtlJ6SmK4AfFhelhtIg5WNLv1HF8eqsZXh6uhUQn44yUTh7VbDABiQ/VYkhcPAHh/Z9mwfm4iInLeyfr+O8YSww0IN2hgtYkeWwhDREQ0mrEwRsOqO4CfHWPkHWX2fLHIYC3CDFqPPa8gCErO2B43xik7TBY89MlBAMBti7IxNiHMY2dzxZUzUgEAq3eVw2y1+eQMREQ0sJ4ZY6cSBAF5iVIcALt/iYiIho6FMRpWWfacMRbGyFvKGqR8MU92i8mmDqEw9q+vC1De1ImUyCDcdeYYzx7MBUvy4hETokNdmxHfHq31+PN/c7QGS1d9i90ljR5/biKi0cBstSlZmVkORimBHgH8fpIzVtPShe+P16GdGbJERBSANL4+AI0u8gu8wloWxsg75I2UaVF9x0+GSi6M7S1rculxBTVteH5jIQDgwQvzEazz3bderVqFS6al4MXvi/DezlIszU/w2HPbbCIe+ewQCmvb8eHuckxLjxr8QURE1EtZYyesNhEGrQrxYXqH9/F1AL/RYsVXh2qw6UQdthTW44T9dd31c9Pxx0sm+eRMRERE7mJhjIZVTo9RSlEUhz1jiUY++Sq7NzrGJqVGAABKGzpR32ZETKjjNyynemd7CcxWEUvGxeEsDxai3HXlzFS8+H0R1h+ucenrGMy3x2qVojeL30RE7jkpB+/HhPT7OinPx4WxP605jFc3F/f5+LfHPN+JTERE5G0cpaRhlR4TDEGQAtLr202+Pg6NQANtpByqcINWKe7uK3M+gP9wpfTGZdmERL8oBuclhmNSSgQsNhEf76nw2PO+9EOR8t9csEFE5B55c3emg3wx2Vh7YayyuQvN9oUzw8VqE/HZvkoAUm7lf26YgR9+dwZUgnThqKq5a1jPQ+SOncUNePqbApgszFslIhbGaJjpNWpEBEmB6PVtLIyR53mzYwyAEsC/u7QJVc1d+Pe3J3D+PzbiR//ZDKPF6vAxcgaMPPriD66cKYXwv+eh7ZRHq1qx8XgdVPa6X2VzF9qYNUNE5LJi+0bKjNj+L/CEG7RIjjAAAI4OcwD/jpMNqG83ITJYiz9dNglnT0hESmQQxidJCwF2FDcM63mI3HHP+/vwty+O4tVNJ319FCLyAyyM0bCLDtEBAOrbjT4+CY1E3swYA4Bp9sLYS98XYd6f1+Ox/x3BwYoWbClswJ6Spj73r28zoq5N+rvuq02Ujlw0JRk6tQqHK1twoNz57rf+vGzvFls2IRGxodK/8SKOUxIRuaznKOVAunPGWrx+pp7WHqwCAJyZlwCtuvutxMwMKVdyx0kuXyH/1tBuUnLxnv32hMOlETabiG+P1Q57RyYR+QYLYzTsYuyFscZ2/qAhz2ruNKO1S3pxk+KljjE5UL7NaIEoSm8ExiZI21YPVPR9cyLnv2TEBCNE7z+xjpHBOiXv7P0hdo3Vtxmxenc5AOCWhVnIjpN+PzhOSUTkOmdGKQFgXKLUoTWcmylFUcS6g9UAgHMmJva6bWZmNAB2jJH/67k5u6HdhFc3n+xznye+PIqbXtqGy579Aa1dfM9CNNKxMEbDLipYKow1sGOMPEzOF4sN1Xlt8+OE5HD8/oJ8/PrssfjuN0vw/p3zccHkZABw2Hl1WB6j9KNuMdkV9nHKj/eUDylj482tJTBZbJicGoGZGVHIsRfGClkYIyJyidlqUyIBMgcYpQR8E8B/oLwF5U2dCNapsSg3ttdtMzOlC0eHKlo4Sk9+bZe9MCZvff3Pd4W9il87Tjbg2Q0nAAAnattx9zt7YbOJw39QIho2LIzRsIsJlUcpmTFGniW/mUjx0hglAAiCgFsXZmHFGblIj5E+z6QUaVvlfgeFMXnEJc+P8sVkp+XGISFcj8YOM9YfrnbrOUwWG17bIm0mu2VBFgRBUBYUnOAoJRGRSyqaOmGxidBrVEgIMwx4X2WUsroVojg8b9q/sI9Rnj42DgatutdtSRFBSIkMgk3s3ZFD5G92FTcBAO46Mxc5cSFo6jDjpe9PApAmAu5+dw9sIrBgTAx0GhW+OlyNp9Yf992BicjrWBijYRetjFKyMEaeVabki3lnjLI/E+2FsRO1begw9b5KflQJ3g8f1jM5Q60ScOk0qWvM3XHKz/ZVoLbViPgwPc6blAQASscYRymJiFxz0h68nxkTApVq4C3GOXGh0KgEtHZZUDFMmyDlfLFTxyhlszKZM0b+zWK1YW9ZEwBgVmY0frl0LADghe8L0dxhxiOfHkJpQydSIoPw7PUz8KdLJwEAnlp/XCkME9HIw8IYDTt5lJIdY+Rp8ihlqhc7xhyJC9MjIVwPUZRGSGQ2m4hj1VJxyJ82UvYkb6fccKwWNa2uv7F6d0cpAODGeRnQaaQfKcooZV07rBw9ICJympwvlhEz+M8xnUaFbHuH7nAE8J+obUNBTRu0agFL8uId3oc5Y+TvjlS1osNkRZheg9z4UJw/KQnjEsLQ2mXBT97YgXd2lEIQgCeumoJwgxZXzEjFzfMzAQAr39mD48O8BZaIhgcLYzTs5FHKBhbGyMPkUcq06OHtGAMcj1OWNHSg02yFTqNCphNvcnwhJy4U09MjYbWJ+HBXucuPlzviFo/rfpOUEhUEnUYFk8WGcvufCRERDU7ZSBk7cPC+bDgD+OVumfk5sQg3aB3eR84Z213SBIvV/exKIm+Rx3ynpkdCpRKgUgm4+6xcAMCWQqmg++NF2ZibHaM85v/OH4+52dFoN1lx1b8348Xvi2C0WIf/8ETkNSyM0bCLDpGCLkdaYazNaMHjXxzF98frfH2UIbPaRLQE4Aae0kbfdIwB3eOUB8q7r9rLb1Ry40OhUfvvt9srZ6YBAN7bWeZSTk1zhxmN9jXmWT3exKlVArLt/3+ijuOURETOKqx1biOlbDgD+L84IBXGlk1wPEYJAGPjwxBm0KDDZMXhSnbWkP/ZVdIEAJhu3zIOSH+nJyRLRea8xDCsPHtsr8do1So8fe105CWGobHDjEc+O4Slq77Fx3vKGcpPNEL47zs1GrFiQkZex1h1Sxeuem4z/vVNAR74+ICvjzNkf1xzCDMe+VLZ2hMIRFHs7hgb5owxAJiYLBfGujvGuvPF/HOMUnb+5CQYtCoU1LRhb1nfBQL9KbJ3NsSH6RGi770FVB7vOVHDwhgRkTNMFht2Fks/dyemOJdLKW889nZhrKKpE3vLmiEIwFn5Cf3eT6USMDNDKjhsP8lxSvI/8mvb6RndhTFBEPC3K6bgsmkpeO76GdBr1H0eFxOqx2c/X4jHLpuE+DA9Shs68Yu39+DSZ35AUR2XDREFOhbGaNhFyeH7HaZh26LkTcerW3HZM5twqFLqFCqqb0eXObDbq9cdrIbZKuLtbSW+PorTGtpN6DBJv+/JkT4YpUyVCmPHa1rRaT/H0Wr/3UjZU7hBi3PsHQDv2TPDnCFn4Tga+ekO4OeLRSIiZ+wqaUSb0YKYEJ1ysWUweUnSz5eCmjavvvZYZx+jnJkRhbgw/YD3Zc4Y+au6NiOK7QsupqZF9rotPzkcq66eOuAYs0atwjWz07HhN4vx67PHIlSvwd6yZlzwj434eI/rcRRE5D9YGKNhJ3eMma0iWo2WQe7t37YW1uPyZzehvKkTWbEhCDNoIIrSC9RAVd9mRHmT1Hn1xcFqmAMkI0TuFksI1/dZIT8c4sP0iA3VwyYCh+0hyEf8eCPlqeRxyk/2VqDLbIUoiiiub8faA1XKts9TyVdIsxyM/HAzJRGRa749VgsAOG1s3KAbKWUpkUGIDdXBYhN7dSx7ktFixfu7pM3FA41RyuSOsR0nG0fEBVAaOXbZOzLHJoQiIshxTp4zgnUarDgjF+t/dTrmZEnZY794ew9+98G+gL84TjRasTBGw86gVSNYJxUuGtqGZ5xSFEXsLG7EJ3sr8Nrmk/jH+uP442eHsHpXGdrdLM7tLW3CDS9uQ0uXBdPTI/HBnfMx3l4AOV7j3EhDU4cJn++v9KuA2p7h8c2dZvxQEBiZab7MFwOkNvxJ9tGXA+XN6DJblY4qf+8YA4B52TFIiQxCa5cFVzy3CdMe+RKn/20D7nhjJ257dYfDxxQ50TFWyI4xIiKFxWrrt1j07VGpMHb62Dinn08QBEyzZyV5I/7AahOx8p29OFDeghCdGhdMTh70MVPSIqFVC6hpNaK0gQtYyH84yhcbioRwA/572xzcdcYYCALw9vZSXPL0D6hvM3rk+Ylo+LAwRj4RFSx1jdUPU87Ynz4/jMuf3YS73tqNBz4+iFVfHsML3xdh5bt7MevRr/Crd/diU0GdSwGaa/ZXwmS1YX5ODN68fS6iQ3TITZCKAceqneuSeWr9cfz0v7vwxJfH3Pq6vOHUK86f76/00Ulc48t8MZmymbKsGQU1bbCJQFSwFvGDjJ34A5VKwBUzUgFICwSaOszQ2RcGHKlqRauDZQzy9rQsB4WxLHvGWF2bEc0dgbfIgYjI04rq2jH/z1/jxpe29SmO1bR04VBlCwQBWJQb69Lzym/ydxU3eeqoAKSLig99chBr9ldCqxbw7xtmIjHCMOjjDFq1spCGOWPkT5R8MQ8VxgBpvHLl2ePw+i1zEBuqx5GqVvzti6P93p9dlET+iYUx8omYUHvO2DAUxjYcrcHzG4sAALOzonHOhERcMzsNN8/PREZMMDpMVnywqwzXvrAV176wxennPV4tdYWdNylJGd0baw/BlW8bjJxz8Oqmk35zdUnuGDszLx4AsO5QYIxTljb4tmMMACbImykrWnqMUYZBEJwbifG1n5yejZVnjcUjl0zEJysW4MDDy5AYLr0JOjXYWRTF7lFKB4WxUL1GeSw3UxLRaNdltuLON3aiptWIjcfrsP1k7+4ueYxyckoEYkJdu5gyPT0SgPSm35k33bWtRry1rWTQixZPrT+O17cUQxCAv189FQtdKNjNUnLGAmeJD41sZqsN+8qaAADTMyI9/vwLc2Px7xumAwDe2VGKQxUtfe6zs7gRM//4FVb50QVxIpKwMEY+ET1Mmynr24z49Xv7AAA3z8/Euz+Zh+dumIHHLpuMhy6agA2/XowP7pyHa2anAwC2FDY4PVpZYM9OGhMfqnzM1Y6xxg7p6+8wWZXina8dKJd+kN+6MAuxoTo0dZix6US9j081OKVjLNr3HWPHq1uxt7QJAJAXAPlismCdBnedmYsb5mZgcmokdBoVxtuDnQ9X9n6B19BuQmuX9G8lI8ZxMTInnpspiYgA4PcfHVAumADSBbGe5MKYK2OUssmpkdCopNHFiuaufu9ntFjx7IYTWPL4Bty7ej/u/O/Ofgtpr28pxpNfHQcA/OGiCU6NUPYk54x9d6zWr+IiKDA1tpuGnFl6uLIFXWYbIoK0yI4NHfwBbpiREY3zJyVBFKVplZ7/vpo7zLjrrd2obzfhs70VXvn8BBTWtuG7Y7UuTQERASyMkY9ED8MopSiK+O0H+1DXZsTYhFD87ty8PvcRBAEzMqLx2GWTEGbQAAAqmwfPw+gyW5VCTM/CmNwxVtrYoWwmHEhTj6u1r232fddYz+D9SakRSsju5/v8f5zS1xljAJAUYUBMiBSCLI+gjguAfLGB5CVJhb1Dlb07xuQxyuQIQ7/LDriZkogIeHd7Kd7bWQaVADx4YT4AYO3BKlTYf95abSI2HpfyPE8f53phLEinxnj79+pdDjq0RFHEFwercNaq7/CXtUfQZr8AuOlEPT7fX9Xn/juLG/HgxwcAAL84Mxc3zMt0+UwLxsQiOkSH8qZOfGAP7idy153/3YlznvwOBU5m+Doi/9uYlh7p9HILd/z2nDzo1Cp8X1CHDfbcQFEU8bvV+5TX2MUNHTBZWDD2NKtNxHUvbMWNL23DVf/ejGNOTvAQASyMkY/IHWNyx5Q3/HdrCb46XAOdWoWnfjRt0E2FyRFSp1F5U/9XW2Unatsg2vOj5C2bgLRxMypYC1F0bhuf/PXHhOi81jV2orYNC/78NV7+YfDnlscos+NCEGbQ4vxJSQCALw5V+fU4pSiKKFcyxnxXGBMEQRmnlIu+gV4Yk99sndoxJofqy1lijmTbRywLB/m30NxpRtUAXQ5ERIHqYEUzfm8vMv3q7HFYviALc7OjYbWJeGNLMQBgb1kTmjvNCDdoMCU10q3P03Oc8lT/WF+An7y+EyUNHYgP0+OJK6fgrjNzAQB/XHMIHabuTvl2owUr390DmwhcPDUZv1ya69Z5QvQa/HRxDgDgya+Oc1Mfuc1itWFncSPMVlEpNLnD08H7/UmPCcbyBZkApH9fZqsNb28vxf8OVEGjEqDTqGC1SZu/ybN2Fjei0v56ckdxI857aiP+uvaIU80KRCyMkU9E2zPG6r20lbKgphV/XHMIAPDbc/OUN/cDSY6U8pAqmwbvGCuo6R6j7JkfJQgCcu1dY4NdpbDaRDR3Sh1jv142DoB3usY+2FmG8qZOfOJE27YcvC+PBM7OikZMiDROudmPxylrW40wWmxQCUBS5ODBwN4kb6aUyV2EgSrfPkp5tKoV1h5t6XLHWGZM/4WxnHi5Y2zgwtgVz27Cksc3KP8eiIhGguZOM376310wWmw4Iy8ed54uFYpunp8FAHhrWwm6zFZlG+Wi3Dho1O69NJ+eIW+mbOr1caPFipfsF8ZuXZiFb369GJfPSMVPF+cgNSoIlc1dePqbAuX+j3x2CMX1HUiJDMIjl0wcUkbm9XMzkBRhQGVzF/67tcTt56HRrbihA2ar9PpjS6F7yxzk7fSA9wtjAPDTJWMQHaLDidp2PLrmMB7+9CAA4J5zxmG8/YJpAWMmPG7dQakDdsm4OJydnwCLTcQzG05g2ZPfocw+WULUHxbGyCfkUcqGdu+MDv517VF0mW1YlBuL5fMznXpMUqTUMVbhYmHsVGOdzBlr6TRDjh64bHoKJqVEeKVrTM4Hq3aiI2f/KYUxjVqFZRPt45R+vJ2y1N4tlhQRBK2bbyo8Rf69A6S8s1C9xoenGbrMmBDoNSp0mq0oaeh+UXGyTvpvR8H7MnmUsri+o9+Ow06TFcdr2tBptipdf0REgU4URfzmvb1KkWnVVVOU8a2l4+OREhmExg4zPtlbMaR8MZn8Zv9QRXOv7qyvD9egudOMxHAD7jtvPELsP5MMWjUeuEAa63z+uyIU1bXjy0PVeHt7KQQBeOKqKQg3aN0+j/w5fmHvTHv6mwJlhJPIFT0LSNtPNriVHbVmfyXKmzqh16gw1d5d6U0RQVrcbe+2fGXTSXSZbThtbBxuW5itXDRkYcyzRFHEukPVAICrZ6XhPzfOxH9umIGkCANKGjrwxDouPKCBsTBGPqGE7w+yEclde+zB579cmut0jkCKXBhzooAk/zCT3/j35OxmSnmMMkSnhl6jVsYVPNk11tJlVjbw1LQaB30xIQfvT+xR3FHGKQ/67zilfBUoJcp3wfuyCcndv3fjEgIneL8/GrVKGQftOU4pb6QcqGMsMdyAYJ0aFpvYq6jWU0WPTL/WLnaMEdHI8PzGQqw7VA2dWoVnr5+OyODu2AWNWoUb5mUAAJ7bcAJ77T+n3ckXk6VGBSE2VA+zVVS6vwHgg13lAIBLpqVAfcrrobPyE3D62DiYrDb87oN9+N0H0rKiHy/KxtzsGLfP0tMVM1KRFRuChnYTXvSTJUMUWHoWkJo7zTjqYm5Uu9GCR9ccBgDccXrOsF2wvGZ2OnLscROxoTo8caVUHO/OXx1ZhTGTxYYthfU+C70/Wt2KkoYO6DUqnGa/yHD2hET854aZAICP95Qrr12JHGFhjHwiJtR7HWO1rUbUtBohCHBqhFKWFCGN4A21Yyw33j5KOUhAaKO9KCi/WD4jL17pGrvr7d39/sC02kSn1rEDwPaiBsg/nyw2EXUD/H43tJuUUNAJyd2/b3OyohEdokNjhxlbCv1znLLMD/LFZKlRQYgMlq6y5wV4vphsfGLvnDFRFJVRyoEyxlQqQeko628zZc9/b/KWSyKiQLa1sB5/WXsUAPDAhfmY7CA37OqZadBrVCisa4coSj8vEsLdjwIQBKFPzlh9mxEbjtYAAC6fnuLwMQ9emA+tWsDWogbUt5swPikcK88e6/Y5TqVRq7DyLOn5nt9YiEYvbyOnkefUzqptRa6NU/7rmwJUNnchLToId9pz74aDRq3C366cgjlZ0XjmuhmIC9MD6H7vUDDCCmMPf3oQP/rPFvxl7RGffP51B6VusUW5sQjWdRc/J6VG4Iy8eNhE9BobJzoVC2PkE1HyKKUXMsbkN+9ZsSG9vjEOJtneMVY5SMeY2WpTigK5DvKj5FHKssbOXoG2p2qyd4xFhUhFFEEQcO+5edCoBPxQUI9lf/8OD358APVtRhgtVqw/XI2V7+7B1IfX4YwnvnUqSHLTKblg1c39F8aU4P1YKXhfplGrcI59nPKhTw6ittW3mzMdKbV3I6VF+75jTBAEzLNfaZ+VFe3j03jG+KTeHWM1rUZ0mKxQCYMXI+Uro4X9XKWr7LHsotXIjjEiCmw1rV1Y8dZuWG0iLpmajOvmpDu8X1SIDpdO6y5WDaVbTKbkjBU3AQA+3lMBi03E5NQIh69XACA7LhS3LcoGAOg0Kjx59VToNQMvK3LV+ZOSkJ8UjjajBc9+e8Kjz00jn1wYm5wqdeRvLXL+Iu2J2ja8sLEQAPDABRMGXcTladPTo/DOT+Zhdo/Xg3Jh7ERNu8+6qzytrLED72wvBQC88H0RDlW0DPIIz1t3SMoXOzs/sc9tPz9jDADgw93lKKln1hg5xsIY+URMiHTVpN1k9fimokP2N++udIsB3VspK5o6B+zIkvKSRATr1EiO6Ht1NyZUj5gQnbSZsqb/ll25Yyyqx3jF/DGxWPvLRTgzLx4Wm4hXNxdj8d82YOYfv8Ktr+7A6l3laDVaUFTXjq+P1Az6NZ1aGKtq6b/oJ49e9ByjlK1YMgbJEQacqG3Htc9v8fiCgKGSO8ZS/aBjDAAevXQS3rx9zpDyYvxJ92ZKqQtSbkVPjQqGTjPwjxFlZKC/jrFmdowR0chgsdpw11u7UdtqxNiEUPzpskkDhtff1CMD1RM/L+ScsV0ljRBFEat3lwEALpvWt1usp7vOyMWtC7Pwr2umeWWTskol4DfnSEuGXvq+CM99e6JPQaDDZMGjaw7h9L99g1+8vRsbj9f2WvhCo5PNJioTFNfOlorM24oanJqcEEURD31yEGariCXj4rB0fLxXz+qs9OhgaNUCOs1WVA7wujyQPPftCVhsIlSCNNly34f7h/Xfb3lTJw6Ut0AlAGc6+HOelh6F08bGwWoT8cwGdo2RYyyMkU+EB2mgsWddyFlbniJfpch3sTCWEKGHIABGiw0NA7T698wX6+8Fb64SwN//OKXcMdYzdwQAxsSH4cWbZ+HN2+ZgQnI4Wo0WtHZZEB+mx83zM3Hx1GQAwKeDbJlsaDcpHT7T7OMVAxXG5CyySQ4KY8mRQXjrx3ORGG7A8Zo2XPfCVr8ahyi1Z4yl+UHGGCBl6M3PifX1MTwmz/5vqbypE80dZpyU88UGCN6XyaOW/eU69OoYY2GMiALYqi+PYUthA0J0ajxz3YxBu9bHJ4XjZ0tycNn0FMzOHHqH8aSUCGhUAmpajdhwtBYHylugUQm4aOrAhbEgnRq/vyAfZ0/o22nhKYvHxuGy6Smw2ET8+X9HcP2LW1Fl79D/oaAOy578Ds9vLEJxfQc+3lOBG17choV/+Rp/++KI8nrJGa9vKcbFT/+A1bvKRkw3zmhW2dKFDpMVGpWAC6ckQ69Roa7NhBO1g2dFfXGwGhuP10GnVuHBCycMacOqJ2nVKmTY81lHQgB/VXMX3t0uFeGf+tE0hOk12FPahDe3Fg/bGb60b6OcmRGNmFC9w/v84kypa+z9nWXcUEkOsTBGPiEIAqLsAfz1Hh6nlItB+cmuFcb0GjVi7d9MK5r6LyDJV64c5YvJnMkZkwuCUcGOtz7NHxOLT1csxBu3zsF7d8zDlnvPxEMXTcAd9nXvXx+tGTCsXM4DG5sQion2QPiBNlPKwfuTUvsWxgAgIyYEb94+B3FhehypasX1L25Fs5eWJ7jCahOVnKrUaP/oGBtpIoK0ynKKw1UtKLKPEmc7URjLsP+ZOBO+38LwfSIKUF8dqsYzG6QxwT9fPnnA1wg9/WZZHlZdNRUaD2xUDtKplQ7fhz89CABYkhevLDzyJUEQ8MSVU/CXyychSKvGphP1OOep7/DT/+7EdS9sRWlDJ5IjDPjrFZNxw9wMhBs0qGzuwtPfnMDyV7Y7VeTaX9aMhz45iL2lTVj57l5c/PQPfpuNSs6RC0cZMcEI0WuUC72D5Yy1Gy145LNDAIAfn5bt1IW84TQmbuRspnzu2xMwWW2YnRWNC6ckK92hf117FDXD1BEnb6M8e0JCv/eZkRGNBWNiYLGJeHYDR7qpLxbGyGei7Z1SnuwY6zJblcLVBBc7xoDunLGeb9ZPNVDwvkzOGTte3f8PvFPD9x1RqQQszI3FrMxoZbtmXmIYcuJCYLLY8KX9B4Ejm+1jlPNzYpFoH/nsr2Osv+D9U2XHheKt2+cgNlSHgxUtuP/jA/3ed7hUt3TBbBWhUQlIHEJwMQ1Mzhk7UtmColp5I+Xghch0e2GsptXoMBeP4ftEFOhKGzqw8t09AICb52fiwinJPjuLHMB/0p6jc/n0VJ+d5VSCIODqWen47K6FmJgSjqYOMz7fXwVBAG6cl4F1K0/HVTPT8MglE7Ht/5biX9dOQ4hOjd0lTXhvZ+mAz22y2PCb9/fCahMxMSUcoXoN9pc340f/2YIfv7bDLy7kketOfc09J0vKcB0oZ0wURdzzwT6UN3UiJTIIP1syxvsHdZESwB/ghbGa1i68ta0EgDSSDQDXzcnAlLRItBoteNhenPSmpg4TttoLpWfl918YA4BfnCktAnl3R6lTy9ZodGFhjHxGvoI50Niiq45WtcImSmuR5e0vrkh2YjOlM4UxOeTWmVHK/jrG+iMIgvKie6Bxyk0n6gAA83JilE1X1f0UxvoL3ndkTHwY/nHNNADS+IOzGzK9Rc4XS44M6rOKnjynZ86YvHzCmSuwkcFahBmkcaJTW9dFUey17IKFMSIKNF1mK+787060dFkwNS0S95033qfnkQP4Aen77xl5/pGr1FNOXChW37kAK5aMwYIxMXjvJ/Pwh4snIlTfPXpq0KpxweRk3G3faPnn/w08UvnMhgIcqWpFdIgOry6fjQ2/WYzr56ZDrRKw7lA1nlp/3OtfF3le38KYNHK8tbD/nLHnNxZizb5KaNUC/nHNVATphjdw3xk58faN3U5spmzqMGH94Wqfv9525PnvCmG02DA9PRILxkhFS7VKwJ8unQi1SsCafZX4xolM5KH4+kgNrDYReYlhyohqf2ZnRWNudjTMVhGvbj7psTNYbSL+t7+Skw8BjoUx8pnoUM+PUvYM3ncnS2CwzZQ2m+hkx5hUGCtr7ES70fGb/cb2vuH7zrpgslQY23i8zmHWV3VLF07UtkMQgLlZMUonVVU/X9dAwfuOTE+PgloloKHdNGBu2XDwp42UI5lcGDtY2YxieydClhOFMUEQlK6x4lM2AbV0WtDRo4tsoNFgIiJ/9IfPDuFAeQuigrV4+rrpgy4k8TY5gB8ALpqS7PPz9EenUeHXy8bhv7fNxcwB8tVump+JcQlhaOww469fHHV4n8OVLfjX11Kg9kMXTUBMqB6xoXr88ZJJePzKyQC6LxZSYDlxymvuaelR0KoFVLV0obSh70XsTQV1+PP/jgAAHrggHzMy/HM7+Jg46X1Cf4uJZM0dZlz+7Cbc+uoOvL+zbDiO5rT6NiPe2CJ1i/38zNxe77smJEfglgWZAIDH/nfYq3l/6w7axygH6RaTXWNf4vBDgee+J/znu0Lc+d9duO2VHcw2DGD++dOSRgVvjFK6G7wvS7J3jJX30zFW0dyJTrMVWrWgZCc5Eh2iQ6y98Nff1aBGJXzftY4xQHqBkJ8UDotNxFp74GRP8hjlxOQIRARrkRghdc/1VxjbXyYVxhwF7zti0KqVfISD5cO/krknZSNlJPPFvEkpjFW0wGixQasWlNyxwaT3kzN26sgyO8aIKJC8ta0Eb24tgSAAT/5omtPfE70pNSoI6dHBEATgyhlpvj7OkGnVKvzh4gkApN/vvaVNvW63WKURSotNxNn5CbhwclKv2xeOkbZ9Hq1u5ThlACqQc33thaQgnRqTUyMB9B2nLG/qxIq3dsMmAlfMSMX1czOG9ayuyLYvJqpvN/W7zMpkseGON3Yqiwbe87PC2IvfF6HTbMXk1AgsdrBVd8UZuQjTa3Csug1fHe4/+mUousxWfHusFgCcXh4yN1vqbDtU0eKRDi+jxYqXfigCAGw72YA3hnHpAHkWC2PkM/IoZb0HRykPuRm8L5Nf1Fb2UxiTu8UyY0IGDcpVAvj7yRlr6nC/YwzAgOOU8pXR+TnSN395lLLVaHHYwbbfxY4xoDuL7GCFbwtjykZKdox5VUZ0MIJ1asid/GnRwU6HRfdXGKs8pTDW0sk3LUTk/4wWKx78+ADuXb0fgJStc7qDN4a+IAgCXl4+C2/fPrffZTqBZk52DC6dlgJRBH7/8QFY7R0Z5U2dePTzwzhQ3oKIIC3+eMnEPtMCcWF6ZMeFQBSBHcUDB7aTf2loNylxK/LoISCNwwFQcqUAKWz/zjd2oqHdhIkp4Q7/LviTEL1GiW9xdAFdFEXcu3o/NhfWI1inhiBICwf6u3A/3ERRxIe7ywEAP12c4/D3OiJIixvmScXJp78p8Moo6MGKFnSarYgN1Q+YkdxTQrgBmTHBsInAzpONQz7Dp3srUdtqhMYe5/Ln/x1RplkosLAwRj4TY++oavDQKKXNJnZvpHS3Y0wO3+9nK6UzY5Sy7gB+xzlj3Vsp3SuMXWC/KrqlsB41rb3Pu8neMTbPXhgLM2gRYs9YOHX0sc1oUX7QuvL7lq8UxprdOL3nyLlVqVHsGPMmlUrAuMQw5f+zBslx6CndHtJ/6gsF+d9ZQrjU0ciOMSLydyX1Hbji2c14dbPUFXDn4hz84sxcH5+qt5y4UMyxd0WMFPeel4cwvQb7yppxyyvbsfhv32DBn7/Gyz+cBCCNzcX3s4BHzqUabJMh+Rf5NXdKZBCCdd35cz3/PK02Ee9sL8GSxzdgX1kzooK1eO76GTBo/S9X7FQ5AwTw/+vrAnywqwxqlYBnrpuO2fZx40/29J8tPJyK6ztQ2dwFrVrA6WP7zzG8ZWEWDFoV9pY144cCz2+Ild+DTE6NcKkQKhdXtwywxMEZoijihY2FAICVZ4/F7MxodJisuHf1fr/MhKOBsTBGPiMXhBo8NEpZ0tCBDpMVeo3KqewjR5IjpRdVNa1dMFttfW6Xf3jlOlEYGzNAAH+nyQqjRXr+yBDXRykBqWNnWnokbCLwv/3d45SlDR0oa+yERiVgVo/cjgT7lanqU8Yp5Q2DsaF6RLgw1jkhWboS7fOOMXvGBDvGvG98j8KpK6vPlYyxPoUx6c9uXKL0vMwYIyJ/9tWhapz/z43YX96MyGAtXr55Fn57Tp6yNZq8Jz7MoATxf3usFifrO6BWCZiWHomHL5qAy6an9PtY+bXQVhbGAor8mjvnlNfcMzKioBKk1/3LnvwOv/1gP2pajUiPDsYLN80MmAul/W2m/HhPOZ748hgA4OGLJmDxuHhcMi1Fuc0fbC6UCkrT0qIGXG4QG6rHj2ZJmV5Pf1Pg8XMoGckuTgop200Lh/Y94YeCehypakWwTo3rZmfgL1dMhl6jwvcFdXhvh3+NvtLgWBgjn4nx8FZKeYwyLzHM6RGvU8WG6KFVC7CJjjc49vdD2pGx9vs4GqWUu8U0KgFhPbYwuerCyd3jlNUtXfjqUDWeWCeF005Ni0RIj+dWAvhP+brkFu6cONeKiXLHWHlTZ7/5CK6qbumC0WId/I52FqtN+XoC5YVQIBtqYay0oaNXKKm85CLP3onWbrIqIzJERP6kqcOEn725C61dFkxPj8Tndy3CEj/c+DiS3TgvAz9dnINbFmThhRtnYs8DZ+HDny7ATfMzB+wWkbtDDpQ397sQifxPfxejwwxaJfqjoKYN4QYN7j9/PL5ceZrfhu07kmPP6i3oMUpZ32bE/314AADw49OylZy08yYmQadW4UhVK45U+faCNNCdZTw3Z/DO1B+flg2tWsDmwnrsLB766GJPB+w5xxNciIIBgDnZnvme8Ly9W+yqmWmICNYiKzYEvzpbKuA/suZQv9nO5J9YGCOfkbdSeqwwVtG9kdJdKpWApAjHmylFUewOAXVqlFJ6s1/e1IlOU+9iT8/g/aFkIJw/OQmCAOwobsScP63Hba/twEf2NuvTTsk7GbQw5sTX1FNEkFYpeMhFyaEoqmvHvMfW46dv7HL6MZXNXbDaROg0KsSF6od8BhrY+B6jlNkuFMaSI4OgVgkwWmyobTMqH5c7xnq+6G3jOCUR+aHP9lXCaLFhXEIY3vnJPGWLNQ0fjVqFe87JwwMX5mNpfgLCDM51uadGBSMlMggWm4jdJU3ePSR5zECvuW+cl4nYUB2WL8jEt79ZgtsWZUOv8f/xyZ7kr6tnxtgzG06gzWjBxJRw/O6cPOXjEcFaLB4nva7/aLdvxylFUVQ6xuY5MbKdHBmEy6alAgCe8WDXmNFiVaZyXMlIBnp/T9hV4l6x7lh1K749VgtBAG5ZkKV8/NaF2ZiSFonWLgv+8NlBt56bfIOFMfIZeStlU4fJI10iQw3el8mbKStOCbisbzehqcMMQei+yjOQyGAtQu0dW6du35OD9yPdzBeTJYQbsGScdMVaJUi5ZpdPT8Ujl0zE7Yuye903sZ9Ryu6OMdcKY0DPAP6h54ztLW2CTQQ2FtQ5HGN1RA7eT40M4ijLMMhLCof82+zKuLJWrVLGlHsG8MvF54yYEOg10o8jT2wIIiLytNW7pLGYK2emQutmVzr5zmwll8rzOUfkHScGyPW9YkYqdtx/Fh68cAKiQob2WtpX5K+rrLETXWYryps68foWKbvwnmV9R7TlccpP9pT36r4fbidq21DbaoROo8K09EinHnPH4hyoBGD9kRqlkWGojlW1wWITERWsVRYZuMKV7EGTxYbqlq5euWEvbpQ2US7LT1SydAFArRLw2KWTAADrDlZzG24AcX+Gi2iI5B9kNhFo7jQrWyrdJX+jdTd4X5bSTwC/3NKdGhXkVKinIAhIjjTgWHUbKpo6exWeuoP33csX6+lf105DYW07suNCeoWTnkoujPXpGKuRMsZcHaUEpMLY/w5UeSRnTA5mN1lsOFrV6tTVnzJ7vlhqNMcoh0OoXoOHL56I1i6zy90S6dHBKG3oRHF9B2ZlRsNmE5UW8+RIA8IMWhjbjAzgJyK/c7KuHbtKmqASgIvsG6EpsMzOisaHu8uZMxYg2nsshhrjxoXbQBATokNEkBbNnWacqG3Dq5tOwmSxYW52NBblxva5/xl58QjTa1DR3IXtJxt8tmBDHqOcmRHl9JKDrNgQnDcpCZ/tq8SfPj+Mf1wzbcjv+w7YL8pPTHEteF82Oysaq3eXO5UzdscbO/H1kRqkRwdj8bg46fuJPe/t9tOy+tw/PzkcYxNCcay6Dd8crVGKmuTfeMmLfEarViHcIBVyGtqNg9x7YA3tJqXgkzfEwlhSpOOOseNK1kFYn8f0Ry6ylTf2fq5G+9UDdzdS9hSs02BiSsSARTFA6i4DgKqW7t9rq01EUZ1cGHOnY8xzAfxy9xcA7Cltcuox3RspOdIyXG6Ym4GfLh7j8uPksVu5Y6yu3QiT1QZBkP5uyt8LGMBPRP5m9W7pDdDC3Lh+Nx+Sf5M7xnaXNrmUZUq+UWhfDBUTogvYjrDBCIKgdI2tO1iN93dKXan3nJPnsNBj0KpxzsREAFBiU3zBlTHKnn62ZAw0KgHfF9Th9L99g+e/KxzSv0U5eF9+L+IqubC4p7QJXeb+z2G22rDxeC0A6TXsa5uLseLN3TBZbJiaFonp6VEOH3d2vvRnte5QlcPbyf+wMEY+Fa0E8A/tzfBh+xhlZkywMr7oLrkTpvKU8ceBWroHe65Ti2xN7XLH2PD9sJczxnqOUpY1dsBktUGvUSlFPFfIo5SFtW19ctRcVdajeLjXicKY2WrDl4drAEh/7uTf0noE8ANApb0jMz5MD61ahTClMMaOMSLyjbo2Y69RGUDK0/lwt/SG9fIBNh+Sf8uODUFsqA4miw37yoYe/0DeVVArZUe5mn8baORuuKe/KYBNBM7KT+i30AJ0j1N+vr/SJwVem03EFnuH1Twngvd7Gp8Ujjdum4P8pHC0dlnw6OeHcdaq7/DFQfcKRwfsF+UnprjXEJEZE4z4MD1MVtuAF+SL6tphtooI0anxnxtm4No56UiJDIJKAO4+a2y/3Wpn5ScAAL49Wjtg4Y38Bwtj5FPdhbGhdYx5InhflmwP3y8/ZZRSbr/PS3S+Y0wujJ36XHLHWGTI0EcpnSWPUta2GZVMNzlfLDsu1K2MrvhwA2JD9bCJwOEhbsnp2TG2t6xp0Pv/6+sCHK5sQWSwli3KASAjWhrVLa6XrgLLhWd52YUcotxqZMcYEQ2/V34owqxHv8Jdb+/pVRzbUdyI0oZOhOjUSgcABR5BEHrkjHGc0t8VuHExOhDlxEuvjSw2EYIA/GbZuAHvPzc7BvFhejR3mrHhaO1wHLGXYzWtaGg3IUirxuTUSJcfPzc7Bp/+fCH+esVkxIfpUdLQgZ+8vhP/WH+8z0WJgZitNqUpYqKbHWM9vycMNE55pEoq0o5NDMPZExLxp0sn4fvfLsGRR87F6acsOutpUkoEEsMNaDdZlfFT8m8sjJFPRYdImwTrh7iZUgne90RhzEHHWEFNKw5XtkCjEnCGC+vZU/rrGOsY/o6x2FA91CoBVpuIOvtmQPmFhzv5YjL5Ss3BcvevwFqstl6Zbsdr2tA2wPrk/WXN+Jd9s80fL5mI+DCOtvi77lFK6d+C/Octh/KzY4yIfGVLYT0eWXMYogh8urcCz2w4ody2epc0RnnupCQE6QJr6x31NjuThbFAoRTGRmi+mKxn4e+yaanKRvv+qFUCLp4q5Rz+Ze2RYY+fUPLFMqOg07hXRlCrBFw1Mw3f/Hoxblso5XOt+vIYHvj4oNPL2E7UtsFksSFMr1FeX7pDHqfcdrL/wtVR+4X/vMTu95iCIAz69atUgtI1tu5QtdtnpOHDwhj5VIy9Y6xxqIWxCs9spAS6M8aaOszoMElv0j/dWwkAOG1snEubJJVRyuZTM8Y8F77vLLVKQFyoVIiUQ8+7g/fdf+HRvZnS/Y6xqpYuWG0idGoVkiIMEEWp+OVIl9mKle/ugdUm4oLJSbhgMoOQA4H8wqWuzYgOk0UpPCcrHWMsjBHR8Ktq7sKKN3fBahOVjvDH1x3FhqM16DJb8dk+KcvnMnYmB7zZWdKb4J3FjbA4uf2afGO0dIzlJYZDEACtWsAvl+Y69ZifnJ6DxHADCmvb8at39w7rhkq5MObqGKUjIXoN7r8gHw9fNAGCALy+pRg/f2uXU2OHB8q73/cNZSu9vJlyZ3EjTBbH3xOOVEodY65MDMnkwtiXh6p9ukmUnMPCGPmUHKg5lI6xLrMVBfaRQE8UxsINWoTZc8oqmqTVvJ/aXxhfOCXJpeeSu2Eqm7p6fUNURimHsWMMABJO2Uwpj1IOJcPBEwH8pfYuopSoIGX1c3/jlH//8hiO17QhNlSPRy6e6PbnpOEVEaxVAvZLGzqVjrEke/E43D5K2dLJUUoiGh4miw0//e9O1LWZkJcYhg9/ugDXzE6HKAJ3vbUbL/1QhNYuC5IjDJjrow1w5DnjEsMQZtCgzWjBYfubXfI/rV1mFNdL8RojvTCWHBmEZ6+bgddumaNksQ4mNlSP526YAZ1ahXWHqvG0fYLC26w2UYmVcTV4fyA3zc/EP6+ZBp1ahc/3V+Hml7ehvm3giB05eN+ZDfYDyY0PRXSIDl1mG/aXNzm8jzxKOc6Nwtjc7BiE6TWoazNit5OLxch3WBgjn4pRMsbcL4wdrWqF1SYiOkSnBMwPVc/NlIcqW1BY2w69RoWl4xNcep7EcANUAmCy2lDXI0fNF6OU0nmkjrHqUwtjQxillDvGjla1wuzmFdjSHtslp9gzCxwF8O842YD/bCwEAPz5skkjdlPRSJUR050zVqF0jMmjlPbCGDvGiGiYPLrmEHaVNCHMoMG/b5iBIJ0aD12Uj2npkWjpsuCva48CAC6eljKkrgTyD2qVgFn2ccqtRcz88VePf3EUFpuI7NgQJEWM/KiMcyYmutyBNTUtEo9cMgEAsOqrY/jmaI03jtbL4coWNHeaEarXYNIQC1KnumByMl5ZPguheg22FDbg7L8PHMp/sEIujA2tIUIQBMzKlJYdbHUwYt3aZUa5PQ7HnY4xnUaFxfYIni85Tun3WBgjn4r2QGHsQIW8rje8380gruqZMyaPUZ6RF6+8eXeWRq1SinU9M7TkjrHhHKUEujdTVjV3oaHdpJwjO9b9K3JpUcEI02tgstqU1ndXlTXIhbFgTEmLBIA+W6NEUcT9Hx2AKAJXzEjF0nzXipTke905Yx3KVkq5Y6x7lJIdY0TkfZ/urcCrm4sBAE9ePVUp3Os1ajx3/QzEhemV+3KMcuSQw7a3n2TOmD/aU9qE17ZI/y4fuWSix17Xj0RXz0rHtXOkDtdfvLUbJ+vavfr55DHK2VnR0Kg9X0KYPyYW790xD+MSwlDfbsJPXt+Jle/sQXNH79eFNpuoTKm4G7zf0xz7iPUWBwH8x6qlbrHEcIPbUz5nKzlj7m3fpOHDwhj5lCcKY/I3xwke+OYokzfllTd24tO98hile1lWymbKRumKg9UmoqXLx6OUzV1Kt1hKZNCQAoVVKgHjh5gzVmb/vUmLDsKklAioBKC8qRM1rd3FxC2FDThS1YpgnRq/Pz/f7fOS78hjAkV17cqfbXfHGDPGiGh4WG0inlgndYOtWDIGZ57SDZ4QbsCz101HkFaNhWNikTtIIDYFDrnrQ14EQ/7DbLXh3tX7IYpSMXrBmFhfH8nvPXhhPqbbO1x/+8E+r36uzYX2fDEvjpWPTwrHJz9fgDsX50AlAKt3l2PZk99hX494laL6dnSYrDBoVcj2wHIGeUx+e1FDn5wxeeTanTFK2eJxcdCqBRTWtrvdQEDDw63C2NNPP43MzEwYDAbMmTMH27Zt6/e+ZrMZf/jDH5CTkwODwYApU6Zg7dq1Q3pOGjk8Wxgber6YLMU+Svm/A1Uob5LWtC8Z5/w2yp6ST9lM2dxphryRONJXHWMtXThRM/R8MVl3AL97mynlUcq0qGCE6DXIjZd+AO0r7X6+17ecBABcMi0FEcP8+0aeIXeM7TjZCJsohc3G2hdCyN2Y7BgjIm9bf7gaJ+s7EBGkxU+X5Di8z8zMaGy570y8vHzWMJ+OvEn+mVM3SIYRDb+Xvi/C4coWRAVr8X/nj/f1cQKCXqPGP6+dDrVKwNaiBuWit6d1ma3KNldPBO8PRK9R47fn5OH9O+cjOzYEVS1duP21HcoFVTlfLD8pHGoPjLjnJYYhNlSHTrMVu0oae9121J4vlpfkfmEszKDFvBypyMtxSv/mcmHsnXfewcqVK/Hggw9i165dmDJlCpYtW4aaGsezzffffz/+/e9/45///CcOHTqEO+64A5deeil2797t9nPSyNGzMCaKrm/rsFhtOFJpb6f14Ly73DF23F48Ois/we2uKqVjzF4YkzdShuk10HqhFXkgvQpjHsgXk8mtzAfL3esYk8P3U6Ok36vJqdLzyQH8Vc1d+OKg9MPkxnkZQzkq+VBGjFQYOyq3pkcYlNyecHaMEdEweeH7IgDAtXPSEazT9Hu/iCDtsP+cJu+SR2Qb2k3cEudHShs68PevjgEA7jtvPGJC9YM8gmQpkUFYMi4OAPDejjKvfI4PdpWhzWhBSmQQxid5rhFhINPTo/DJzxdiTHwoqluMWPHf3TBbbd1jlB5636dSCUp34vfH63rdphTGhtAxBnCcMlC4/NN+1apVuP3227F8+XLk5+fjueeeQ3BwMF566SWH93/99ddx33334bzzzkN2djbuvPNOnHfeeXjiiSfcfk6j0YiWlpZevygwyYUxo8WGDtPg63lPdaK2HUaLDaF6DTKc3ObiDLmYJXN3jBLo7j6TO8bk4P3IkOHvepJHKaubu3CiVsoiyPFAG/IEe/jl4coWlwucRosV1farQPKonZwztscewP/mthJYbSJmZ0YjL3F4fiCT56Wf8m9ULkADPTvGWBgjIu/ZX9aMbUUN0KgE3DQv09fHoWEmv+602kTlQiX5lpwh22W2YV52DK6YkerrIwWcK2akAZAKWBY3FmHtKW3Cor9+jXe3l/a5zWYT8eJG6WLCLQuzPNKl5axQvbQYJUyvwbaTDXh0zeHujZQejNBZaC+MbSzoLoyJoogjVVKNYVzC0N57nGUvjO0pbUJNS9cg9yZfcakwZjKZsHPnTixdurT7CVQqLF26FJs3b3b4GKPRCIOh90aRoKAgfP/9924/52OPPYaIiAjlV1pamitfBvmRYJ0aeo3019CdcUp5dC8/KdyjG6OSI7v/zoYbNFiUGzeE57KPUtq38DW2y8H7w79RUe4YazdZlXl9TxTGMqKlrrNWowWtRtcKGxVNXRBFIEirVraUTrUXxvaWNsFoseKtbSUAgBvYLRbQkiIMvV5QJffYNsXwfSIaDi9+L202vmByEhJHwcY76k2rVimLj+raWBjzB1uLGvDtsVroNCo8eikD991xRl48YkJ0qG014ttjtS49VhRFPPzpQZQ2dOKhTw+iqrl34ebrIzUorGtHmEGDq2cN/3vunLhQPHHVFADAK5tOKiOdE4a4kbKnhblSYWx/WZMS9l/Z3IWWLgvUKgE58UObrkkIN2BKWiREEfjqMCfi/JVLhbG6ujpYrVYkJJwSUpqQgKoqx62By5Ytw6pVq3D8+HHYbDZ8+eWXWL16NSorK91+znvvvRfNzc3Kr9LSvtVtCgyCICjFkG+P1eJAeTPKGjvQ6WT32AH76F6+B/PFAPR6sXzuxCToNO6PUqREyRlj0g8a+QrlcAfvA0CIXoMwvVSAkF8QDvWbPQAE6dTKKFxNi2u5HaX2jZRp0UHKi6FxiWHQaVRo6bLg+e8KUdtqRGyoHssmJA75rOQ7GrUKKT26MZMie3aMSX9/2k1WWDneQkReUNncic/2Sa8/b12Y7ePTkK/IOWO1rcwZ8wdfH5EKBRdMTvJImPpopNOocKl9e+67O1x7X/zN0RrsLmkCAHSYrPjT54d73f78RuliwrWz0xGq73/03JvOnpCIn58xBgBgsYnQqVVKHrEnJEUEIScuBDYR2FwodY3JY5Q5cSHQa9xfUiaTxym/5Dil3/J6cMJTTz2F3Nxc5OXlQafTYcWKFVi+fDlUKvc/tV6vR3h4eK9fFLhi7XkP9390ABf883ss/Ms3mPzwF/jKiYBCuWPMk8H7gBT8KL+BH8oYJdDdMdbQbkKnyYqmDrljzDcB8gmndOnEeSjHId7ejeZqi7AcvJ8a1T1mp1WrMNH+Z/qPrwsAANfOThtSgZL8g5wzBvQeWZZHKQGgjeOUROQFr24qhsUmYk5WNCalem4MhwILA/j9y3f2DqfFbi65IsmVM6VurvWHa5z+uy2KIp5YJ2W7nZkXD0EAPtlboXRl7S9rxlb76PnNCzK9cm5n/XLpWCy2Z6nlJYV5/D2BPB200Z4zdqRK3kjpmfeYcmHsh4J6tLk4XUPDw6W/UbGxsVCr1aiu7l2wqK6uRmKi406OuLg4fPTRR2hvb0dxcTGOHDmC0NBQZGdnu/2cNLLcdUYu5mZHY1xCGBLC9dCpVTBbRXx1eODCmM0m4pCHAxh7WnXVFPzl8klYMGZo21fCDVqlS6u8qVPpGPPFKCXQPU4JSO3JnmpZTwiXXmjKeWHOKmuURkzTonrnusk5YyaLDWqVgGvncIxyJEjrkTPWc5RSp1EpY9UtHKckIg9rN1rw5tZiAMBti9gtNprJAfwsjPledUsXjlS1QhCARfacJ3LPuMQwTEmLhMUm4qPd5U495ouDVThY0YIQnRp/u3IKfjQrHQDw4CcHYbWJeKHH6HnPXFhfUKsEPPWjafjxadm4//x8jz+/nDP2fYHcMSa9xxxq8L5sTHwosmJDYLLa8O1R18ZdaXi4VBjT6XSYMWMG1q9fr3zMZrNh/fr1mDdv3oCPNRgMSElJgcViwQcffICLL754yM9JI8PS/AS8/eN5+OLu07D1vqV43D5HXlAz8Mrh0sYOtBot0GlUGBPv+dbrOdkxuHpWukcKR0rOWFMnGu0dY5G+6hg7pTDmKfFhcseYu6OUvYPZ5ZwxQLrKwiyYkaFnAP+pL7LCgxjAT0Te8f7OMrR0WZAZE4wz89iZMpopo5QsjPmcnIc1OSUCUSG+uWA8klw1U1pc8M720kGXYVltIlZ9KXWL3bowC9EhOvxm2ThEBGlxuLIFj687qoye+8vFhIggLe47bzxmZ0V7/Lnn5sRAoxJQXN+B0oYOpWPMU4UxQRCUEH6OU/onl3sQV65cieeffx6vvvoqDh8+jDvvvBPt7e1Yvnw5AODGG2/Evffeq9x/69atWL16NQoLC7Fx40acc845sNlsuOeee5x+ThpdxtiLNcdr2gb8pi6v6x2XEOb369STe2ymbPJ1x1hE9+ikJwuK8XLHmKuFMXvHWM9RSgCYkhqp/DdD90eOnoWxnksugO6cMXaMEZEniaKI1zafBCBtVfPksh4KPLFh0uuvulaG7/uaPEZ5+lj3l1xRtwunJEOvUeF4TRv2ljUPeN/P9lXgWHUbwg0a3GovfEWH6PCrs8cCAJ7dcAJWm4h52TFemczxN6F6DaalRwKQctdO1EoNGuM8VBgDuscpvz5SA7Mb20PJu1xO0Lv66qtRW1uLBx54AFVVVZg6dSrWrl2rhOeXlJT0yg/r6urC/fffj8LCQoSGhuK8887D66+/jsjISKefk0aX7LgQqASgudOMujaT0vJ+KmVdrwe3knhL744xOXzfNx1jvUcphx68L0uwd4y5OkpZrmSM9e4eyogJxg1zMyBC+qFMI0NmjPR3LkSnRkRQ738Dcs4YO8aIyJOOVLXiRG17r4BqGr2YMeYfrDZRGVs7jYUxjwg3aHHuxER8tKcC7+4o7TV90ZPFasOTXx0HAPzk9Jxer8eunZ2ON7eWKB1Tty3K8vq5/cWCMbHYfrIRr20uhtkqIkyv6bU0aqimpUchNlSHujYTthU1YAHHh/2KW6slVqxYgRUrVji8bcOGDb3+//TTT8ehQ4eG9Jw0uhi0aqRFB6O4vgPHa1r7LYzJHWP5yf5/FUPeTFne1NUjfN83HWO9Rim90DFW60LHWIfJomzHPHWUUhAEPHLJRI+dj/zD+KQw/OT0bIf5dvJm01Z2jBGRB32+XxoHOn1sXK9FHzQ6xbEw5hf2lTWhqcOMMIOm3wIOue6qmWlSYWx7KXRqFX5+xhjE9Fi0VddmxL++LkBRXTuiQ3S4eX5mr8dr1Co8fNEEXPvCVoxNCMOSUbQUYVFuLJ786rgS5zM2McxjWcyAlJN2Zl4C3tlRinUHq/yyMCaKIgrr2j0atxMofLNzlWgQufGhKK7vwImaNszP6ftNQxRFZSPlRA9vpPSGFAcdY74bpZQKYxqV0GusbajkgpsrHWNy8H64QdOne4hGJkEQcO+54x3eFqYUxtgxRkSeIYoi1tgLY+dPSvLxacgfsGPMP3x3TOoWWzgmFho/j0QJJHOzY3D+pCSs2V+JVzadxPs7y3D7omzMHxODt7aW4LN9lTDZx/hWLBmDEH3fcsCc7Bh8efdpiA7RjarR8ympkQjTa9Bq3xrpqXyxns6eIBXGvjxUjYcumuDRwttQNHeY8cGuMvx3azFKGzux9d4zR13uHwtj5Jdy4kPx1eGafgP4a1qNqGszQSUAeR5ao+tN8ihluR+E749PCsdpY+OQl+jZbDZllLKlC6IoOvWNXg7ePzVfjEanML08SsmOMSLyjCNVrSi0j1GeOX70dD5Q/+SMsfo2E2w2cVS98fcn3x6rAcAxSk9TqQQ8fd10/Oh4Lf6y9ggOlLfg718dw9+/6r7P1LRILF+QiYumJPf7PNmjsWNIrcLcnBh8eagagHcKYwvGxCJIq0ZFcxcOVrT4PL/taFUrXthYiE/3VaDLLBVMg3VqHKhoxqLc0fVvk4Ux8ku58dI3ouP9FMbkbrGcuFAE6dTDdi539SyMWW3SQgFfVeG1ahVeu2W2x59XHqXsMtvQarQg3IlxFbljLC3atyugyT+wY4yIPI1jlHSqmBDp9YrFJqK50zzquiL8QXOHGXtKmwCwMOYti3LjsCAnFp8fqMQT646hvLETF0xJwk3zMjGFo6v9WpQbqxTGxnmh+cKgVeP0sXFYe7AK6w5W+bQwVtdmxBXPbVJed+clhuG6uRm4ZGryqPx5ycIY+SV5W2J/HWMHy6V8MV9X2Z2VEKaHSoBSFNOqBYQEQEHPFQatGuEGDVq6LKhp6XKqMCZ3jKWxY4zQHb7fwsIYEXkAxyjJEZ1GhYggrX3Jk9Gtwlhrlxk6jQp6zch6LTdcfjhRB5sovd73ZLg59aZSCbhgcjIumJzs9DTHaLfQnvslCMC4BM93jAHAWfkJUmHsUDVWnj3OK5/DGT8U1KG1y4L06GD8/eopmJ4eNar/jrAwRn5J3pZY02pEc6e5T/7UAXvH2IQAyBcDpNbcxHADKpql/K3IYN2I/MaTEG5AS1cbqluMGBM/+A+TUvtGylOD92l0CmP4PhF5EMcoqT+xoTo0d5pR22ZErgtvfksbOvDntUewZp9UcA03aBAbpkdcqB7Xz83AhQOMplG3b4/WAgBOG2WjWr40Et93eEN2XCgeuCAfBq0aEV6KvTkjLx5qlYAjVa3YX9aMSam+afT4wb4V9tyJiZiREe2TM/gTFsbIL4UZtEiKMKCyuQsFNW2YkRHV63Z5I+WEANhIKUuODFIKY1E+yhfztvhwPY7XtKHGyQB+eZQyNYpXC4mjlETkWRyjpP7EhupxorZd2Yw9mDajBc9uKMDzG4tgstiUj7d0WdDSZUFhbTsOVrTgtNw4r72ZHilEUcR3x6XC2OnjWBgj/3PLwiyvPn9UiA5LxsXjq8PVuOGlrXjj1jl9pqC6zFZ8sqcCJ+raUNnUhcrmTlS1dOHs/ET8/oJ8j5xj04l6AMC8nBiPPF+gY2GM/NaY+FB7Yay1V2GsqcOkFFTyA6RjDABSooKwo7gRgNQxNhJ1B/A7t+lJGaVkxxihe5SSHWNENFQ9xygvmMwxSuotNsy+mbJ18Ncrm0/U4663d6PWft952TH4/QX5SIkMQm1bF2pajXjok4M4Vt2G1zafxM/PzPXq2QNdQU0bKpu7oNeoMCeLXSo0Oj1x5RTc+PI27C1twjXPb8Ery2cr73e/PlKNBz85iNKGzj6Pe/H7Itw0LxPpMUN771RS34Gyxk5oVAJm898hAIC7cclv9Zcz9kOBVN3OiQvpM2Lpz5J7ZCiM3I6x7s2Ug2nuNCtZUuwYI0AaSQHYMUZEQ9d7jDLB18chPxMXai+MtQ1cGLNYbfjtB/tQ22pERkww/nPDDLx5+xzkJ4cjIliLMfFhmJ8Ti58tGQMAeOmHInSY/ONnmNUm4uM95Sizx1b4i8/3VwEAZmdFw6BlRhuNThHBWrxx62zMyoxCa5cFN7y4FZ/srcBPXt+BW17ZgdKGTiRFGHDz/Ezcd14e/nnNNMzKlApn7+0sHfLn/+GENEY5LT0SwTr2SgHsGCM/JhfGTt1Muf6wtCkk0F7o9i6MjcyOsXj7FdgaJ67Ayi/UYkN1/IZMAIDwILljzD/eVBBR4Oo5Rhmq588Y6i02VHodNlhh7H8HqlDS0IGoYC0+v2sRQvr5u3T+pCSs+vIYius78ObWEty2KNvjZ3bVU18dwz++LkBksBYv3zwL09KjBn+Ql9W3GfHCxkIAwOXTU318GiLfCjNo8eots3H7azvwQ0E97nprNwBArRJw68Is/OLM3F7fcwQB2H6yEe/vLMMvl46FWuV+bpw8Rjk/J3ZoX8QIwo4x8ltj4vp2jFmsNnx9tAYAcGZeYAXppkQalP8esaOU9o6xGic6xuT24BRupCQ7OWOshaOURDQEHKOkwcQqHWP9Z4yJooh/f3cCAHDT/Mx+i2KAtGTpjtNzAADPbyyE0WL14GldV9rQgX9/JxWgmjrMuO6FrfjuWK1PzwQA//y6AK1GCyYkh+MiLiogQrBOgxdvmoUz7O9rZ2VGYc1dC3HfeeP7fM85Kz8BUcFaVDZ3KTl9AzlU0YKfvL4DR6paen1cFEVstneMzWe+mIKFMfJb8pag8qZOpS19V0kTmjrMiAzW9gnk93ejYZQyIVx6oelMxpiSL8YxSrKTM8Y6TFZYrLZB7k1E5FhDuwmFte0QBChvNoh6inVilHLTiXocKG+BQavCjfMyB33Oy6anICFcj+oWI1bvKvfUUd3y5/8dgdFiw+ysaCzKjUWHyYpbX92Oz/ZV+OxMJ+va8caWYgDAfeeNh2oI3S5EI4lBq8YLN87E1786He/8eB7yEh1naOs1alwyLQUA8O72gccpjRYrVry1C18crMb9Hx6AKIrKbceq21DXZkKQVu0XnaT+goUx8lvRITpEh+ggikBhbTuA7jHKJePioVEH1l/f0TFKae8Ya+3q9Q3YkeM1rQCAHHtnIJHcMQZIG8CIiNxRZe9ajgnRcxslOeRM+P5z30rdYlfPTEN0yOCv2/QaNW63j1A+9+0Jn13g2VJYjzX7K6ESgIcvmoAXb5qFCyYnwWwV8fO3dg/6htpb/vbFUVhsIk4fG4cFYzi+RdSTSiUgOy500ILxVTPTAABfHa5G/QCF/We+OaG8f95R3IgthQ3KbT8USN1is7KiodME1vtpb+LvBPm1UwP4v1LyxQLvCnC4Qau88Y8coR1j8faOsS6zTQnW78/RaunPdFximNfPRYFBq1bBoJV+LDFnjIjcVWPvWpa7mIlO1Z0xZnJ4Ie9gRTM2Hq+DWiW4lBd27Zx0RAVrUVzfoYzzDierTcTDnx5SzjI+KRw6jQpP/Wgarp+bDlEEHllzCFbbwBcvPW1XSSPW7K+EIAD3npc3rJ+baCQZnxSOyakRMFtFfLjbcWdqQU0bnt0gFfbz7O+z/vXNceX27nwxjlH2xMIY+bXuAP5WFNW140RtOzQqAaeNjfPxydwzPklqjc2OC/HxSbzDoFUrm0IHyhmz2UQcr5Y6xsYmsDBG3eTuDuaMEZG75I6xxHDDIPek0UoepTRZHV/I+/e3Uj7X+ZOSkBbtfBZqsE6DWxZkAZA6Ngbrnve0d7aX4nBlC8INGqw8a5zycbVKwMMXTUSwTo3WLgsKa9sGeBbPEkURj31+GABwxfTUfsfEiMg5ctfYO9tL+3yPEUUR9324HyarDUvGxeGFm2ZCoxLwQ0E9dhY3wmK1YWuhVBhbwOD9XlgYI7/WM4BfHqOckx2N8AAdjXj62un48KfzMSZ+5BaDnNlMWdbYiQ6TFTqNCpkxDN+nbnJXJTvGiMhd1fbCWDwLY9QPg1aNMHuw9ak5Y6UN3d1ePz7N9e2SN87LRLBOjaPVrdh+snHoh3VSc6cZj687CgC4+6yxfcY/1SoBE1MiAAB7SpuG7VzrDlVj+8lGGLQqrDx77LB9XqKR6qKpyTBoVThe04bdp/xbfm9HGbYVNSBIq8YfLp6I1KhgXDZdyiX719fHcaCiBa1GC8INGuQns0jdEwtj5NdyE+SOsTZljHLp+ARfHmlI4sL0Iz7kUN5MWT1Ax9hRe7fYmLjQgMuKI++SO8ZYGCMid1VzlJKc0F/O2IvfF8FqE7EoN1YpJLkiIliLCydLGxff3lYy9IM66dVNJ9HQbsKY+FBcPzfD4X2mpkUCGN7C2Jtbpd+D5QuykBTBhUtEQxVu0OK8idLG5Xe2laLLbEWHyYKyxg48au/OXHnWWKXb9aeLx0AlAN8crcV/7Jt25+XEQM0FGL3wHSn5NXmUsri+Q7nqFsiFsdEg3onNlMfshTHmi9GpwpWOMY5SEpF7qjlKSU6Is49T1vboGLPZRKzeVQYASpC+O66eLY06rdlfiebO4fl5tr+8GQBw/Zx0aPu56CgXxvaWNQ3LmURRxAH7uZZNSByWz0k0Glw1yz5OuaMUeb9fi/wHvsDCv3yD5k4z8pPCsXxBpnLfzNgQXDRFKtZ/vr8KADCfY5R9sDBGfi0x3IBQvQZWmwirTcTYhFCXsh5o+PXcTNmfI1UsjJFjHKUkoqGSC2MJLIzRAGLD7AH8PTrGjte0oaXLgmCdekjB1NPSIjEuIQxGiw0f73EckO1ppQ0dAKQ3wf2ZYi+MHalsRZfZ6vUzVbV0ob7dBLVKUELAiWjo5mRFY2ZG3ymkMIMGf7l8cp+JnJ8tGQOhR4PYgjEM3j+VxtcHIBqIIAjIiQ/FXnvL95nsFvN78uhKzUAdY3JhjMH7dIowvTxKyY4xInJPd8YYRympf3IAf12bSfnY9pMNAIBp6ZFDinoQBAFXz0rDHz47hLe2leKGuRkQBO+NLYmiiBJ7YSwjpv/CWHKEAbGhetS1GXGwogUzHLyx9qSD5S0ApOgMg1bt1c9FNJoIgoD37piHlk4LVCopQ1AlCNCqVQ5HJHMTwnDuxER8vr8K8WF65NhzvKkbO8bI743p8Q+XY5T+T+4Y6y9jzGSx4YR9G9JYXj2kU4QHsWOMiNxnttqUQgdHKWkg3YWx7gt5O4ul2I4ZGdFDfv7LpqdAp1HhcGWLMuboLXVtJnSYrBAEICWy/xwvQRAwNU3KTds7DDljByqkr3tCCkO+iTxNEAREBGsRZtAiWKeBQaseMDfsV2ePQ3ZsCG5dmOXVQn2gYmGM/J4cwB8TolOyEch/KR1j/WylLKprh8UmIkyvQXIE37RQb3L4fgs7xojIDbX2nz1atYCoYN0g96bRzFFhbEex1DHmaETJVZHBOpw7UcrVemtb6ZCfbyByt1hyRBB0moHf3k1JjQQwPAH8ByukjrEJya4vMSAiz8qJC8XXv16Mn5ye4+uj+CUWxsjvLR2fgIggLZYvyOT2jADQcyulKIp9bpc3Uo5NDOPVCupDzhhrYccYEbmhSh6jDDNAxdcMNIDYUKlwWmvvMKxp6UJpQydUgjRK6QlX2wOyP9lTjnaj936ulTS0AwDSncjhnTKMAfwH7Z1yE5PZMUZE/o2FMfJ7Y+JDsffBs7HijFxfH4WcEGdff2602NDS2fdFoJwvNpb5YuSA3DHGUUoickeNErzPfDEaWKz99Yocvr/DPkY5LjFc+Vk0VPOyY5AZE4x2kxVr9lV65DkdKanvBOBkYczeMVZc34HGdtPAdx6ChnYTKpqlf4/5LIwRkZ9jYYyIPMqgVSMiSHpB6WgzpbyRktuJyJHurZQcpSQi11U1cyMlOSeuxyilKIrYcVIqjHlijFImCAKusneNvb29xGPPeyp5lDI9ZvDCWESwFtn2zZXe7Bo7aM8Xy4wJ9lihkYjIW1gYIyKPk6/UVzvYTHmsmh1j1L/uwhg7xojIddX27h8WxmgwcsaY0WJDm9HSnS+W6dlNjVfMSIVGJWBXSROOVLV49LllroxSAj3GKUu9txSA+WJEFEhYGCMij+tvM2WHyaJc1RzHjjFyIFwZpWTHGBG5rrqFHWPknCCdGiE6NQCgtKFTKeTMzBz6Rsqe4sMMOCtf2qr+6qZijz63TOkYc7YwlmrfTOnFjrED5dxISUSBg4UxIvK4+H42Ux6rbgMg5ZBFh3BbGPXFjjEiGopqZoyRC+ScsfWHq2G1iUiKMCAlMsjjn+em+ZkAgI92l6O5w7MXfrrMVqVD39WOsT2lTQ4XJXnCIXaMEVEAYWGMiDyu52bKnuTg/XEco6R+yDkkHSYrLFabj09DRIFGLhAksmOMnCCPU649WAUAmOHBfLGe5mRFIy8xDJ1mK97dUerR5y61d4uFGTSIDHYuy2t8Uji0agEN7SaUNXZ69DwA0Ga0oLBOGu+cwOB9IgoALIwRkcfFh8kdY70LY0eZL0aDkDvGAOmFNRGRK+QLMvEsjJETYkOl7nVljNJLhTFBEJSusde2nITV5rkurZ5jlIIgOPUYg1aN/CSpYLWntMljZ5EdrpR+PxPDDUrxkYjIn7EwRkQeJ3eM1ZwSvn+UGylpEFq1Cgat9KOJ45RE5IoOk0X5vpEYwcIYDe7Uoo2n88V6umRqCiKCtCht6MQ3R2o89ryu5ovJugP4mzx2FpmcLzaR+WJEFCBYGCMij1O2UvbXMcbCGA1ADuBv6TKjpL4Dv3p3L6Y/8iXW2UddiIgckccoQ3RqhOo1g9ybqHdhLFin9uqFuyCdGj+alQYAeGXTSY89b3G9vTAW42JhLDUSgHcC+OUOvHzmixFRgGBhjIg8rnsrpVEJdW1oN6HWHsafGx/qs7OR/5PHKf/0+WGc8cQGfLCrDA3tJjz51XEfn4yI/FlVMzdSkmvk8H0AmJYeCY3au2+Nrp+bAZUAfF9Qh4KaVo88Z+kQO8b2lzfD7OFMT6VjjPliRBQgWBgjIo+Ls7/QNFlsaO6Uti/JY5Tp0cEI4ZV8GoAcwP9DQT0sNhGLcmOhU6twqLIFByuafXw6IvJXcq4lC2PkrLjQ7g3ZMzK8N0YpS4sOxpnjEwAAr24q9shzujtKmR0bglC9Bl1mGwpr2z1yFkDakllQI20hn5DCjjEiCgwsjBGRxxm0amUz0rInv8P9H+3HJ3vLATB4nwY3NkHqKJyTFY337piH12+dg7MmSG8k3ttR5sujEZEfk4P35XF+osH0HKWclemd4P1T3WwP4f9gVxlausxDei6bTVQKYxnRIS49VqUSkGv/eXus2jPda/JzWWwiooK1SGbWHxEFCBbGiMgrfnxaNkJ0alS3GPHGlhK8tU1aTz4ukWOUNLA/XjIJX//qdLz947mYZQ9CvnJGKgDgoz3lMFqsvjweEfmpqmZpXJ8dY+Qs+e+KSgCm2kcLvW1+Tgxy40PRYbLinvf2ocvs/s+02jYjjBYb1CoBSZGu/70fGy9drDzuwcKYnC82ITnC6S2ZRES+xsIYEXnFTxePwa4HzsLLy2fhmtnpiA3VQxCgjBAQ9UenUSE7LrTXC+pFuXFIDDegqcOM9Yc9t82LiEaOao5SkotSo4Lwk9Oz8fsL8pUxfm8TBAH3X5APnVqFtQercPPL29A6SOeYzSbiZ//dhVte2d4rD0wO3k+ONEDrRj5ad8dYm8uP7Y+cLzaBGymJKICwMEZEXqPXqLFkXDweu2wStt13Jg7/4RxMTx+eUQUaWdQqAZfPSAEAvLuj1MenISJ/VM3wfXKRIAi499zxWL4ga1g/7+lj4/DK8lkI1WuwpbABP/rPFmVBkSPfHK3Bmv2V+PpIDb47Vqt83N0xStk4+xbOYx5aBNBpsmLHyUYAUscYEVGgYGGMiIaFSiXAoFX7+hgUwK6YIa25/+5YrbJ9johIJneMJUYwY4z83/wxsXj7x3MRG6rDwYoWXPHcJmXD5Kn+812h8t89szblwliai8H7Mjn3tbi+Y0gjnQCwq6QR5/1jI45Wt0KnUWFmBi+EElHgYGGMiIgCQlZsCGZnRsMmAqt3M4SfiLqJoojqFqnjJj6MHWMUGCamROD9O+YjLToIxfUdWPHmLlhtYq/77C1twtaiBqjs6QLrj1Sjod0EACipl7ZJurqRUhYfpke4QQOrTXR7M6XJYsMT647iimc3oaiuHYnhBrx00ywkRwa59XxERL7AwhgREQWMK2ZKIfzv7SiDKIqD3JuIRoL1h6tx00vbUNPSf6doU4cZJouUvRTPrZQUQDJjQ/DuT+YhTK/B3rJmvLmtpNftz2+UusUumZqCSSkRMFtFfLxH2vStjFLGuFcYEwRB6Ro77sY4pdFixdX/2Yx/fl0AmwhcOi0FX/zyNCzMjXXrPEREvsLCGBERBYzzJyUhWKdGUV07dhY3+vo4RORlXWYrfvvBPnx7rHbAfEF5jDI6RAe9hmP7FFiSIoLwm3PGAQD+uvYIaux/n0sbOvD5/koAwG2LsnHFjO6LQwBQ0tAJwP2OMQDItRfGjrmxmfL9nWXYXdKEcIMGz1w3HX+/eioigodniQERkSexMEZERAEjRK/B+ZOSADCEn2g0eHtbCerapLGxHQMUw+XcwfgwdotRYLpuTgYmp0agtcuCR9ccBgC89EMRbCKwKDcW+cnhuHhqMnRqFQ5VtmDHyQbUtUnjw+5mjAHAWDc3U5qtNjy74QQAYOVZY3Ge/WczEVEgYmGMiIgCyqXTpO2UXx+p4Tgl0Qhmstjw7x6h47uKG2GzOf43X2PPF+NGSgpUapWARy+ZBJUAfLynAmv2VeKd7dIFoNsXZQMAIoN1OCs/AQCw6stj9o9pERHkfpeWMkrpYsfYx3sqUNbYidhQHX40O93tz09E5A9YGCMiooAyIzMKQVo16tpMOOrG6AcRBYbVu8pQ2dyF+DA9grRqtHRZcKLWcVdLtT1/LJGFMQpgk1IjcOO8TADAXW/vRofJirzEMCzqkdklZ21uOlEPYGhjlACQa+8YK25wfjOl1SbimW8KAEgjntw6TkSBjoUxIiIKKHqNGrOzogEA3x+v8/FpiMgbLFYbnrGPaf3k9BxMSYsAgH6zBavshbEEBu9TgPvV2WMRH6ZXtlP++LRsCIKg3L5oTGyvkeGhjFECQFyoHpHBWogiUFDj3Djl5/srUVjXjoggLa6fmzGkz09E5A9YGCMiooCzcIx09fyHAhbGPMliteHrI9X42X934Rdv74bFavP1kWiU+nRfBUoaOhAdosM1s9MwIyMKQP+FsWp5lDKCHWMU2MIMWjx44QQAQHKEARdMTu51u0atwmXTU5X/zxhiYUwQBIyNd34zpc0m4ml7t9gtC7IQqtcM6fMTEfkDficjIqKAs8BeGNta1ACTxQadhtd5hqK0oQNvbSvBB7vKlAIDAFwzOx1zs2N8eDIa6SxWG375zh40d5px7ex0nJWfAJUg4OlvpG6xWxdmIVinwcyMaAAnBiiM2TvGwlgYo8B3/uQkhBlmIy062OHPtytnpuK5b6V/I0MdpQSAsYmh2HaywakA/vVHanCkqhWheg1unp855M9NROQPWBgjIqKAk5cYhpgQHerbTdhT2qSMVpLrWrvMOOfJ79BukrJlooK10KpVqGk1oqiunYUx8qpdJU34bF8lAGDj8TokRRgwLzsGBTVtCDdocOM8aUxrWnokAKCwrh0N7SZEh+h6PY9SGGPGGI0Qp42N6/e2nLhQLMqNxQ8FdZhq/7cxFM4G8IuiiH99fRwAcMO8DEQEux/6T0TkT3iJnYiIAo5KJWC+vWvse45TDsnhyla0m6yIDNbimeumY+t9S3H+5CQAQGE/QedEnrLZHiCeGROM6BAdKpu7sHp3OQDg5gVZCDNIb7wjg3UYEy+FhO86pWvMYrWhrk0epWTGGI0Oz14/A+t/tRh5ieFDfq5c+yjlQAttdhY34OaXt2NvWTMMWhVuXZg15M9LROQvWBgjIqKAtHCM1MnEnLGhkd8ITU+PwnmTkqDTqJAdGwIAKKpr9+XRaBTYXCj9+71tUTY2/e4MPHHlFExLj8Tk1AjcsiCz131npNtzxkp6F8bq2kywiYBaJSAmhIUxGh1C9Rpk2b9XD9VY+2bK0oZOdJgsvW7bUliPa5/fgsuf3Yxvj9VCrRJwz7I8xIby3xoRjRwcpSQiooAk54ztKW1Ca5dZ6Swh1xyrkgpj8igNAGTHSW+SCmtZGCPv6TJbsaukCQAwLycGBq0al89IxeUzUh3ef0ZGFN7ZUYqdJ3sXxuSNlHGheqhVgqOHEtEAYkL1SjxBQU0bJqdGAgBe2FiIP645DADQqARcMSMVdy7OQUaMZwpyRET+gh1jREQUkFKjgpEZEwyrTcTWwgZfHydgyR1jcscAAGTHSW96Sho6YOZmSvKSXSWNMFlsiA/TK12KA5mRKXWM7S1rgsnS/ffyne2lAIDcHn+Hicg18r8fOYC/oKYVf117FABw9cw0bPjNYvz58sksihHRiMTCGBERBawFzBkbElEUlbDlnh1jCWEGBGnVsNhElDZ0+Op4NMJtseeLzcuJgSAM3umVHRuCyGAtjBYbDlW2AACOVrXine0lAIC7zsz13mGJRrieAfxWm4h73t8Hk9WGJePi8OfLJyE1aujbL4mI/BULY0REFLAW2gtjzBlzT22bEY0dZqgEKMHmgLTcQM6u4TglecvmQnthzMnNp4IgdOeM2QP4//T5YdhE4JwJiZiVye20RO7KtRfGjlW34pVNJ7GrpAmheg0evXSSU4VrIqJAxsIYEREFLKnTBDhe04Zqe84QOe9YlTQykxkTAoNW3es2eZyysI6bKcnzOk1W7CltAiD9O3bW9AypMLaruBHfHavFt8dqoVUL+N25ed44JtGoMdZ+cWRPaRMe/0IaobzvvPFIjgzy5bGIiIYFC2NERBSwIoN1mJQSAYBdY+6Q88UcZTNxMyV5047iBpitIpIjDEiPdn5Ea4a9MLb9ZAP+9LkUCn7D3Exkemg7H9FoJY9SNnaY0Wm2Yl52DK6ZnebjUxERDQ8WxoiIKKApOWPHWRhzlZwvNq5HvphM3kx5gqOU5AWb7Plic53MF5NNSY2ERiWgptWII1WtCDdocNeZY7x1TKJRIypEh9hQPQAgSKvGny/nCCURjR4sjBERUUBTcsZOsDDmKmUjZaKjwhg7xsh7Np9wLV9MFqRTY0JyuPL/d52Zi8hgnUfPRjRazciIBAD8Ztk4bp8kolFF4+sDEBERDcXEZGmUsrrFCKPFCr1GPcgjCJA2Uh6r6r9jTA7fr201orXLjDCDdljPRyNXm9GC/eXNAFzLF5NNz4jC3rJmpEcH44Z5GZ4+HtGo9adLJ+Gm+ZkuF6yJiAIdO8aIiCighRk0UKukcY/GdrOPTxM4yps60W6yQqsWHOYzhRm0iAuTxmq4mZI8aXtRA6w2EenRwUiNcj5fTHbLgiyclZ+Av189lYVwIg+KCdVjfk4sRyiJaNRhYYyIiAKaSiUgyj5K1dBu8vFpAsfxamnbZHZsKLRqxy8HGMBP3rC50L0xSlladDCev3GmEsRPRERENBQsjBERUcCLDpHG/FgYc95A+WIyOWessLZtWM5Eo4OSL+bGGCURERGRp7EwRkREAU/pGOtgYcxZ3fliof3eJzvWvpmSHWPkIc2dZhyscD9fjIiIiMjTWBgjIqKAFxMqFcYa2THmNKVjzEHwvkzZTMmMMfKQ7UUNsInSmG5CuMHXxyEiIiJyrzD29NNPIzMzEwaDAXPmzMG2bdsGvP+TTz6JcePGISgoCGlpabj77rvR1dWl3P7QQw9BEIRev/Ly8tw5GhERjULMGHON1SaioEYajxyoMJbVI2PMZhOH5Ww0sm072QAAmJMd7eOTEBEREUk0rj7gnXfewcqVK/Hcc89hzpw5ePLJJ7Fs2TIcPXoU8fHxfe7/5ptv4ne/+x1eeuklzJ8/H8eOHcPNN98MQRCwatUq5X4TJkzAV1991X0wjctHIyKiUSo6hIUxV5Q0dMBoscGgVSEtuv+tgGnRwdCoBHSarahu7UJSRJBTzy+KIv689ggMGjXuPmusp45NI8C2IqkwNiuThTEiIiLyDy53jK1atQq33347li9fjvz8fDz33HMIDg7GSy+95PD+mzZtwoIFC3DttdciMzMTZ599Nq655po+XWYajQaJiYnKr9jYWPe+IiIiGnWYMeaao/Z8sdz4MKhVQr/306pVSI+RCmeFLoxT7ihuxL+/LcRT64+jvs04tMPSiNFhsuBAuZQvxsIYERER+QuXCmMmkwk7d+7E0qVLu59ApcLSpUuxefNmh4+ZP38+du7cqRTCCgsL8fnnn+O8887rdb/jx48jOTkZ2dnZuO6661BSUtLvOYxGI1paWnr9IiKi0YsZY6455kS+mCw71vXNlO9sL1X++2Q988lIsqekCRabiKQIA1KjnOs+JCIiIvI2lwpjdXV1sFqtSEhI6PXxhIQEVFVVOXzMtddeiz/84Q9YuHAhtFotcnJysHjxYtx3333KfebMmYNXXnkFa9euxbPPPouioiIsWrQIra2tDp/zscceQ0REhPIrLS3NlS+DiIhGGGaMuaa7MNb/RkpZdpx0n0InN1O2dpmxZl+l8v9FdR1unJBGIjlfbFZmNASh/05FIiIiouHk9a2UGzZswJ/+9Cc888wz2LVrF1avXo01a9bgkUceUe5z7rnn4sorr8TkyZOxbNkyfP7552hqasK7777r8DnvvfdeNDc3K79KS0sd3o+IiEYHZoy5RimMJbrSMeZcYezTvZXoNFuV/y+qc77TjEY2JV8si2OURERE5D9cSriPjY2FWq1GdXV1r49XV1cjMTHR4WN+//vf44YbbsBtt90GAJg0aRLa29vx4x//GP/3f/8HlapvbS4yMhJjx45FQUGBw+fU6/XQ6/WuHJ2IiEYwuTDW2GGCKIrsRhmAyWJTilzjnBillDdTFjpZ4Hpnh3SxKjUqCGWNnTjJjjECYLbasLukCQAwm/liRERE5Edc6hjT6XSYMWMG1q9fr3zMZrNh/fr1mDdvnsPHdHR09Cl+qdVqANLWKkfa2tpw4sQJJCUluXI8IiIapeRRSrNVRJvR4uPT+LeiunZYbCLC9BokRRgGvb88SlnW2AmjxQqL1YZ1B6vwfx/ux6GK3hmfR6pasLe0CRqVgLvOyAXg/AgmjWwHypvRabYiIkiL3PjBR3iJiIiIhotLHWMAsHLlStx0002YOXMmZs+ejSeffBLt7e1Yvnw5AODGG29ESkoKHnvsMQDAhRdeiFWrVmHatGmYM2cOCgoK8Pvf/x4XXnihUiD79a9/jQsvvBAZGRmoqKjAgw8+CLVajWuuucaDXyoREY1UQTo1grRqdJqtaGg3Icyg9fWR/NaneysAAHlJYU511sWG6hBm0KC1y4KHPz2Erw/XoKqlCwDw+f5KfHDnfKV4Jofunzk+HjMzowAAxfXt7OIjbO+RL6YaYBMqERER0XBzuTB29dVXo7a2Fg888ACqqqowdepUrF27VgnkLykp6dUhdv/990MQBNx///0oLy9HXFwcLrzwQjz66KPKfcrKynDNNdegvr4ecXFxWLhwIbZs2YK4uDgPfIlERDQaRIfoUN7UiYZ2EzJiQnx9HL9UVNeO/3xXCAC4dWGWU48RBAHZsSHYW9aMN7dKG6OjQ3SICNKiqK4dN760Dat/Oh8RQVp8uLscAPCjWelIiw6GWiWgw2RFTasRCeGDd6fRyLWtqBEAMDsryscnISIiIurN5cIYAKxYsQIrVqxweNuGDRt6fwKNBg8++CAefPDBfp/v7bffducYRERECrkw1tjBAH5HRFHEw58ehMlqw6LcWCyb4Dgb1JGz8hOwt6wZc7Kicd3cDCybkIDWLgsuf3YTius7sPzl7bhxXgaaOsxIDDfgtLFxUKsEpEYFobi+A4W17SyMjWI2m4gdxd0dY0RERET+xK3CGBERkb+Jsgfw17exMObIV4drsOFoLbRqAQ9dNMGl0cYVZ+Ti9tOyodeolY/pQ9V47ZbZuOyZTThY0YLfrd4PALhiRirU9lG5rNgQFNd34GR9O+blxHj2C6KAUVDbhqYOM4K0akxMifD1cYiIiIh6cSl8n4iIyF9FB0u5YuwY66vLbMXDnx4EANy6MBs5ca6Hn/csiskyYkLw8vJZCNapIe/TuWpmmnJ7pn2ktYgB/KPatiKpW2xaeiS0ar70JCIiIv/CVydERDQiRIfoAQAN7WYfn8T/PPftCZQ1diIpwoCfnzHGo889OTUSz1w3HQatCudMSER6TLByW3YcC2PUO3ifiIiIyN9wlJKIiEaE6BB7x1g7O8Z6Km3owLMbTgAA/u/88QjRe/5H/+Jx8dhx/1kI1vbuKmPHGAHAdnvH2OwsFsaIiIjI/7BjjIiIRgQlY4yFsV7+9PlhGC02zM+JwfmTkrz2eUL1GqhUvXPLsmKlwlhJfQesNtFrn5v8V1ljByqau6BRCZiWHunr4xARERH1wcIYERGNCDH2whgzxrptP9mA/x2o+v/27jw8yvrc//jnmUkySUgmK9lJAoR9FZCICKJQFi1Hq21xOYq2YqvYn4raVaV24xw9tVovW1tPW+1ptdRWa6u0iqxaEBVU9rATliwkIfs2mXl+f8xCItkTMsnM+3Vdua4yz5OZe5Dvlekn9/f+ymJIKxd3beB+b0iLjVCY1aJGp0uny+v69LXRP3i3UY5Lj1FkGBsVAABA/0MwBgAICHGRnmCMjjFJkstl6kdv7JUkLbk4U6NSovu8BqvFUJZn5hjbKYPTKx+dlCTNGMappAAAoH8iGAMABIR4tlK28I+dp/XpyQoNCrNqxedG+q2O7ETmjAWrrYdLteVwqcKsFt0yI8vf5QAAALSKYAwAEBC8wVhFnUNNTpefq/GveodT//3P/ZKku+YM1+Bom99qGUYwFpRM09STa/MkSTdMH6L02Ag/VwQAANA6gjEAQECIiQiVd4RWeZ3Dv8X42W/eO6rTFfVKiwnXHbOG+bUWOsaC07sHS/ThsbMKC7Fo+RU5/i4HAACgTQRjAICAEGK1KCYiVJJUFsTbKc9UNegXGw5Jkh5aOErhoVa/1pOd4A7GjpUSjAUL0zT107UHJEn/mZulZHu4nysCAABoG8EYACBgxHsG8AdzMPb0ugOqaXRqYkaMrpmU7u9yNGywOxg7UVarxqbg3uIaLNbvL9anJ8oVEWrVXXOG+7scAACAdhGMAQAChnfOWLCeTFlQUafVH56QJH1n0RhZLIafK5KSom2KDLPKZUonztb6uxxcYO7ZYu5usVsvzfLrfDsAAIDOIBgDAASMOE8wVlYbGMFYVb1DK1/frS2HSzp1/682HZHDaSp3aLxmDE+4wNV1jmEYvu2UR8+wnTLQvbWnUHtOV2pQmFVfm023GAAA6P8IxgAAAcO3lbI6MIKxt/cU6cWtx3Xb7z7U+0dK2723uKpeL3+QL0n6xpUj+qK8ThuayJyxYGCapp7dcFiS9JXLhvo6OAEAAPozgjEAQMCIjwqsjjHvrLTGJpeWvfiR9p6ubPPe/333qBqaXLooM1Yzc/pHt5iXNxg7wsmUAW1Hfrl2napQWIhFt88c6u9yAAAAOoVgDAAQMLwdY4EyY6yy3iFJMgypqqFJS3/3gfJLz5/TVVbTqD+8f1yS9I0rc2QY/p8t1ly2t2OMYCyg/X7rMUnSf0xKo1sMAAAMGARjAICA4Z0xVhogwVhFnTsYu/WSLI1OidaZqgbd+tttKqluaHHfb987qtpGp8al2XXFqCR/lNoub8fYUYKxgFVcVa81uwokSbddmu3fYgAAALqAYAwAEDDiB4VKks4GyFbKSk8wlhEXqRe/Ml0ZcRE6Vlqrz//8PT2z7qCKK+tVUefQi1uOSeqf3WLSuWCsoKJedY1OP1eDC+HlbSfkcJqakhmr8ekx/i4HAACg0wjGAAABI36QTZJ0tsbh50p6R2V9kyTJHhGiZHu4fv+V6UqNCVdhZb1+uvaALv2v9frSc1tU1dCkkclRmj82xc8Vty4uMlT28BBJDOAPRA6nS3/c5t7Ku5RuMQAAMMAQjAEAAobvVMoA20oZE+HuhBs2OEobHpyjny2ZpGlZcWpymTpQVC1JWn5FjiyW/tctJkmGYWh0il2StOtkhZ+rCU71Dqd+vfmwXtxyTKZp9upzv7WnUMVVDUqMsmnR+NRefW4AAIALLcTfBQAA0FviPFsp6xxO1TU6FRFm9XNFPePdSmkPD/U9Fh5q1RcuytAXLspQXmGVVn94QqEhhj4/Mc1fZXbK1Ow4fXCsTB8eK9OXLx7i73KCyob9xXr077t1oqxOkjQ6JVq5w3rv5FLvVt6bcjMVFsLvXAEAwMBCMAYACBhRthCFWS1qdLpUVtuo9LAIf5fUI96OMXtEaKvXR6VE69HFY/uypG6blhUnSdp+/KyfKwkep8vr9Ng/9uitPUWSJIshuUzpuU2Hey0Y23O6Qh8eO6sQi6GbczN75TkBAAD6Er/WAwAEDMMwfF1jZwNgO2VlfcutlAPZVE8wdqSkRqWfOVUTve9QcZUW/Gyz3tpTpBCLoa/NHqY3vjFLFkPakHdG+woqe+V1fr/FPVts4fgUJdvDe+U5AQAA+hLBGAAgoMR55oyVDvBgrKHJqXqHS1LbHWMDSWxkmEYkRUlqvWusscml/3v/uPIKq/q6tIDT5HTpgVd2qqqhSePT7Xrz/83Sd64ao7Fpdi2a4J4B9qtNh3v8Og1NTv3909OSpFtnZPf4+QAAAPyBYAwAEFASotzB2EDvGKusc59IaRhStC0wJh9My257O+Xz7x7RI3/brc8/866e3XBITU5XX5cXMJ5/96g+PVGu6PAQPX/rNI1KifZdu+vy4ZKkf+ws0Imy2h69zkfHzqrO4VRStE0Xe/7bAgAADDQEYwCAgBIXICdTeueLRdtC+u1pk101LStekvThsbLzrv3D03nkcJp64q08felXW3XkTHWf1hcIDhRV6WdrD0iSHv38WKXGtJyzNz49RrNGJMrpMvW/7x7p0WttPnBGkjRrxGAZRmD8GwUAAMGHYAwAEFDiB3k6xmoHdjDmnS8WCNsovbwdY7tPVare4fQ9fuRMtfYXVslqMfT9xWMVbQvRx/nluurn72rNrgJ/lTvgOJwuPfDnT9XodOnK0Un64tSMVu/zdo2t/uhEj+a9bT5YIkmaPTKx288BAADgbwRjAICAEigzxirrAmfwvldmfKQSo2xqdLq061SF73Fv+HXp8ATdNnOo/nX/bM3MSVC9w6Ufv7nPX+UOOL/adFi7TlXIHh6iVddNaLOLa8bwBE3MiFG9w6UXtxzr1msVV9VrX0GlDEO6LIdgDAAADFwEYwCAgBIoM8a8Wynt4YETjBmGoWme0yk/OnZuztibuwolSVd7BsOnx0boZ0smS5IKKurkYN5Yhw4VV+vpdQclSY9dM67dEyINw/B1jb249biqG5q6/HrvHnB3i41Pi1FClK0bFQMAAPQPBGMAgIASKDPGKuvdYYU9IjAG73t5t1N+5JkzdrSkRvsKKmW1GJo/LsV3X+Igm8KsFrlMqaiy3i+1DiRv7SmUw2nqspxEXTs5vcP7549L0bDEQaqoc2jl63u6/HqbD7rni7GNEgAADHQEYwCAgOKdMTbgg7EA3EopSdOy3QP4t+eflctltthG6f1vJ0kWi6GUGHfX0+lygrGO5Je6T5iclh3XqUH4Vouhn1w3QRZD+uuOk3rloxOdfi2Xy9S73vliIwZ3r2AAAIB+gmAMABBQAmb4fgBupZSkcWl2hYdaVF7r0JGSar250x2MXeXZRtlcWqw3GKtr9bmcLnPAb5ntLcfLaiRJWQmRnf6eS4YlaMXnRkqSHnl9tw4UVXXq+/YWVKqsplGDwqya4tkaCwAAMFARjAEAAsq5YMwhl8v0czXdVxGgHWOhVosmD4mVJP1l+ynt9WyjXNBsG6VXWmyEJOl0RevB2IOvfKqLf/yOXvv45AWrd6Dwdoxlxg/q0vfdPSdHs0Ykqt7h0t1/3KGaTswb23TAvY1yxvBEhVr5KAkAAAY2Ps0AAAJKbKQ7SHK6TFXVd32oeH9RWe/pGAuwYEySpmW5t1P+9t9HJUkzhrXcRumV7g3G2ugY23q4VE0uUw/8+VP9/dPTF6ja/q+hyakCzxy2rnSMSe4tq08tmaxku02Hiqv1yN92yzTbD5Q3e4Kxy5kvBgAAAgDBGAAgoNhCrIq2uQfWn6lu8HM13ReoHWOSNNUzgL+xyX3aZGvbKCUpNcYbjJ0/Y6ze4VShJwxymdL9qz/xbcsMNifK6mSa0qAwqxJaCRg7khBl0zM3TpHFkF79+JRWf9j2vLHqhiZtP+4+UXT2SOaLAQCAgY9gDAAQcEamREvSgA5KKusC81RKSZqSGSfvfHj3NsrkVu9rb8bYiTL31sFoW4i+ODVDTpepe//0sd7aU3hhiu7H8j3zxTITBnVq8H5rpg+N14MLRkmSHn19j3bkn231vvc9XXpZCZHKSujatk0AAID+iGAMABBwll6aLUn6/dZjqnc4/VtMN3m3UgZix1hMRKhGJbvDy0uGxSshytbqfe1tpTzunamVEKn/vn6ivnBRuppcpu55aUeboU6g8v1dxEf06Hnuuny4Fo5LUaPTpbv+sF3FVed36m0+6N5GOWsE2ygBAEBgIBgDAAScq8anKD02QqU1jXrt41P+LqdbKgL0VEqvhePdw/Zvmp7V5j2pnmCssr5JVZ6g0Ou4p2MsKyFSVouh//nSJM0ZNVgOp6k1A7hTsDvyfX8XPevgMgxD//PlSRqRFKWiygbd/Ycdvu2ukmSapm++2OwRbKMEAACBgWAMABBwQqwW3T4zW5L0/LtHBtzplKZpqrIucIfvS9I9V+Roy7ev1NUTW58vJklRthDZw91bSQsqWnYv5Zd6tg96TmG0Wgxd7pl5daqNYf2B6tyJlF0bvN+aKFuIfn3rNEWHh+ij42f1gzf26HhpjZ5+56Cu/OkmHSutVYjF0IzhCT1+LQAAgP6AYAwAEJCWXDxE0bYQHTlTow15xf4up0uqG5rkzfICcSul5A4v02I73vrnveezYVfzjjGv9Dbu7UuNTS699vFJ/eH9430WyLb2d9ETQxMH6ekbJsswpD+8n6/Ln9ion71zQEdLahQeatE9V+YoOkA7GQEAQPAJvIm+AABIig4P1U25mfrV5iP69eYjmjum9QHv/VFlvXvwfpjVIltIcP8OKz02QvsLq1RQ/tmOMU8Y1KxLyheine37YKyy3qGXt+Xrd/8+5jsts6LOoeVX5FzQ13W5zHNbKeN7bxj+laOTtWLeSP107QFZDGlmTqK+cFG65o9LUZSNj48AACBw8MkGABCwbpuZrd+8d1TbjpZp58lyTcyI9XdJnVJRe24bZXdPGQwUaa0M4He6TJ04e274vldGnPve0ppG1TucCg+1XvD6TNPUsxsO6blNR1Td4A40YyNDVV7r0E/fztOkjFhddgEH1RdV1auxyaUQi+E7xbO33HNlji7NSVBGXKSS7b373AAAAP1FcP8aGgAQ0FJjIrR4Upok6fl3j/q5ms7znkhpj+D3V6mesKd5MFZQUSeH01So1VBqzLntmDERoRoU5g7D+mo75cYDZ/Q/bx9QdUOTRiRF6fEvTtS2787Vl6dlyGVK/+9PH6ug4sLV4j2RMj0uQiHW3v1YZxiGpmbFE4oBAICARjAGAAhod8waKklas6tAJz1dRv2d90TKQJ0v1hWtzQ3zbqMcEuc+kdLLMAylx/XddkrTNPWztQckSbfOyNJb983Wl6cNkS3Eqh9cM17j0uwqq2nU3X9sebpjb+rNwfsAAADBiGAMABDQxqXFKHdovJwuU2/vKfJ3OZ3iO5GSAee+rZTNT6U8Vnr+NsrP3t8XHWNr9xZp58kKRYZZde/cEbI0C+nCQ6365c1TZQ8P0cf55frJmn09eq3qhqZW39PxMvfpnL01eB8AACDYEIwBAALexdnxkqSDxdV+rqRzvMP36RhrHozV+U559IVBrXRJpbcyk+xCcLlMPenpFrt9ZrYSomzn3ZOZEKmfLZksSXphyzG9/smpbr/Wf/7vNl3xxEYdKq5qce04HWMAAAA9QjAGAAh4I5KjJEkHi6o6uLN/8G6lZMaYlBxtk8WQHE5TJdUNkpptH0w4/xTGvtpKuWZ3gfYXVinaFqJls4a1ed/cMcm6x3My5bf/uksHuvFv8O29RfrkRLkanS6t2VXY4tqJMm8w1nsnUgIAAAQTgjEAQMAbkRQtyd0xZpqmn6vpGFspzwmxWnzD371bCb1dUu11jJ28gB1jTpepp945KEn66qyhio0Ma/f++z83UpflJKrO4dTX/2+7qjyHK3SGaZp6Zv1B35/X7y9ucf24JxhjKyUAAED3EIwBAALesMGDZDHcnVhnqhr8XU6HKhm+30LzOWOmaSrfEwZlJ7YdjF3IjrG/f3pKh4qrFRMRqq9cNrTD+60WQ0/fMFmpMeE6UlKjb/11Z6cD2vX7i7XndKUiQt2nbX56slylns65ijqHymvd/1bYSgkAANA9BGMAgIAXHmpVlmfb3UCYM1ZZ791KSTAmnQvGTpfXqaymUdUNTTIMKSOulWDMs5WysLJeTlfXugNN01RVvUM1DU1t3tPkdOlpT7fYnbOHdbqrLyHKpmdvnqJQq6E1uwr1m/eOdqqen69zv9bSS7M1Ls0u05Q25p2RdG5LaWKUTYNsbLsFAADoDj5FAQCCQk5SlI6W1OhAUZVm5iT6u5x2VdAx1kJazLmtlN6tgyn2cIV7uqiaS4oOV4jFUJPLVFFlvS9Ua8tv3juq1z85pdLqRpVUN6ihyaVQq6HX7p6p8ekx593/zr4iHSutVcKgMN12aXaX3seUzDg98vmxevT1PVr1z/2akB6j3GEJbd6/6cAZfXqyQhGhVt0xa6hCrYb2nK7U+rxiXT81gxMpAQAAegEdYwCAoDDSO4B/IHSM1bk7lpgx5ta8Yyy/g1MYrRZDqbEtZ5K1pd7h1Ko1+7TzZIVOldepocklyT3o/9UdrZ8guW6fe8bXtReld6tL65ZLsnTt5DQ5Xabu/uMO3/D8zzJNU097usX+85JMJUbZdMXoJEnS5rwzcjhd7c5aAwAAQOcQjAEAgoJ3AP+hov4fjNEx1lLzGWO+MKidLqnOzhk7WFStJpep2MhQvXb3pXr3m1fo6RsmS5LW7S86bw6Yy2Vqg2cb45WekKqrDMPQqusmany6XaU1jVr2+49U3crWzX8fKtXH+eWyhVi0bLb71MtJGbGKHxSmqoYmfXTsbLPTOQnGAAAAuotgDAAQFHKS3B1jB4qr+v3JlOdmjDHxQJLSPB1gp8vrmm0fHNTO/Z5grIOOsT2nKyRJ49NidFFmnIbER2rumGSFWS06Xlqrw2dqWty/+3SFSqobNCjMqouz47v9fiLCrHr+1mkaHG3T/sIq3fenT+RqNg+toKJOj7+1X5J0U26mkqLd799qMTRn5GBJ0oa8Yt/fBYP3AQAAuo9gDAAQFHKSomQYUnmtQyXVjf4uR41NLr178Ize3lPY4nGH06XaRqckOsa80mLcQVdJdaMOejr+2guDMjodjFVKksam2X2PRdlClDvMHXqt31/U4v4N+93dYpeNSFRYSM8+QqXGROjXt0xVWIhF7+wr0hNv5+nk2Vp977Vduvzxjdp5skLhoRZ9bfbwFt/n3U65fn+xr2OMGWMAAADdx6+iAQBBITzUqsz4SB0vrdXBoioNjrb1eQ2V9Q6t21ekd/YWa9OBM74tdC8ty9Wlw90HAlR6tlFKUjQzxiRJsZGhigi1qs7h9HV5tbuVMq5zWym9zzWuWTAmSXNHJ+ndgyVat69YdzYLptbnueeLdXcb5WddlBmnJ744Uff+6RP9cuNhPb/5iJo8nWO5Q+P1rUWjleI5eMBr9sjBsloMHWo2Ky8zvu3uOQAAALSPjjEAQNDwzhnzxwB+l8vU4mfe0/2rP9WbuwpU3dAkw3Bf+zi/3HdfZb07LIu2hchqMfq8zv7IMAzfdkrvjsOsdsKg9Fh3aHa6nY4xp8vUvoIqSa0EY2OSJUkfHT+rilp3UFlS3aCdJ8slSXNG9U4wJknXTE7X8ivc4VuTy9TMnAT96c5LtPprMzQlM+68+2MiQjUt69zjkWFWJUaF9Vo9AAAAwYaOMQBA0BiRHKV39hXpQFFVn7/2qfI6HS+tVYjF0NcvH655Y5P170MleuKtPO0vPFePd/C+nW2ULaTFRvhmfsVEhComsu2/n7Rmp1KapinDOD9gPFpSozqHU+GhFg1NjGpxbUh8pEYmR+lAUbU2HijWNZPTtSnvjEzTHaIl28PPe76eeOBzozQ6xa70uIhWw7DPunJ0krYdLZPk3lLa2vsDAABA59AxBgAIGiOT3QGIPzrGvGFcTlKUHlwwSpOHxPpmW+0vqPTd591KGR3O766a884ZkzqeqeUdvl/b6FR5raPVe/Z6/s5Hp9hb7cy7crS7a2z9fvf2yd7eRtmcxWJo8aS0ToVin62B+WIAAAA9QzAGAAgavq2URX1/MmWeJxgbmRzte2xMijsYO1JSo3qHe+C+t2OMwfstecMuqeNTGMNDrUqMcs+Qa2sAf1vzxbzmjXGHTxvzzqje4dTmA+7B+1dcgGCsq3KSopThmaPW3umcAAAA6BjBGAAgaAwf7D6Z8mytQ6U1fXsypfc0xVEp54KxZLtNsZGhcrpM3zD1ynq2UrbGuz1S6lyXlG8AfxvB2F7PiZTj0mJavX5RZpxiI0NVUefQ85uPqKq+SfGDwjQpI7aLlfc+wzB04/RMSdJlOYl+rgYAAGBgIxgDAASNiDCrhsS5QxVvUNVX8grP7xgzDMPXNbbPs7WPjrHWNe8Ya2/wvle6d85YKydTmqapPb5grPWOMavF0BWeIfvPbjwkSbrccyJkf3D3nOH65NHPafbIwf4uBQAAYEAjGAMABJVzc8b6bgB/k9OlQ2c8HWPNgjFJGp3q/rN3AH9lnftUSns4wVhzLYKxznSMxbbdMVZYWa+ymkZZLUaLDr7P8s7yqne4JPWPbZRehmEoNpLTKAEAAHqqW8HYs88+q+zsbIWHhys3N1cffPBBu/c/9dRTGjVqlCIiIjRkyBDdf//9qq+v79FzAgDQHTm+OWN91zF2vKxWjU0uRYRafbOhvLwdY/sL3R1M3q2UdIy1lBoT7uvWyk7sTMeYJxhrpWPMu41y+OBBCg+1tvkcs0cOVojnNa0WQ5ePoDsLAAAg0HQ5GFu9erVWrFihlStXaseOHZo0aZIWLFig4uLiVu9/6aWX9O1vf1srV67Uvn379Jvf/EarV6/Wd7/73W4/JwAA3TUiyd0x5j0lsi8c8HSDjUiOkuUzW/G8HWP7CtwHAni3UtojOJWyufBQq3507Xg9fPUYJdvDO7w/3bNl9nTF+cHYng7mi3nFRITq4ux4SdLUzDjFRBJWAgAABJouB2NPPvmkli1bpttvv11jx47Vc889p8jISP32t79t9f4tW7Zo5syZuummm5Sdna358+frxhtvbNER1tXnBACgu7wzvrzD7vtCaydSNq/HYkhlNY06U9WgSmaMtenG6Zm6Y9awTt3bXsdYRydSNnfLjCxJ0s2XZHa2TAAAAAwgXQrGGhsbtX37ds2bN+/cE1gsmjdvnrZu3drq91x66aXavn27Lwg7cuSI1qxZo6uuuqrbz9nQ0KDKysoWXwAAdMbwJPc2vNKaRpVWN/TJa/pOpGwlGAsPtWqoZ2vgvsIqXzDGjLGe8QZjpTWNqmt0trjm7Rgb24lg7KoJqTryk6t0zeT03i8SAAAAftelYKykpEROp1PJycktHk9OTlZhYWGr33PTTTfpBz/4gS677DKFhoZq+PDhmjNnjm8rZXeec9WqVYqJifF9DRkypCtvAwAQxCLDQjQk3h2aHOyjrjFfx1gbg95Hp3rmjBVUqrLeM3yfjrEesUeEKMrm3o7afAB/Ra1DJz1dZONS299K6fXZ7a8AAAAIHBf8VMqNGzfqJz/5iX7xi19ox44devXVV/Xmm2/qhz/8Ybef8zvf+Y4qKip8XydOnOjFigEAgW6EbwD/hZ8z1tDk1NGSGkmtd4xJ0piUcydTVrCVslcYhuHrGjvdLBjbU+DeRpkeG8HMMAAAAKhLk30TExNltVpVVFTU4vGioiKlpKS0+j2PPPKIbrnlFt1xxx2SpAkTJqimpkZ33nmnvve973XrOW02m2w2W1dKBwDAZ0RylNbvL9bT6w6pocmlm3OzFBHmPp2wocmpt/cU6bWPTykzPlIrF4+VYXS/Y+jImRo5Xaaiw0OUbG/9Z9cYT8fYvoLKc1spGb7fY+lxEcorqmrRMbbXN3i/422UAAAACHxd6hgLCwvT1KlTtW7dOt9jLpdL69at04wZM1r9ntraWlksLV/GanX/nw/TNLv1nAAA9MT1UzKUHhuhkuoG/ejNfZr1+AY9t+mwfvTGXl3yk3X6xssfa/3+Yr2w5Zj2FfSsq8x7+uWo5Og2AzbvVsoDRVVqcpmS6BjrDWmx7tMrmw/g39vJEykBAAAQHLr86+gVK1Zo6dKlmjZtmqZPn66nnnpKNTU1uv322yVJt956q9LT07Vq1SpJ0uLFi/Xkk0/qoosuUm5urg4dOqRHHnlEixcv9gVkHT0nAAC9aWRytDY8OEd/3XFSz244pJNn6/Rf/9zvu55iD1ekzaojZ2q0ZldBp4a0tyWvsP35YpKUFhOu6PAQVXnmi4VYDEWEWrv9mnBLj42UJL21p1CZCZGaM3Kwb/A+HWMAAACQuhGMLVmyRGfOnNGjjz6qwsJCTZ48Wf/61798w/Pz8/NbdIg9/PDDMgxDDz/8sE6dOqXBgwdr8eLF+vGPf9zp5wQAoLeFhVh04/RMfXFqhl7dcVJ/+vCEEqNsuuHiIbp85GC9uatA9/7pE63ZVaAH5o/s9nbK5h1jbTEMQ2NS7PrgWJkkd7dYT7Zvwm1Shrsr7GBxtb75l50tro1LJxgDAACAZJimafq7iJ6qrKxUTEyMKioqZLfzQRcA0HPVDU2a8sO1amxy6V/3zdLolO79fJn9+Abll9Xq5WWXaMbwhDbvW/n6br249bgkaWjiIG14cE63Xg8t7TpZobX7irQpr1g7T1XINN2D99/71hWEjwAAAAGss1kRk30BAGhFlC1El48crLV7i7RmV2G3grHaxibll9VKkkYmR7V7r3fOmCTZmS/WayZkxGhCRoxWfG6kSqsb9MHRMo1oZ94bAAAAgkuXhu8DABBMrp6QKklas6ugW99/sKhakpQYFaaEqPZPUx7dbAaZPZzfW10ICVE2LZqQqpyk9kNKAAAABA+CMQAA2nDlmCSFWS06VFztmxXWFXme7xnZznwxr1Ep0fI2MXEiJQAAANA3CMYAAGiDPTxUs0cmSupe19iBws4HY5FhIcpOGOR+XYIxAAAAoE8QjAEA0I5F47u/ndLbMTYqpeNgTDq3ndIeTjAGAAAA9AWCMQAA2jFvbLJCrYYOFFXrUHHXtlN6Z4x1pmNMkq6fkqGshEjNG5PU5ToBAAAAdB3BGAAA7YiJCNVlOd7tlIWd/r6KWocKK+sldXwipde8scna9NAVmpYd3/VCAQAAAHQZwRgAAB24qhunU246eEaSlB4boWi2RgIAAAD9EsEYAAAd+NzYZIVYDO0vrNLRkpoO7zdNU7/adFiS9KVpGRe6PAAAAADdRDAGAEAHYiPDNDUrTpK07Uhph/e/e7BEe05XKiLUqqUzsi9wdQAAAAC6i2AMAIBO8AZjO/LPdnjvc55usSUXD1HcoLALWhcAAACA7iMYAwCgE6ZkeoOx8nbv23myXFsOlyrEYuiOWUP7oDIAAAAA3UUwBgBAJ0zxdIwdKq5WRa2jzfu83WL/MSlNGXGRfVIbAAAAgO4hGAMAoBPiB4VpaOIgSdKOE61vpzxaUqN/7i6UJH3t8uF9VhsAAACA7iEYAwCgky7KjJUkfXy89WDs15uPyDSlK0cnaVRKdB9WBgAAAKA7CMYAAOik9uaMFVfV6687TkqSvk63GAAAADAgEIwBANBJ3pMpPzlRLqfLbHHt5W0n1Njk0pTMWF2cHeeP8gAAAAB0EcEYAACdNDI5WlG2EFU3NOlAUZXvcdM0fd1it8zIkmEY/ioRAAAAQBcQjAEA0ElWi6FJQ2IkSTvyz80Z+/DYWeWX1SrKFqIF41L8VR4AAACALiIYAwCgC3xzxo6X+x77y/YTkqSrJqQoMizEH2UBAAAA6AaCMQAAumCKZ87Yx56OsdrGJq3ZVShJ+uLUIX6rCwAAAEDX8WttAAC6YMoQdzB2pKRGZTWN2nSgWNUNTcqMj2ToPgAAADDA0DEGAEAXxESGavjgQZLcXWN/2e4eun/9lAyG7gMAAAADDMEYAABd5J0z9ubOAm05XCpJum5Kuj9LAgAAANANBGMAAHTRVM+csVc/PiXTlC4ZFq8h8ZF+rgoAAABAVxGMAQDQRd4B/F4M3QcAAAAGJoIxAAC6KGdwlKLD3efXRIZZtWh8ip8rAgAAANAdBGMAAHSRxWJo8pBYSdKi8akaZOOQZwAAAGAg4pM8AADdcM8VObJaDN07d4S/SwEAAADQTQRjAAB0Q+6wBOUOS/B3GQAAAAB6gK2UAAAAAAAACEoEYwAAAAAAAAhKBGMAAAAAAAAISgRjAAAAAAAACEoEYwAAAAAAAAhKBGMAAAAAAAAISgRjAAAAAAAACEoEYwAAAAAAAAhKBGMAAAAAAAAISgRjAAAAAAAACEoEYwAAAAAAAAhKBGMAAAAAAAAISgRjAAAAAAAACEoEYwAAAAAAAAhKIf4uoDeYpilJqqys9HMlAAAAAAAA8DdvRuTNjNoSEMFYVVWVJGnIkCF+rgQAAAAAAAD9RVVVlWJiYtq8bpgdRWcDgMvl0unTpxUdHS3DMPxdTq+orKzUkCFDdOLECdntdn+XAwxYrCWg51hHQO9gLQE9xzoCekcwrCXTNFVVVaW0tDRZLG1PEguIjjGLxaKMjAx/l3FB2O32gP1HCvQl1hLQc6wjoHewloCeYx0BvSPQ11J7nWJeDN8HAAAAAABAUCIYAwAAAAAAQFAiGOunbDabVq5cKZvN5u9SgAGNtQT0HOsI6B2sJaDnWEdA72AtnRMQw/cBAAAAAACArqJjDAAAAAAAAEGJYAwAAAAAAABBiWAMAAAAAAAAQYlgDAAAAAAAAEGJYAwAAAAAAABBiWCsn3r22WeVnZ2t8PBw5ebm6oMPPvB3SUC/9f3vf1+GYbT4Gj16tO96fX29li9froSEBEVFRen6669XUVGRHysG+ofNmzdr8eLFSktLk2EY+tvf/tbiummaevTRR5WamqqIiAjNmzdPBw8ebHFPWVmZbr75ZtntdsXGxuqrX/2qqqur+/BdAP7V0Tq67bbbzvsZtXDhwhb3sI4Q7FatWqWLL75Y0dHRSkpK0rXXXqu8vLwW93Tm81x+fr6uvvpqRUZGKikpSQ899JCampr68q0AftWZtTRnzpzzfi59/etfb3FPsK0lgrF+aPXq1VqxYoVWrlypHTt2aNKkSVqwYIGKi4v9XRrQb40bN04FBQW+r/fee8937f7779c//vEPvfLKK9q0aZNOnz6t6667zo/VAv1DTU2NJk2apGeffbbV648//rh+/vOf67nnntO2bds0aNAgLViwQPX19b57br75Zu3Zs0dr167VG2+8oc2bN+vOO+/sq7cA+F1H60iSFi5c2OJn1Msvv9ziOusIwW7Tpk1avny53n//fa1du1YOh0Pz589XTU2N756OPs85nU5dffXVamxs1JYtW/Tiiy/qhRde0KOPPuqPtwT4RWfWkiQtW7asxc+lxx9/3HctKNeSiX5n+vTp5vLly31/djqdZlpamrlq1So/VgX0XytXrjQnTZrU6rXy8nIzNDTUfOWVV3yP7du3z5Rkbt26tY8qBPo/SeZrr73m+7PL5TJTUlLMJ554wvdYeXm5abPZzJdfftk0TdPcu3evKcn88MMPfff885//NA3DME+dOtVntQP9xWfXkWma5tKlS81rrrmmze9hHQHnKy4uNiWZmzZtMk2zc5/n1qxZY1osFrOwsNB3zy9/+UvTbrebDQ0NffsGgH7is2vJNE3z8ssvN++99942vycY1xIdY/1MY2Ojtm/frnnz5vkes1gsmjdvnrZu3erHyoD+7eDBg0pLS9OwYcN08803Kz8/X5K0fft2ORyOFmtq9OjRyszMZE0B7Th69KgKCwtbrJ2YmBjl5ub61s7WrVsVGxuradOm+e6ZN2+eLBaLtm3b1uc1A/3Vxo0blZSUpFGjRumuu+5SaWmp7xrrCDhfRUWFJCk+Pl5S5z7Pbd26VRMmTFBycrLvngULFqiyslJ79uzpw+qB/uOza8nrj3/8oxITEzV+/Hh95zvfUW1tre9aMK6lEH8XgJZKSkrkdDpb/COUpOTkZO3fv99PVQH9W25url544QWNGjVKBQUFeuyxxzRr1izt3r1bhYWFCgsLU2xsbIvvSU5OVmFhoX8KBgYA7/po7eeR91phYaGSkpJaXA8JCVF8fDzrC/BYuHChrrvuOg0dOlSHDx/Wd7/7XS1atEhbt26V1WplHQGf4XK5dN9992nmzJkaP368JHXq81xhYWGrP7O814Bg09pakqSbbrpJWVlZSktL086dO/Wtb31LeXl5evXVVyUF51oiGAMw4C1atMj3vydOnKjc3FxlZWXpz3/+syIiIvxYGQAg2N1www2+/z1hwgRNnDhRw4cP18aNGzV37lw/Vgb0T8uXL9fu3btbzIsF0HVtraXmMywnTJig1NRUzZ07V4cPH9bw4cP7usx+ga2U/UxiYqKsVut5J6wUFRUpJSXFT1UBA0tsbKxGjhypQ4cOKSUlRY2NjSovL29xD2sKaJ93fbT38yglJeW8g2GamppUVlbG+gLaMGzYMCUmJurQoUOSWEdAc/fcc4/eeOMNbdiwQRkZGb7HO/N5LiUlpdWfWd5rQDBpay21Jjc3V5Ja/FwKtrVEMNbPhIWFaerUqVq3bp3vMZfLpXXr1mnGjBl+rAwYOKqrq3X48GGlpqZq6tSpCg0NbbGm8vLylJ+fz5oC2jF06FClpKS0WDuVlZXatm2bb+3MmDFD5eXl2r59u++e9evXy+Vy+T5kAWjp5MmTKi0tVWpqqiTWESBJpmnqnnvu0Wuvvab169dr6NChLa535vPcjBkztGvXrhZB89q1a2W32zV27Ni+eSOAn3W0llrzySefSFKLn0vBtpbYStkPrVixQkuXLtW0adM0ffp0PfXUU6qpqdHtt9/u79KAfunBBx/U4sWLlZWVpdOnT2vlypWyWq268cYbFRMTo69+9atasWKF4uPjZbfb9Y1vfEMzZszQJZdc4u/SAb+qrq72/XZQcg/c/+STTxQfH6/MzEzdd999+tGPfqQRI0Zo6NCheuSRR5SWlqZrr71WkjRmzBgtXLhQy5Yt03PPPSeHw6F77rlHN9xwg9LS0vz0roC+1d46io+P12OPPabrr79eKSkpOnz4sL75zW8qJydHCxYskMQ6AiT3lq+XXnpJr7/+uqKjo31zjGJiYhQREdGpz3Pz58/X2LFjdcstt+jxxx9XYWGhHn74YS1fvlw2m82fbw/oMx2tpcOHD+ull17SVVddpYSEBO3cuVP333+/Zs+erYkTJ0oK0rXk72Mx0bpnnnnGzMzMNMPCwszp06eb77//vr9LAvqtJUuWmKmpqWZYWJiZnp5uLlmyxDx06JDvel1dnXn33XebcXFxZmRkpPmFL3zBLCgo8GPFQP+wYcMGU9J5X0uXLjVN0zRdLpf5yCOPmMnJyabNZjPnzp1r5uXltXiO0tJS88YbbzSjoqJMu91u3n777WZVVZUf3g3gH+2to9raWnP+/Pnm4MGDzdDQUDMrK8tctmyZWVhY2OI5WEcIdq2tIUnm7373O989nfk8d+zYMXPRokVmRESEmZiYaD7wwAOmw+Ho43cD+E9Hayk/P9+cPXu2GR8fb9psNjMnJ8d86KGHzIqKihbPE2xryTBN0+zLIA4AAAAAAADoD5gxBgAAAAAAgKBEMAYAAAAAAICgRDAGAAAAAACAoEQwBgAAAAAAgKBEMAYAAAAAAICgRDAGAAAAAACAoEQwBgAAAAAAgKBEMAYAAAAAAICgRDAGAAAAAACAoEQwBgAAAAAAgKBEMAYAAAAAAICg9P8Bq36dS6e38hoAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "%matplotlib inline\n",
        "df_account_value.account_value.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr2zX7ZxNyFQ"
      },
      "source": [
        "<a id='6.1'></a>\n",
        "## 7.1 BackTestStats\n",
        "pass in df_account_value, this information is stored in env class\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nzkr9yv-AdV_",
        "outputId": "73339178-6be7-44e1-e017-50b44882f096",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Backtest Results===========\n",
            "Annual return         -0.105737\n",
            "Cumulative returns    -0.105737\n",
            "Annual volatility      0.211654\n",
            "Sharpe ratio          -0.424407\n",
            "Calmar ratio          -0.458436\n",
            "Stability              0.012836\n",
            "Max drawdown          -0.230647\n",
            "Omega ratio            0.929272\n",
            "Sortino ratio         -0.578326\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             0.926525\n",
            "Daily value at risk   -0.027022\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(\"==============Get Backtest Results===========\")\n",
        "now = datetime.datetime.now().strftime('%Y%m%d-%Hh%M')\n",
        "\n",
        "perf_stats_all = backtest_stats(account_value=df_account_value)\n",
        "perf_stats_all = pd.DataFrame(perf_stats_all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DiHhM1YkoCel",
        "outputId": "81e68603-03d8-4665-e2fb-2ae72b0c5ab3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "==============Get Baseline Stats===========\n",
            "\r[*********************100%***********************]  1 of 1 completed\n",
            "Shape of DataFrame:  (251, 8)\n",
            "Annual return          0.008342\n",
            "Cumulative returns     0.008309\n",
            "Annual volatility      0.173584\n",
            "Sharpe ratio           0.134686\n",
            "Calmar ratio           0.051410\n",
            "Stability              0.185640\n",
            "Max drawdown          -0.162268\n",
            "Omega ratio            1.022609\n",
            "Sortino ratio          0.187640\n",
            "Skew                        NaN\n",
            "Kurtosis                    NaN\n",
            "Tail ratio             1.052711\n",
            "Daily value at risk   -0.021777\n",
            "dtype: float64\n"
          ]
        }
      ],
      "source": [
        "#baseline stats\n",
        "print(\"==============Get Baseline Stats===========\")\n",
        "df_dji_ = get_baseline(\n",
        "        ticker=\"^BSESN\", \n",
        "        start = df_account_value.loc[0,'date'],\n",
        "        end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "\n",
        "stats = backtest_stats(df_dji_, value_col_name = 'close')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RhJ9whD75WTs",
        "outputId": "4e0a4872-fb40-4a89-cac1-b87d8a705bf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_dji:             date           dji\n",
            "0    2022-01-04  1.000000e+06\n",
            "1    2022-01-05  1.006135e+06\n",
            "2    2022-01-06  9.957550e+05\n",
            "3    2022-01-07  9.981408e+05\n",
            "4    2022-01-10  1.009017e+06\n",
            "..          ...           ...\n",
            "247  2023-01-02  1.021917e+06\n",
            "248  2023-01-03  1.024029e+06\n",
            "249  2023-01-04  1.013391e+06\n",
            "250  2023-01-05  1.008309e+06\n",
            "251  2023-01-06           NaN\n",
            "\n",
            "[252 rows x 2 columns]\n",
            "df_dji:                       dji\n",
            "date                    \n",
            "2022-01-04  1.000000e+06\n",
            "2022-01-05  1.006135e+06\n",
            "2022-01-06  9.957550e+05\n",
            "2022-01-07  9.981408e+05\n",
            "2022-01-10  1.009017e+06\n",
            "...                  ...\n",
            "2023-01-02  1.021917e+06\n",
            "2023-01-03  1.024029e+06\n",
            "2023-01-04  1.013391e+06\n",
            "2023-01-05  1.008309e+06\n",
            "2023-01-06           NaN\n",
            "\n",
            "[252 rows x 1 columns]\n"
          ]
        }
      ],
      "source": [
        "df_dji = pd.DataFrame()\n",
        "df_dji['date'] = df_account_value['date']\n",
        "df_dji['dji'] = df_dji_['close'] / df_dji_['close'][0] * env_kwargs[\"initial_amount\"]\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji.csv\")\n",
        "df_dji = df_dji.set_index(df_dji.columns[0])\n",
        "print(\"df_dji: \", df_dji)\n",
        "df_dji.to_csv(\"df_dji+.csv\")\n",
        "\n",
        "df_account_value.to_csv('df_account_value.csv')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9U6Suru3h1jc"
      },
      "source": [
        "<a id='6.2'></a>\n",
        "## 7.2 BackTestPlot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HggausPRoCem",
        "outputId": "3129cd9f-f034-4dd2-a5a2-c0bb886a7dac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "df_result_ensemble.columns:  Index(['ensemble'], dtype='object')\n",
            "df_trade_date:         datadate\n",
            "0    2021-10-04\n",
            "1    2021-10-05\n",
            "2    2021-10-06\n",
            "3    2021-10-07\n",
            "4    2021-10-08\n",
            "..          ...\n",
            "367  2023-03-24\n",
            "368  2023-03-27\n",
            "369  2023-03-28\n",
            "370  2023-03-29\n",
            "371  2023-03-31\n",
            "\n",
            "[372 rows x 1 columns]\n",
            "df_result_ensemble:                  ensemble\n",
            "date                    \n",
            "2022-01-04  1.000000e+06\n",
            "2022-01-05  1.003203e+06\n",
            "2022-01-06  9.919141e+05\n",
            "2022-01-07  9.959933e+05\n",
            "2022-01-10  1.009521e+06\n",
            "...                  ...\n",
            "2023-01-02  8.836512e+05\n",
            "2023-01-03  8.881057e+05\n",
            "2023-01-04  8.823464e+05\n",
            "2023-01-05  8.931202e+05\n",
            "2023-01-06  8.942632e+05\n",
            "\n",
            "[252 rows x 1 columns]\n",
            "==============Compare to DJIA===========\n",
            "result:                  ensemble           dji\n",
            "date                                  \n",
            "2022-01-04  1.000000e+06  1.000000e+06\n",
            "2022-01-05  1.003203e+06  1.006135e+06\n",
            "2022-01-06  9.919141e+05  9.957550e+05\n",
            "2022-01-07  9.959933e+05  9.981408e+05\n",
            "2022-01-10  1.009521e+06  1.009017e+06\n",
            "...                  ...           ...\n",
            "2023-01-02  8.836512e+05  1.021917e+06\n",
            "2023-01-03  8.881057e+05  1.024029e+06\n",
            "2023-01-04  8.823464e+05  1.013391e+06\n",
            "2023-01-05  8.931202e+05  1.008309e+06\n",
            "2023-01-06  8.942632e+05           NaN\n",
            "\n",
            "[252 rows x 2 columns]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 1500x500 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1500x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "\n",
        "\n",
        "# print(\"==============Compare to DJIA===========\")\n",
        "# %matplotlib inline\n",
        "# # S&P 500: ^GSPC\n",
        "# # Dow Jones Index: ^DJI\n",
        "# # NASDAQ 100: ^NDX\n",
        "# backtest_plot(df_account_value, \n",
        "#               baseline_ticker = '^DJI', \n",
        "#               baseline_start = df_account_value.loc[0,'date'],\n",
        "#               baseline_end = df_account_value.loc[len(df_account_value)-1,'date'])\n",
        "df.to_csv(\"df.csv\")\n",
        "df_result_ensemble = pd.DataFrame({'date': df_account_value['date'], 'ensemble': df_account_value['account_value']})\n",
        "df_result_ensemble = df_result_ensemble.set_index('date')\n",
        "\n",
        "print(\"df_result_ensemble.columns: \", df_result_ensemble.columns)\n",
        "\n",
        "# df_result_ensemble.drop(df_result_ensemble.columns[0], axis = 1)\n",
        "print(\"df_trade_date: \", df_trade_date)\n",
        "# df_result_ensemble['date'] = df_trade_date['datadate']\n",
        "# df_result_ensemble['account_value'] = df_account_value['account_value']\n",
        "df_result_ensemble.to_csv(\"df_result_ensemble.csv\")\n",
        "print(\"df_result_ensemble: \", df_result_ensemble)\n",
        "print(\"==============Compare to DJIA===========\")\n",
        "result = pd.DataFrame()\n",
        "# result = pd.merge(result, df_result_ensemble, left_index=True, right_index=True)\n",
        "# result = pd.merge(result, df_dji, left_index=True, right_index=True)\n",
        "result = pd.merge(df_result_ensemble, df_dji, left_index=True, right_index=True)\n",
        "print(\"result: \", result)\n",
        "result.to_csv(\"result.csv\")\n",
        "result.columns = ['ensemble', 'NSEI']\n",
        "\n",
        "%matplotlib inline\n",
        "plt.rcParams[\"figure.figsize\"] = (15,5)\n",
        "plt.figure();\n",
        "result.plot();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "id": "lmoXQo8zmqrx"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "dbUMm21Rm3_U"
      },
      "outputs": [],
      "source": [
        "# !cp -r \"/content/ \"/content/drive/MyDrive/RL_Project\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBQx4bVQFi-a"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "FinRL_Ensemble_StockTrading_ICAIF_2020.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.10.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "metadata": {
          "collapsed": false
        },
        "source": []
      }
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
